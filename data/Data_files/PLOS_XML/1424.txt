article id="http://dx.doi.org/10.1371/journal.pone.0179708"  #@NEW_LINE#@#  
title  #@NEW_LINE#@#  
Dynamic properties of successful smiles  #@NEW_LINE#@#  

Abstract  #@NEW_LINE#@#  
Facial expression of emotion is a foundational aspect of social interaction and nonverbal communication.  #@NEW_LINE#@#  In this study, we use a computer-animated 3D facial tool to investigate how dynamic properties of a smile are perceived.  #@NEW_LINE#@#  We created smile animations where we systematically manipulated the smiles angle, extent, dental show, and dynamic symmetry.  #@NEW_LINE#@#  Then we asked a diverse sample of 802 participants to rate the smiles in terms of their effectiveness, genuineness, pleasantness, and perceived emotional intent.  #@NEW_LINE#@#  We define a successful smile as one that is rated effective, genuine, and pleasant in the colloquial sense of these words.  #@NEW_LINE#@#  We found that a successful smile can be expressed via a variety of different spatiotemporal trajectories, involving an intricate balance of mouth angle, smile extent, and dental show combined with dynamic symmetry.  #@NEW_LINE#@#  These findings have broad applications in a variety of areas, such as facial reanimation surgery, rehabilitation, computer graphics, and psychology.  #@NEW_LINE#@#  

Citation: Helwig NE, Sohre NE, Ruprecht MR, Guy SJ, Lyford-Pike S (2017) Dynamic properties of successful smiles.  #@NEW_LINE#@#  PLoS ONE 12(6):  #@NEW_LINE#@#  
           e0179708.  #@NEW_LINE#@#  

        https://doi.org/10.1371/journal.pone.0179708  #@NEW_LINE#@#  
Editor: Kim A. Bard,  #@NEW_LINE#@#  
University of Portsmouth, UNITED KINGDOM  #@NEW_LINE#@#  

Received: August 30, 2016; Accepted: June 3, 2017; Published:  June 28, 2017  #@NEW_LINE#@#  
Copyright:  Â© 2017 Helwig et al.  #@NEW_LINE#@#  This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.  #@NEW_LINE#@#  
Data Availability: All relevant data are within the paper and its Supporting Information files.  #@NEW_LINE#@#  
Funding: This work was supported by faculty start-up funds from the University of Minnesota (NEH, SJG, SL-P).  #@NEW_LINE#@#  
Competing interests:  The authors have declared that no competing interests exist.  #@NEW_LINE#@#  
Introduction  #@NEW_LINE#@#  
The ability to express emotional intent via facial expression is a foundational aspect of social interaction and nonverbal communication.  #@NEW_LINE#@#  Since Paul Ekmans pioneering work [13], much effort has been devoted to the study of the emotional processing of facial expressions.  #@NEW_LINE#@#  Research has revealed that a variety of different emotional cues can be perceived within 100 to 200 ms after encountering a face [4, 5].  #@NEW_LINE#@#  Furthermore, studies have shown that evaluations of facial emotions can have immensely important societal outcomes, e.g., recognizing an angry face to avoid a threat or recognizing a trustworthy face to determine a good leader [6].  #@NEW_LINE#@#  The smile is the most well-studied facial expression, given that smiles are used frequently during interpersonal interactions [7].  #@NEW_LINE#@#  Previous research suggests that an inability to effectively smile increases ones risk for depression [8], which highlights the smiles important role in mental health.  #@NEW_LINE#@#  
Unfortunately, tens of thousands of individuals each year suffer from trauma, cerebrovascular accidents (strokes), neurologic conditions, cancers, and infections that rob them of the ability to express emotions through facial movement [9].  #@NEW_LINE#@#  The psychological and social consequences are significant.  #@NEW_LINE#@#  Individuals with partial facial paralysis are often misinterpreted, have trouble communicating, become isolated, and report anxiety, depression, and decreased self-esteem [8, 10, 11].  #@NEW_LINE#@#  One option for such individuals is known as facial reanimation, which consists of surgery and rehabilitation aimed at restoring facial movement and expression.  #@NEW_LINE#@#  Despite the prevalence of facial reanimation procedures, clinicians lack rigorous quantitative definitions of what constitutes a socio-emotionally effective facial expression [1214].  #@NEW_LINE#@#  The key question is this: what spatial and temporal characteristics are most pertinent for displaying emotions in a real-world (dynamic) setting?  #@NEW_LINE#@#  
While much has been discovered about the psychology of facial expression and the perception of emotions, less is known about the impact of dynamic elements, e.g., the rate of mouth movement, left-right asymmetries, etc.  #@NEW_LINE#@#  This is largely because the vast majority of facial expression studies have been conducted on static images of actors expressing different facial emotions, thereby ignoring the temporal component associated with these expressions.  #@NEW_LINE#@#  In real-world applications, the dynamics of a facial expression can drastically influence facial perception [5, 15, 16].  #@NEW_LINE#@#  Successfully treating patients who have facial movement disorders fundamentally requires an adequate understanding of both the spatial and temporal properties of effective emotional expression.  #@NEW_LINE#@#  However, the temporal components of facial emotional perception are less frequently studied, because systematically manipulating the timing of emotional expressions is a very difficult taskeven for the best-trained actor.  #@NEW_LINE#@#  
Synthetic models of human facial expressions [1618] offer exciting possibilities for the study of spatial and temporal aspects of dynamic expressions of emotion.  #@NEW_LINE#@#  Past research has revealed that spatial and temporal characteristics of dynamic facial expressions can be useful for distinguishing between different types of smiles [19, 20].  #@NEW_LINE#@#  Furthermore, some studies have shown that the dynamics of facial expressions can have important, real-world economic and social outcomes [21, 22], and other studies have examined the role of symmetry (or asymmetry) in dynamic facial expressions [23, 24].  #@NEW_LINE#@#  The general consensus is that dynamic aspects of facial expressions can have noteworthy affects on the perception of the expression, and more work is needed to understand how subtle spatiotemporal changes of facial expressions alter their intended meaning.  #@NEW_LINE#@#  
In this work, we leverage recent advances in computer animation and statistical learning to explore the spatiotemporal properties associated with a successful smile.  #@NEW_LINE#@#  Specifically, we develop a 3D facial tool capable of creating dynamic facial expressions, which allows us to isolate and manipulate individual features of lip motion during a smile.  #@NEW_LINE#@#  The resulting tool is able to control the timing of a smile to a greater degree than is possible with trained actors, and allows us to manipulate clinically relevant features of smiles.  #@NEW_LINE#@#  Using this tool, we investigate which combinations of spatial (i.e., mouth angle, smile extent, and dental show) and temporal (i.e., delay asymmetry) parameters produce smiles judged to be successful (i.e., effective, genuine, and pleasant) by a large sample of fairgoers (802 participants).  #@NEW_LINE#@#  
For this study, we focused on analyzing only the effect of mouth motion, given that (i) smiling impairment due to restricted mouth motion has been specifically shown to increase depressive symptoms in patients with facial neuromuscular disorders [8], and (ii) existing surgical interventions have shown particular success in rehabilitating corresponding muscles after trauma [9].  #@NEW_LINE#@#  Although orbicularis oculi contraction is important in Duchenne smiles [7], to date, techniques are limited in restoring periocular movement.  #@NEW_LINE#@#  Multiple approaches focus on restoring mouth movement, so we seek to understand the effects of targeted manipulation of the mouth on the perception of smiling expressions.  #@NEW_LINE#@#  Past studies have found that the lower-half of the face (particularly the mouth shape) is the most salient factor for determining the intended meaning of a smile [25].  #@NEW_LINE#@#  Thus, with this model, we expect the study participants to perceive differences in the emotions of the expressions and, as a result, provide meaningful information for clinical translation.  #@NEW_LINE#@#  

Materials_and_methods  #@NEW_LINE#@#  
Computer-animated_facial_tool  #@NEW_LINE#@#  
Using an interpolative blend shape approach [26], we developed a computer-animated, realistic 3D facial tool capable of expressing a variety of emotions.  #@NEW_LINE#@#  Similar to other recent anatomically motivated face simulation systems such as FACSgen [17] and FACSgen 2.0 [18], our model follows linear motion interpolation between anatomically valid static face poses.  #@NEW_LINE#@#  The modeling process was closely monitored and rechecked by a board-certified facial reconstructive surgeon (coauthor Lyford-Pike) in order to ensure a high degree of anatomical accuracy of the resulting mouth animation.  #@NEW_LINE#@#  Importantly, our model allows us to manipulate the characters mouth independently of other muscle groups.  #@NEW_LINE#@#  This allows us to focus our study directly on mouth motion, which is both one of the most important aspects for visually identifying emotion [25] and the element of face movement most easily manipulatable through surgical intervention.  #@NEW_LINE#@#  The resulting face generation model supports variations in the extent, dental show, position, angle, timing, and asymmetry of mouth motion.  #@NEW_LINE#@#  
With this tool, we created 250 ms animations of smile-like expressions, systematically manipulating spatial and temporal properties.  #@NEW_LINE#@#  We focus on 27 stimuli (see Fig 1) that were created by taking a systematic sweep of three blend shapes.  #@NEW_LINE#@#  The three blend shapes were designed to manipulate three parameters: (i) the mouth angle, (ii) the smile extent, and (iii) the amount of dental show (see Fig 2).  #@NEW_LINE#@#  Before collecting data, we designated smile 22 (high mouth angle, low smile extent, and medium dental show) as a prototypical smile for the investigation of timing asymmetries.  #@NEW_LINE#@#  To create spatiotemporal asymmetries in the smiling expressions, we manipulated the timing delay of the left side of the facial expression for smile 22.  #@NEW_LINE#@#  In addition to the symmetric versions of smile 22 previously described, we created five other versions of smile 22 with different delay asymmetries (see Fig 3).  #@NEW_LINE#@#  The delay asymmetries were created by delaying the start of the smile expression on the left side of the face.  #@NEW_LINE#@#  

Study_participants  #@NEW_LINE#@#  
We use data collected from a diverse sample of study participants over the course of three days at the 2015 Minnesota State Fair in the University of Minnesotas Driven to Discover building.  #@NEW_LINE#@#  Note that using fairgoers as the general public should provide a more representative sample compared to the WEIRD sample that is commonly used in behavioral research [27].  #@NEW_LINE#@#  Participants ranged in age from 18 to 82, and there was a bimodal age distribution for both the female and male participants with peaks at about 20 and 50 years of age, see Fig 4.  #@NEW_LINE#@#  Participants were excluded from our analyses if they (i) had consumed six or more alcoholic drinks that day, and/or (ii) did not complete the entire survey.  #@NEW_LINE#@#  Our final sample included 802 participants (510 females and 292 males) who met the inclusion criteria for our study.  #@NEW_LINE#@#  

Procedure  #@NEW_LINE#@#  
Our study protocol (including our informed consent procedure) was approved by the Institutional Review Board at the University of Minnesota.  #@NEW_LINE#@#  During the 2015 Minnesota State Fair, we asked laypersons who entered, and/or walked by, the Driven to Discover building to participate in our Smile Study.  #@NEW_LINE#@#  As compensation for participating in our study, participants were entered in a drawing to win an iPad.  #@NEW_LINE#@#  Upon verbally consenting to participate in our study, a volunteer explained to each individual that we were interested in how people perceived facial expressions of emotion.  #@NEW_LINE#@#  After the basic introduction, each participant was handed an iPad with a custom-built app, which contained a welcome screen, an information/consent screen, and an instructions screen (see Fig 5).  #@NEW_LINE#@#  After the instructions screen, participants provided some basic demographic information: age, gender, zip code, and number of alcoholic drinks they had consumed that day.  #@NEW_LINE#@#  Then each participant was shown 15 randomly sampled animations, followed by five still pictures of facial expressions of emotion.  #@NEW_LINE#@#  Note that the animations were randomly sampled from a larger population of facial expressions, but in this paper we only analyze the data corresponding to the 27 animations in Fig 1.  #@NEW_LINE#@#  
For each stimulus, participants were asked to (i) Rate the overall effectiveness as a smile using a 5-point Likert scale: Very Bad, Bad, Neutral, Good, and Very Good, (ii) Tap one or more [words] that best describe the face using a list of seven emotions: Anger, Contempt, Disgust, Fear, Happiness, Sadness, and Surprise, (iii) Indicate how much the expression is Fake (low end) versus Genuine (high end) using a continuous slider bar, and (iv) Indicate how much the expression is Creepy (low end) versus Pleasant (high end) using a continuous slider bar.  #@NEW_LINE#@#  Throughout the remainder of the paper, we refer to the ratings as (i) Effective ratings, (ii) Emotion ratings, (iii) Genuine ratings, and (iv) Pleasant ratings, respectively.  #@NEW_LINE#@#  Participants were instructed to interpret the words Effective, Fake, Genuine, Creepy, and Pleasant in a colloquial sense of these words.  #@NEW_LINE#@#  This was done to avoid biasing the participants opinions, so that the ratings could be interpreted in a colloquialinstead of a clinicalsense of these words.  #@NEW_LINE#@#  Participants were allowed to quit the study at any point.  #@NEW_LINE#@#  

Data_analysis  #@NEW_LINE#@#  


Results  #@NEW_LINE#@#  
Spatial_properties  #@NEW_LINE#@#  
The AIC and BIC values for the fit models are given in Table 2.  #@NEW_LINE#@#  Note that both the AIC and BIC select Model 1 (from Table 1) as the optimal model for each of the three response variables.  #@NEW_LINE#@#  This implies that the perception of a smile involves a three-way interaction between the mouth angle, the smile extent, and the amount of dental show displayed in the expression.  #@NEW_LINE#@#  To quantify the model fit, we calculated the model coefficient of multiple determination (i.e., R-squared) without (R2) and with () the estimated random effect  in the prediction.  #@NEW_LINE#@#  We define R2 (or ) as the squared correlation between the response variable and the fitted values without (or with) the random effects included.  #@NEW_LINE#@#  In the leftmost columns of Table 3, we display the R-squared values from the optimal model, along with the estimated variance components.  #@NEW_LINE#@#  Table 3 reveals that the fixed-effects terms in the model explain about 10% of the variation in the response variables (i.e., ), whereas the model explains about 40% of the variation in the response variables with the random effects included (i.e., ).  #@NEW_LINE#@#  
We plot the SSANOVA model predictions (i.e., estimated effect functions) for the optimal model in Fig 6.  #@NEW_LINE#@#  The main effect functions for age (Fig 6, top left) reveal that there is quadratic trend such that younger and older participants give slightly lower ratings; however, the confidence intervals on the age effect functions are rather wide and the trend is not significantly different from zero for two of the three response variables.  #@NEW_LINE#@#  Similarly, we see little to no effect of gender (Fig 6, top middle) or the number of alcoholic drinks (Fig 6, top right).  #@NEW_LINE#@#  In contrast, the smile effect function (Fig 6, bottom) reveals that (i) aside from the extreme smiles with high angle and high extent, the ratings of the three response variables are rather similar within each smile, and (ii) there are significant differences between the ratings across the 27 smiles.  #@NEW_LINE#@#  
To obtain a better understanding of the three-way interaction effect, Fig 7 plots the smile effect as a function of three factors (angle, extent, dental show).  #@NEW_LINE#@#  This plot reveals that there is a sweet spot of parameters (particularly mouth angle and smile extent) that results in the most successful smiles.  #@NEW_LINE#@#  The highest rated smiles were those with low to medium extents in combination with medium to high angles.  #@NEW_LINE#@#  Using the parameter definitions in Fig 2, successful smiles have mouth angles of about 1317Â° and smile extents of about 5562% the interpupillary distance (IPD).  #@NEW_LINE#@#  However, as is evident from Figs 6 and 7, the best smiles represent a diverse collection of different combinations of facial parameters.  #@NEW_LINE#@#  This reveals that, although there is an optimal window of parameters, there is not a single path to a successful smile.  #@NEW_LINE#@#  

Fig 7 also reveals that there are particular combinations of the smile parameters that result in unsuccessful smiles.  #@NEW_LINE#@#  One interesting finding was how low the ratings were for smiles with extreme angles.  #@NEW_LINE#@#  Another interesting finding is that the effect of dental show on the smile ratings differs depending on the angle-extent combination of the smile.  #@NEW_LINE#@#  For smiles that have smaller angle-extent values, displaying low or medium dental show is better than displaying high dental show.  #@NEW_LINE#@#  In contrast, for smiles with medium to large angle-extent combinations, displaying high dental show is better.  #@NEW_LINE#@#  This point is illustrated in Fig 8.  #@NEW_LINE#@#  However, for smiles with angle-extent combinations that are too large (i.e., smiles 21, 24, 27), increasing dental show decreases smile quality.  #@NEW_LINE#@#  
To understand which emotions were perceived from each smile, Fig 9 plots the percentage of participants who selected each of the seven emotions for each of the 27 smiles.  #@NEW_LINE#@#  From the top subplot of Fig 9, it is evident that the emotion Happy was selected most oftenwhich was expected.  #@NEW_LINE#@#  To better visualize which non-happy emotions were perceived from the smiles, the bottom subplot of Fig 9 shows the percentage of participants who selected the six non-happy emotions.  #@NEW_LINE#@#  This plot reveals that (i) Contempt is the most frequently perceived non-happy emotion, (ii) participants tended to perceive Contempt from a variety of different types of smiles, and (iii) smiles with a combination of low angle and low extent showed the largest percentages of Contempt ratings.  #@NEW_LINE#@#  

Temporal_properties  #@NEW_LINE#@#  
The fit statistics for the SSANOVA models fit to the asymmetric smiles are given in the rightmost columns of Table 3.  #@NEW_LINE#@#  Note that the models explained about 4% of the data variation at the aggregate level and about 60% of the variation at the individual level.  #@NEW_LINE#@#  The SSANOVA model predictions (i.e., effect functions) are plotted in Fig 10.  #@NEW_LINE#@#  In this case, we see that there is a trend such that older participants provide higher ratings (Fig 10, top left); however, the confidence intervals are wide, and the trend is insignificant for two of the three predictors.  #@NEW_LINE#@#  Similar to the previous model, there is no significant gender effect (Fig 10, top middle) or drinking effect (Fig 10, top right).  #@NEW_LINE#@#  The interesting result from this model is plotted in the bottom portion of Fig 10.  #@NEW_LINE#@#  We find that having a slight asymmetry (25100 ms) increases the smile ratings by a significant amount compared to having a perfectly symmetric smile.  #@NEW_LINE#@#  However, a delay asymmetry of 125 ms or more resulted in reduced smile ratings, which decreased almost linearly with the delay asymmetry in the range of 100200 ms. At the largest delay asymmetry (200 ms), the expected smile ratings were about 0.09 units below the symmetric smile ratings.  #@NEW_LINE#@#  


Discussion  #@NEW_LINE#@#  
Our results shed new light on how people perceive dynamic smile expressions.  #@NEW_LINE#@#  Using an anatomically-realistic 3D facial tool, we determined which spatial (angle, extent, dental show) and temporal (delay asymmetry) smile parameters were judged to be successful by a large sample of participants.  #@NEW_LINE#@#  Most importantly, our results allow us to both dispel and confirm commonly held beliefs in the surgical community, which are currently guiding medical practice.  #@NEW_LINE#@#  Our result regarding the optimal window (or sweet spot) of smile extent contradicts the principle that more is always better with respect to smile extent.  #@NEW_LINE#@#  Consequently, using absolute smile extent (or excursion) as a primary outcome measureas is currently done in practice [14, 43]is inappropriate.  #@NEW_LINE#@#  Instead, clinicians should use both mouth angle and smile extent as outcome measures because an effective smile requires a balance of both.  #@NEW_LINE#@#  
Among medical professionals, there is a debate about the importance of showing teeth during smiling, with some believing it to be of paramount importance while others trivialize its role.  #@NEW_LINE#@#  Our finding that dental show significantly influences the perception of a smile clarifies this debate.  #@NEW_LINE#@#  Specifically, the degree of dental show can have negative or positive effects: increasing dental show can decrease smile quality (for low angle-extent smiles), increase smile quality (for high angle-extent smiles), or have little influence on smile quality (for medium angle-extent smiles).  #@NEW_LINE#@#  Thus, the interaction between dental show and the angle-extent parameters confirms the idea that individuals with limited facial movement should be encouraged to form closed-mouth smiles (see Fig 8).  #@NEW_LINE#@#  Our results reveal that forming open-mouth smiles with small angles/extents can produce unintended perceptions of the expression, e.g., contempt or fear instead of happiness.  #@NEW_LINE#@#  
Our finding that small timing asymmetries can increase smile quality may seem counter-intuitive, in light of past research revealing that people tend to prefer symmetric faces [44, 45].  #@NEW_LINE#@#  However, this result is consistent with principles of smile design in which dynamic symmetry (i.e., being very similar but not identical) allows for a more vital, dynamic, unique and natural smile compared to static symmetry (i.e., mirror image), see [46, pg.  #@NEW_LINE#@#  230].  #@NEW_LINE#@#  Furthermore, this finding is consistent with some research which has found that slightly asymmetric faces are preferred over perfectly symmetric faces [4749].  #@NEW_LINE#@#  Our results suggest that this preference relates to the perception of the genuineness and pleasantness of the smile expression, such that slight timing asymmetries are viewed as more genuine/pleasant (see Fig 10).  #@NEW_LINE#@#  
Our discovery of the threshold at which delay asymmetries become detrimental to smile quality (i.e., 125 ms) provides a helpful benchmark for clinicians and therapists.  #@NEW_LINE#@#  This finding compliments past research which has found that emotional cues can be perceived within 100200 ms of encountering an image of a face [4, 5].  #@NEW_LINE#@#  The smile is successful long as the left-right smile onset symmetry remains within 125 ms.  #@NEW_LINE#@#  Beyond 125 ms, delay asymmetries have a noteworthy negative effect such that a 200 ms delay asymmetry results in an expected 0.09 unit decrease in smile ratings.  #@NEW_LINE#@#  Note that this decrease is a medium effect size with respect to psychological standards [50]: defining , we have that  for effectiveness,  for genuine, and  for pleasant.  #@NEW_LINE#@#  Furthermore, the difference between the ratings with a 75 ms versus a 200 ms delay is a medium-large effect size by typical psychological standards: defining , we have that  for effectiveness,  for genuine, and  for pleasant.  #@NEW_LINE#@#  It is interesting to note that modifying only the dynamic symmetry can have such a noticeable effect on how the smile is perceived.  #@NEW_LINE#@#  
In summary, our findings complement the literature on the dynamics of facial expressions of emotion [15, 25].  #@NEW_LINE#@#  Similar to past studies [1618], we have found that computer generated models of facial expressions can be a useful tool for systematically studying how people perceive facial expressions of emotion.  #@NEW_LINE#@#  Our results agree with past literature that has found dynamic (spatiotemporal) aspects of facial expressions to be important to their perception [1924].  #@NEW_LINE#@#  In particular, we found that a successful smile consists of (i) an optimal window of mouth angle and smile extent, (ii) the correct amount of dental show for the given angle-extent combination, and (iii) dynamic symmetry such that the left and right sides of the mouth are temporally synced within 125 ms. Consequently, our results extend the literature by providing spatiotemporal benchmarks of a successful smile with respect to clinically meaningful parameters.  #@NEW_LINE#@#  

Conclusion  #@NEW_LINE#@#  
Our study looked at how dynamic (spatiotemporal) properties of mouth movement relate to perceptions of facial expressions generated by a 3D computer model.  #@NEW_LINE#@#  We found that a successful smile involves an intricate balance of mouth angle, smile extent, and dental show in combination with dynamic spatiotemporal timing.  #@NEW_LINE#@#  Future research should encompass more combinations of angle, extent, dental show, and timing parameters, in order to develop a more complete spatiotemporal understanding of how the interplay between these elements affects individuals perceptions of the smile trajectory.  #@NEW_LINE#@#  Also, future studies could consider manipulating additional facial features (e.g., orbicularis oculi contraction) to create a more diverse set of facial expressions.  #@NEW_LINE#@#  Additionally, 3D cameras could be used to create scans of people smiling to enable the data-driven generation of emotional expressions, replacing the artist-created blend shapes approach used in our study [26, 51, 52].  #@NEW_LINE#@#  Such an approach could be useful for fine-tuning the smile stimuli used in this study, which have the limitation of being artist-generated.  #@NEW_LINE#@#  Furthermore, 3D cameras could be used to study timing asymmetries in a more diverse sample of facial expressions, which would be useful for examining the robustness of our timing asymmetry effect.  #@NEW_LINE#@#  Note that our results regarding timing asymmetries have the limitation of coming from a single smile expression (i.e., smile 22).  #@NEW_LINE#@#  Another useful extension of our study would be to examine how a large sample of participants perceive a variety of other facial expressions of emotion, e.g., surprise, anger, fear, or sadness.  #@NEW_LINE#@#  Finally, the integration of biologic measurements (e.g., eye-tracking or electroencephalography) could provide useful data about the perception of dynamic facial expressions.  #@NEW_LINE#@#  

Supporting_information  #@NEW_LINE#@#  
S1_Dataset_Smile_ratings  #@NEW_LINE#@#  
Data and R code to reproduce results.  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pone.0179708.s001  #@NEW_LINE#@#  
(ZIP)  #@NEW_LINE#@#  

S1_Video_Smile_videos  #@NEW_LINE#@#  
Smile animations (stimuli) used in paper.  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pone.0179708.s002  #@NEW_LINE#@#  
(ZIP)  #@NEW_LINE#@#  


Acknowledgments  #@NEW_LINE#@#  
Data were collected at the University of Minnesotas Driven to Discover Building at the 2015 Minnesota State Fair.  #@NEW_LINE#@#  The authors thank Moses Adeagbo, Heidi Johng, Alec Nyce, and Rochelle Widmer for aiding in the data collection and development of this study.  #@NEW_LINE#@#  

Author_Contributions  #@NEW_LINE#@#  


Conceptualization: NEH SJG SL-P.  #@NEW_LINE#@#  
Data curation: NEH NES MRR SJG.  #@NEW_LINE#@#  
Formal analysis: NEH NES MRR SJG.  #@NEW_LINE#@#  
Funding acquisition: NEH SJG SL-P.  #@NEW_LINE#@#  
Investigation: NEH NES MRR SJG SL-P.  #@NEW_LINE#@#  
Methodology: NEH NES MRR SJG SL-P.  #@NEW_LINE#@#  
Project administration: SL-P.  #@NEW_LINE#@#  
Resources: NEH SJG SL-P.  #@NEW_LINE#@#  
Software: NEH NES MRR SJG.  #@NEW_LINE#@#  
Supervision: S.L.-P.  #@NEW_LINE#@#  
Validation: N.E.H.  #@NEW_LINE#@#  S.J.G.  #@NEW_LINE#@#  S.L.-P.  #@NEW_LINE#@#  
Visualization: NEH NES MRR SJG SL-P.  #@NEW_LINE#@#  
Writing  original draft: NEH SJG SL-P.  #@NEW_LINE#@#  
Writing  review & editing: NEH NES MRR SJG SL-P.  #@NEW_LINE#@#  



References  #@NEW_LINE#@#  



