article id="http://dx.doi.org/10.1371/journal.pcbi.1005232"  #@NEW_LINE#@#  
title  #@NEW_LINE#@#  
Personalized glucose forecasting for type 2 diabetes using data assimilation  #@NEW_LINE#@#  

Abstract  #@NEW_LINE#@#  
Type 2 diabetes leads to premature death and reduced quality of life for 8% of Americans.  #@NEW_LINE#@#  Nutrition management is critical to maintaining glycemic control, yet it is difficult to achieve due to the high individual differences in glycemic response to nutrition.  #@NEW_LINE#@#  Anticipating glycemic impact of different meals can be challenging not only for individuals with diabetes, but also for expert diabetes educators.  #@NEW_LINE#@#  Personalized computational models that can accurately forecast an impact of a given meal on an individuals blood glucose levels can serve as the engine for a new generation of decision support tools for individuals with diabetes.  #@NEW_LINE#@#  However, to be useful in practice, these computational engines need to generate accurate forecasts based on limited datasets consistent with typical self-monitoring practices of individuals with type 2 diabetes.  #@NEW_LINE#@#  This paper uses three forecasting machines: (i) data assimilation, a technique borrowed from atmospheric physics and engineering that uses Bayesian modeling to infuse data with human knowledge represented in a mechanistic model, to generate real-time, personalized, adaptable glucose forecasts; (ii) model averaging of data assimilation output; and (iii) dynamical Gaussian process model regression.  #@NEW_LINE#@#  The proposed data assimilation machine, the primary focus of the paper, uses a modified dual unscented Kalman filter to estimate states and parameters, personalizing the mechanistic models.  #@NEW_LINE#@#  Model selection is used to make a personalized model selection for the individual and their measurement characteristics.  #@NEW_LINE#@#  The data assimilation forecasts are empirically evaluated against actual postprandial glucose measurements captured by individuals with type 2 diabetes, and against predictions generated by experienced diabetes educators after reviewing a set of historical nutritional records and glucose measurements for the same individual.  #@NEW_LINE#@#  The evaluation suggests that the data assimilation forecasts compare well with specific glucose measurements and match or exceed in accuracy expert forecasts.  #@NEW_LINE#@#  We conclude by examining ways to present predictions as forecast-derived range quantities and evaluate the comparative advantages of these ranges.  #@NEW_LINE#@#  

Author_summary  #@NEW_LINE#@#  
Type 2 diabetes is a devastating disease that requires constant patient self-management of glucose, insulin, nutrition and exercise.  #@NEW_LINE#@#  Nevertheless, glucose and insulin dynamics are complicated, nonstationary, nonlinear, and individual-dependent, making self-management of diabetes a complex task.  #@NEW_LINE#@#  To help alleviate some of the difficulty for patients, we develop a method for personalized, real-time, glucose forecasting based on nutrition.  #@NEW_LINE#@#  Specifically, we create and evaluate the computational machinery based on both Gaussian process models and data assimilation that leverages the physiologic knowledge of two mechanistic models to produce a personalized, nutrition-based glucose forecast for individuals with type 2 diabetes in real time that is robust to sparse data and nonstationary patients.  #@NEW_LINE#@#  Our computational engine was conceived to be of potential use for diabetes self-management.  #@NEW_LINE#@#  

Citation: Albers DJ, Levine M, Gluckman B, Ginsberg H, Hripcsak G, Mamykina L (2017) Personalized glucose forecasting for type 2 diabetes using data assimilation.  #@NEW_LINE#@#  PLoS Comput Biol 13(4):  #@NEW_LINE#@#  
           e1005232.  #@NEW_LINE#@#  

        https://doi.org/10.1371/journal.pcbi.1005232  #@NEW_LINE#@#  
Editor: Feilim Mac Gabhann,  #@NEW_LINE#@#  
Johns Hopkins University, UNITED STATES  #@NEW_LINE#@#  

Received: May 3, 2016; Accepted: October 31, 2016; Published:  April 27, 2017  #@NEW_LINE#@#  
Copyright:  Â© 2017 Albers et al.  #@NEW_LINE#@#  This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.  #@NEW_LINE#@#  
Data Availability: A de-identified version of the data used in this study, including all glucose finger stick data and carbohydrate estimates for meals, are available on PhysioNet under the project titled "Glucose and Nutrition Forecasting: Small.  #@NEW_LINE#@#  
Funding: GH, ML, and DJA are supported by a grant from the National Library of Medicine LM006910.  #@NEW_LINE#@#  LM, DJA and ML are supported by a grant from the Robert Wood Johnson Foundation RWJF 73070.  #@NEW_LINE#@#  LM is supported by a grant from the National Institute of Diabetes and Digestive Kidney diseases R01DK090372.  #@NEW_LINE#@#  
Competing interests:  The authors have declared that no competing interests exist.  #@NEW_LINE#@#  
Introduction  #@NEW_LINE#@#  
One promise of data science is the application of elegant solutions to new and important problems.  #@NEW_LINE#@#  In this way, personal health care can be seen as a prediction challenge: Identifying the disease the patient has contractedestimating the current state, forecasting the disease progression under different interventionsestimating the evolution of the state, and therapyoptimization of feedback to achieve target state.  #@NEW_LINE#@#  The ability to predict outcomes is important in selection of treatment.  #@NEW_LINE#@#  It is also important for self-management of chronic diseases, as it can help individuals to select the most beneficial self-management strategies and improve their health.  #@NEW_LINE#@#  The increase in data related to individuals behaviors and health biomarkers opens an unprecedented opportunity to use computational and data science methods to predict health outcomes based on basic physiological knowledge and individuals historical records.  #@NEW_LINE#@#  However, to be useful in the real world, such methods need to generate accurate and actionable predictions based on realistic datasets that are consistent with current standards for health monitoring.  #@NEW_LINE#@#  
Data assimilation (DA) [1], an application of filtering theory [2], pairs mechanistic models with data via Bayesian statistics to create a forecast.  #@NEW_LINE#@#  It has been applied or deployed successfully in fields including atmospheric physics and meteorology [3, 4], engineering [5], statistics and computer science [6, 7], and, in a more limited way, biomedicine [8].  #@NEW_LINE#@#  The power of DA is in its ability to incorporate human knowledge into a forecast; in contrast to the more traditional machine learning approaches, DA with mechanistic models does not require extensive datasets and can be personalized and adapted quickly by estimating mechanistic model parameters.  #@NEW_LINE#@#  As a result, such models can arrive at an accurate forecast with data that are fewer, more sporadic, or incomplete.  #@NEW_LINE#@#  The use of DA and control theory in medicine is relatively rare and has been applied in limited situations where data are collected in highly controlled data-rich environments.  #@NEW_LINE#@#  Examples include algorithms in implantable defibrillators and pacemakers to cope with irregular heartbeats [913], model construction and fitting for prostate cancer treatment [14], epidemiology [15], and the artificial beta-cell or pancreas project designed to manage insulin and glucose for individuals with type 1 diabetes [8, 1620].  #@NEW_LINE#@#  
Here we focus on DA for uses related to type 2 diabetes.  #@NEW_LINE#@#  Diabetes mellitus is a high-impact disease.  #@NEW_LINE#@#  In 2012, 8.3% of all Americans and 25% of Americans over the age of 65 had diabetes.  #@NEW_LINE#@#  It is the 7th leading cause of death in the United States, and costs associated with this disease amount to $176 billion in direct medical costs and $69 billion in reduced productivity in 2012.  #@NEW_LINE#@#  Type 1 diabetes is an autoimmune disease that destroys pancreatic beta cells and typically renders the body unable to produce insulin.  #@NEW_LINE#@#  Type 1 accounts for 5% of patients with diabetes.  #@NEW_LINE#@#  The remaining 95% of diabetic patients have type 2 diabetes [21], a disease with complex causes (cf.  #@NEW_LINE#@#  Fig 1 of [22]) where the individual remains capable of producing insulin but has elevated glucose levels.  #@NEW_LINE#@#  
The main approach to diabetes management is maintaining blood glucose within ranges considered safe.  #@NEW_LINE#@#  For diabetes patients, such maintenance is done through a combination of nutrition management, physical activity, and medication.  #@NEW_LINE#@#  Hemoglobin A1c (HbA1c), a physiologic measurement that correlates to a three-month average of blood glucose [23], is a clinical indication commonly used to evaluate diabetes management.  #@NEW_LINE#@#  Elevated HbA1c values above 8% lead to elevated mortality [24], while individuals with HbA1c in the near normal range of 66.5% have improved outcomes [25, 26].  #@NEW_LINE#@#  These observations have led to the clinical goal of reducing HbA1c to near normal levels of 67% [25, 26] when possible, and maintaining below 8% in nearly all circumstances.  #@NEW_LINE#@#  From the perspective of self-management, HbA1c normality serves as a long-term goal for patients, but has little practical utility in guiding individuals daily choices.  #@NEW_LINE#@#  Instead, individuals with diabetes self-monitor daily blood glucose readings; higher frequency of self-monitoring of glucose has been associated with better glycemic control and improved clinical outcomes [2729].  #@NEW_LINE#@#  The current recommended frequency of glucose self-monitoring for individuals on intensive insulin regimens is 610 times daily; however, no clear guidelines are available for individuals who use basal insulin or oral agents [30].  #@NEW_LINE#@#  
Nutrition-based glucose management is hard to achieve because it is difficult to understand the impact of foods on glucose levels on a meal-by-meal basis [22, 25, 26, 31].  #@NEW_LINE#@#  Glucose-insulin dynamics are high-dimensional, nonlinear, oscillatory, noisy, multi-scale, and dependent on many personal and demographic factors [22].  #@NEW_LINE#@#  Studies have demonstrated great variability in individuals glycemic response to meals with identical nutritional composition [31].  #@NEW_LINE#@#  Anticipating the impact of different meals on ones blood glucose levels is challenging for both individuals with diabetes and diabetes educators [32].  #@NEW_LINE#@#  This personal diversity and forecasting difficulty has led the American Diabetes Association to recommend personalized treatment [33].  #@NEW_LINE#@#  There is a clear need for tools and mechanisms that assist individuals with diabetes in understanding and predicting the impact of their nutritional choices on glucose levels and identifying approaches to regulating nutrition to minimize its glycemic impact.  #@NEW_LINE#@#  
The method requirements to implement personalized forecasting for type 2 diabetes (diabetes will refer to type 2 diabetes unless otherwise noted) glucose management differ from data-rich applications because diabetes data are collected primarily by patients and are sparse, irregularly measured, and noisy.  #@NEW_LINE#@#  A recent study examining fluctuations in glucose levels for non-diabetics in response to nutrition, physical activity, and sleep established feasibility of utilizing machine learning methods when high density data on glucose levels is available through continuous glucose monitoring [31].  #@NEW_LINE#@#  However, because continuous glucose monitoring continues to be out of reach for the vast majority of individuals with diabetes, these data-dense methods are not likely to lead to practical solutions in the near future.  #@NEW_LINE#@#  Because of this gap, we focus on forecasting glucose in scenarios consistent with common self-monitoring practices of individuals with diabetes.  #@NEW_LINE#@#  We extend DA to clinical settings that lack tight monitoring and are subject to the constraints of collecting data in real-world clinical situations where the data are complex, irregularly sampled, and biased [34].  #@NEW_LINE#@#  
Glucose prediction in the context of diabetes has been studied by researchers across many disciplines, and has resulted in a diversity of data-driven approaches for personalized glucose forecasting [35, 36].  #@NEW_LINE#@#  These efforts have attempted different tasks (e.g.  #@NEW_LINE#@#  prediction of hypoglycemia [3739], glucose control [36, 4045], and physiologic inference [41, 4649]), and have taken a variety of approaches to identifying suitable models of a diabetics glucose system (e.g.  #@NEW_LINE#@#  nonlinear Weiner model [40, 41, 50], neural networks [42], probabilistic models [38], and mechanistic systems of ordinary differential equations (ODEs) [48, 49]).  #@NEW_LINE#@#  Many of the desired prediction tasks have been approached by wrapping the aforementioned models in different predictive algorithms and inference schemes (e.g.  #@NEW_LINE#@#  stochastic filters [44], PI controllers [45, 51], Gaussian process models [52], fuzzy logic [45], and many other machine learning methods [36, 37, 39, 53]).  #@NEW_LINE#@#  These studies have paved the way towards personalized interventions for people with diabetes, but most studies fail to show their applicability in settings where data are restricted to those with realistic qualities.  #@NEW_LINE#@#  
A number of recent studies have begun to focus more on this point of realistic applicability.  #@NEW_LINE#@#  Zitar and Al-Jabali demonstrated that neural networks could be constructed, based on mechanistic ODEs, to fit a large real-world data set of type 2 diabetics, but lacks sensitivity to nutrition, making the approach less useful for personalized nutritional adjustments [42].  #@NEW_LINE#@#  Beverlin et al., on the other hand, demonstrated that glucose predictions can be generated with low error and high correlation by fitting a nonlinear Weiner box model to four patients with type 2 diabetes [40, 41].  #@NEW_LINE#@#  However, their model was trained with glucose data sampled every 5 minutes by an implantable sensor, which is neither used nor recommended for the majority of people with type 2 diabetes.  #@NEW_LINE#@#  Barazandegan et al.  #@NEW_LINE#@#  proposed the use of online sequential Monte Carlo estimation using a mechanistic model of glucose-insulin dynamics in response to nutrition developed by Vahadi et al., and demonstrated that sequential importance resampling particle filter can be used for accurate individualized forecasting, even in the presence of missing and noisy data [44, 46, 48].  #@NEW_LINE#@#  However, this work was based entirely on simulated data, rather than free-living biological data.  #@NEW_LINE#@#  The research presented here aims to bridge the gap in the literature between proposed methods for personalized glucose forecasting and evaluation of those methods on real-world data.  #@NEW_LINE#@#  We fit a mechanistic model of type 2 diabetes glucose dynamics ([49]) using a simple data assimilation strategy for sequential estimation (unscented Kalman filter [54]), and demonstrate the efficacy of this approach in 3 individuals with type 2 diabetes and 2 individuals without diabetes who only used a smart phone application to capture pre and post-meal glucose readings and descriptions of their meals.  #@NEW_LINE#@#  
The goal of the research presented here is to generate personalized, accurate, and actionable predictions of glucose in response to nutrition that can assist individuals with diabetes in making quantitatively informed nutritional choices.  #@NEW_LINE#@#  Our solution uses DA to translate the systems physiology knowledge of glucose-insulin dynamics encoded in mechanistic models into a clinical context to create personalized modeling engines capable of generating nutrition-based, post-meal glucose and HbA1c forecasts in real time.  #@NEW_LINE#@#  These forecasts would then be integrated into mobile applications such as the one developed by Mamykina et al.  #@NEW_LINE#@#  [32].  #@NEW_LINE#@#  To make the information useful for individuals with diabetes, these forecasts must: (i) use the minimally invasive data that diabetes patients collect in routine care, up to a maximum of 610 measurements a day, (ii) personalize to the individual and adapt to changes in behavior and health-state, (iii) work in real time, and (iv) be accurate enough to produce a forecast that can differentiate glucose values that correspond to between 0.52% differences in HbA1c values.  #@NEW_LINE#@#  
Our solution is constructed and evaluated in eight steps.  #@NEW_LINE#@#  The data assimilation-based solution is developed and internally evaluated in the inital five steps.  #@NEW_LINE#@#  Then we show how the DA methodology can potentially be generalized using model averaging in step six, compare the DA against non-personalized versions of itself and with machine learning-based forecasting in step seven, and then demonstrate how the DA output could be translated into a more useful form in step eight.  #@NEW_LINE#@#  In more detail: First, we develop the DA framework within the context of diabetes.  #@NEW_LINE#@#  Second, we show that the DA can generate a personalized forecast using data collected routinely by individuals with diabetes.  #@NEW_LINE#@#  Third, the DA predictions are shown to have similar and sometimes higher correlation with measured postprandial glucose levels than predictions generated by Certified Diabetes Educators who rely on their extensive knowledge and experience, and whose predictions, from the perspective of the patient trying to estimate the glycemic impact of their meal choices, represents the current clinical gold standard prediction.  #@NEW_LINE#@#  Fourth, we show that the DA will not only adapt to the individual, but will also adjust with minimal data when the individual changes behavior quickly.  #@NEW_LINE#@#  Fifth, because there is no single model that will provide the best forecast in all situations, we use statistical model selection [5557] to pick the best model for each individual given their data capture habits and the employed DA strategies.  #@NEW_LINE#@#  Sixth, armed with the individual model performance results and motivated by achieving the most robust and accurate possible forecast, we show how model averaging techniques can be used to improve model forecast performance.  #@NEW_LINE#@#  Seventh, to demonstrate the impact of tracking states and parameters on a forecast and to contrast the mechanism-based DAs with more traditional machine learning techniques, we generate forecasts using DAs with the state and parameter filters turned off in parallel with a dynamic Gaussian process model.  #@NEW_LINE#@#  And eighth, we take initial steps towards establishing glucose level forecast accuracy benchmarks for individuals with diabetes by examining accuracy of individual forecasts generated using DA over a period of time relevant for self-management.  #@NEW_LINE#@#  
Roadmap for the rest of the paper.  #@NEW_LINE#@#  This paper is not the least complex and parts of it can be read independently of other parts.  #@NEW_LINE#@#  To help make reading the paper easier, we are including a descriptive outline of the paper.  #@NEW_LINE#@#  The methods section has five components: (i) DA, the mechanistic models, and basic model selection and evaluation tools, (ii) DA-based model-forecast averaging, (iii) dynamical Gaussian process models, (iv) the study designs and data we use in the paper, and (iv) validation methods for the DA and its forecasts.  #@NEW_LINE#@#  The results section has seven components: (i) DA-based glucose state estimation and convergence, (ii) a comparison between DA-based postprandial glucose forecasts and certified diabetes educator-based postprandial glucose forecasts, (iii) personalization of models though DA-based parameter estimation, (iv) model selection and evaluation, (v) model averaging, (vi) a comparison between the Gaussian process model forecasts and the DA where sub-filters, e.g., state and parameter filters, are turned off, and (vii) a consideration of the potential impact of a clinical intervention.  #@NEW_LINE#@#  The discussion section has two large components: (i) a summary of our results and related discussions, and (ii) a more broad discussion of issues related to applying DA in clinical and biological contexts.  #@NEW_LINE#@#  Many of the results and discussion sections can be read relatively independently assuming the reader understands the relevant methods introduced in the methods section.  #@NEW_LINE#@#  

Materials_and_methods  #@NEW_LINE#@#  
Development_of_the_data_assimilation_framework_with_two_endocrine_models_relevant_for_diabetes  #@NEW_LINE#@#  
Data assimilation (DA) is a data science machine that unifies models with data to reconstruct the model state and provide forecasts.  #@NEW_LINE#@#  Crudely, DA is a sophisticated interpolation and forecasting scheme.  #@NEW_LINE#@#  We focus on the use of mechanistic models that represent human understanding of the system dynamics, although versions also exist for unsupervised models as well.  #@NEW_LINE#@#  Our objectives here are to reconstruct the state of the endocrine system relevant to glucose-insulin dynamics regulation from the sporadic blood-glucose measurements clinically expected from a patient with diabetes.  #@NEW_LINE#@#  A detailed explanation of the methods we use can be found in S1 Appendix.  #@NEW_LINE#@#  
Concretely, the objective of a DA filter is to reconstruct and predict state xk of a system from noisy, sparse measurements yk, where k indexes time.  #@NEW_LINE#@#  Inherent in this process is assumed uncertainty in how well the state xk is known.  #@NEW_LINE#@#  Therefore a distribution of state is assumed and tracked.  #@NEW_LINE#@#  Because of the combination of the nonlinear, high-dimensional dynamics of the endocrine models and the sparsity of the data, we utilize a variant of an unscented Kalman filter (UKF) or Bayesian sigma point processor [7, 5861] for DA.  #@NEW_LINE#@#  Critical in our implementation are the capacities to accommodate sparsely and non-periodically acquired data appropriate for diabetic monitoring and non-stationary system parameters consistent with changes in patient behavior and physiology.  #@NEW_LINE#@#  

Model_averaging  #@NEW_LINE#@#  
The model averaged output quantity, , is estimated from a set of models fi, a set of continuous and potentially nonlinear functions that translate the model output into a -compatible form.  #@NEW_LINE#@#  Here g is the mean of the posterior distribution or the mean of the sigma points output by the DAs, via an optimized weighted sum:  #@NEW_LINE#@#  
(4)  #@NEW_LINE#@#  
where we assume M models and positive weights wi that sum to one, or .  #@NEW_LINE#@#  Due to this constraint, M  1 weights wi are sufficient to determine ; thus, with two models, we seek the optimal value of w1.  #@NEW_LINE#@#  There are many methods for selecting the optimal weights where optimal is defined by the set of weights such that  minimizes a model evaluation metric, three of which are introduced in the sections that follow.  #@NEW_LINE#@#  

Gaussian_process_regression_model  #@NEW_LINE#@#  
Some previous studies have used non-mechanism-based machine learning methodology to forecast post meal glucose.  #@NEW_LINE#@#  We do not use continuous glucose monitor data here and therefore cannot directly compare the DA output with what has been done in other studies, but we can use machine learning methods on our data and compare those forecasts with the DA forecasts to some degree.  #@NEW_LINE#@#  In the same spirit as was used with the UKFwe use standard methods and do not optimize hyperparameters to simulate what is possible in the high-throughput settingwe use a Gaussian Process Model Regression (GPMR) [65] modified for next step prediction [66].  #@NEW_LINE#@#  The theory for these regressions is well-known, so we will not discuss it in detail here.  #@NEW_LINE#@#  However, it is necessary for us to explain the details of the methodology we use for training, forecasting, and evaluating the GPMR.  #@NEW_LINE#@#  The regression takes two input variables, pre-meal glucose defined as a glucose measurement within 15 minutes of eating and the carbohydrate content of a meal.  #@NEW_LINE#@#  The output is the post meal glucose forecast that is independent of time and represents a post-meal glucose value.  #@NEW_LINE#@#  The GPMR will be trained initially on 50 meals; when new meals are encountered, a post-meal glucose forecast will be made, and then that meal will be incorporated into the training set for the next, yet to be observed, meal.  #@NEW_LINE#@#  In this way, the training set increases with every meal while the post-meal glucose forecast is always made for a single meal as it would be encountered in real time.  #@NEW_LINE#@#  The post-meal glucose forecast is compared with the first post-meal glucose measurement on a time interval of 45180 minutes after the meal.  #@NEW_LINE#@#  Because of these data constraints, the GPMR cannot be used to forecast pre-meal glucose, glucose at random times, or glucose without a meal and without a pre- and post-meal glucose measurement, and therefore there are fewer meals available to forecast.  #@NEW_LINE#@#  Because of these practical issues, the GPMR uses a different training set than the UKF schemes.  #@NEW_LINE#@#  As we have mentioned earlier, there is a lot of space for improving both GPMR and UKF or more broadly DA inference machines, a topic we will address in the discussion.  #@NEW_LINE#@#  
There are two details worth mentioning related to DAs with mechanism-based models and GPMR.  #@NEW_LINE#@#  First, both the DAs and the GPMR we use in the paper are Gaussian processes in the formal sense [67], but their primary dynamics are generated by very different processes, one mechanistic with a random component and one has only a random component.  #@NEW_LINE#@#  Second, the DAs generate continuous forecasts and therefore can forecast all glucose measurements regardless of the data available, making them flexible and robust to missing or partially missing data.  #@NEW_LINE#@#  

Study_design  #@NEW_LINE#@#  
In this study, we create the mechanistic model-based glucose forecasting machinery with data assimilation that provides real-time, personalized glucose forecasts that adapt to and track an individual patients changing state over time, and we validate it on longitudinal time series from five patients.  #@NEW_LINE#@#  We demonstrate that the DA forecasts, subject to real world constraints of sparse, noisy, real patient-collected data, personalize, adapt over time, and track quickly relative to postprandial blood glucose readings captured by the participants, such that the DA machinery can be used as the engine in a diabetes self-intervention application.  #@NEW_LINE#@#  Through the DA we translate physiologic knowledge directly to an individual to help them make disease self-management decisions.  #@NEW_LINE#@#  The DA we use is designed to track, forecast, and correct states and parameters of nonstationary systems in real time without the luxury of an explicit training set.  #@NEW_LINE#@#  Instead, the algorithm is adjusted to each patient, using the prior data for training and predicting unseen subsequent data points.  #@NEW_LINE#@#  Similar methodology was used in the DA model averaging construction.  #@NEW_LINE#@#  The GPMR construction differs as is demanded by the details of the GPMR computation.  #@NEW_LINE#@#  It is initialized with a training set of 50 meals when possible and then forecasts post-meal glucose given carbohydrate and pre-meal glucose measurements.  #@NEW_LINE#@#  For the DA, we use two independent mechanistic-model-based DAs to forecast because different individuals, or individuals in changing states, may require different mechanistic models as forecasting engines.  #@NEW_LINE#@#  We also develop the model selection criteria for evaluating and selecting the most accurate model, given a prediction task, in the results section.  #@NEW_LINE#@#  
The five independent datasets chosen represent typical self-monitoring scenarios for individuals with type 2 diabetes from three different diabetes studies.  #@NEW_LINE#@#  The first three participants have type 2 diabetes while the last two participants do not.  #@NEW_LINE#@#  In addition, we compared accuracy of the DA predictions with accuracy of predictions generated by certified diabetes educators, whose judgement often represents the gold standard with respect to human-based post-meal glucose prediction and is used to arrive at nutritional therapy recommendations for individuals with diabetes.  #@NEW_LINE#@#  We compare the DA forecast to that of the diabetes educators to demonstrate that the DA can perform as well as the most skilled humans.  #@NEW_LINE#@#  This evaluation is important because it compares human and machine accuracy for the prediction task that people with type 2 diabetes must perform every time they consume food.  #@NEW_LINE#@#  We chose an N of five because our goal is to understand and validate the personalized performance of the DA in depth.  #@NEW_LINE#@#  In this way we performed five independent experiments and compare their outcomes.  #@NEW_LINE#@#  We have two layers of inclusion/exclusion requirements, those for this paper and those of the original studies where the data originate; the details of the data collection for the diabetes studies are discussed in paragraphs below and the related citations.  #@NEW_LINE#@#  For this study we chose five individuals with the following characteristics:  #@NEW_LINE#@#  
Their data are shown in more detail in Table 1.  #@NEW_LINE#@#  We did not exclude data outliers because we want to show the DA performance under realistic, real-time circumstances.  #@NEW_LINE#@#  Each participant is treated as an independent experimental set-up, and the number of glucose measurements represent the number of experiments per experimental set-up.  #@NEW_LINE#@#  

Evaluation__validation__generalizability_and_usability_of_the_model-based_UKF_construction  #@NEW_LINE#@#  
In this paper we address the validation or evaluation, generalizability, and usability of the mechanistic model-based UKF forecasts.  #@NEW_LINE#@#  The UKF is a prediction/correction machine, meaning that it uses the most recent data to make predictions until the new data point is encountered, at which point the prediction is evaluated and the UKF states and parameters are corrected.  #@NEW_LINE#@#  This implies a different validation and generalizability situation from what is often encountered in biomedical studies.  #@NEW_LINE#@#  
Validation of the UKF, because of the prediction/correction construction, requires each person to be treated as an independent experimental set-up.  #@NEW_LINE#@#  Therefore, sample size for validation is the number of meals per person.  #@NEW_LINE#@#  For validation purposes, we conducted five experiments on different experimental set-ups where the experiments range from having sample sizes of 24 to 520.  #@NEW_LINE#@#  We validate the model/UKF combination using mean squared error, linear correlation, and a KL-divergence-based distance on a per-person/experiment basis.  #@NEW_LINE#@#  Moreover, we compare expert nutritionist forecasts to model forecasts, but this is not so much a validation of the UKF as it is a quantitative validation of the challenges that individuals with type 2 diabetes face in the course of their self management and a demonstration of a way the UKF-based forecast could potentially help individuals with type 2 diabers.  #@NEW_LINE#@#  The nutritionist is the gold standard baseline for human-based prediction of the glycemic impact of a chosen meal.  #@NEW_LINE#@#  Therefore, when we compare the nutritionist forecasts with the model-based forecasts we are comparing machine-forecasting to human-based forecasting to demonstrate the potential usefulness of the UKF framework.  #@NEW_LINE#@#  It is important to understand that the nutritionist is not the gold standard by which we evaluate the UKF, the glucose measurements serve that purpose.  #@NEW_LINE#@#  
Generalizability moves beyond validation of the UKF and addresses the likelihood, for a population, that the UKF equipped with one or another of the mechanistic models would be applicable.  #@NEW_LINE#@#  Relative to generalizability to the population of human beings, we have a sample size of five including three individuals with type 2 diabetes and two individuals without type 2 diabetes.  #@NEW_LINE#@#  While these five individuals are rather diverse and have different disease states with only five people we cannot claim that the models or the UKF will generalize to all people.  #@NEW_LINE#@#  However, this is not the purpose of this paper; before justifying imposing the UKF on a larger population, it is important to validate and understand, on an individual level, the accuracy of the UKF forecast and how well the UKF can personalize to different individuals.  #@NEW_LINE#@#  
Usability moves beyond validation but in a different direction than generalizability.  #@NEW_LINE#@#  Usability addresses the usefulness, to a person with type 2 diabetes, of the UKF output.  #@NEW_LINE#@#  To address usability one must address the consistency of the accuracy of the UKF output and the nature of the presentation of the UKF output.  #@NEW_LINE#@#  For example, the usability is often quantified based on the impact of the presentation of the forecast on the patient state as the study progresses.  #@NEW_LINE#@#  The retrospective nature of this paper and the limited population size prevent us from addressing usability in earnest here.  #@NEW_LINE#@#  What we do instead is investigate the building blocks for a potential diabetes management intervention.  #@NEW_LINE#@#  We do this to help put the UKF forecasts in a more clinical context and justify that the UKF forecasts can be of potential use for a diabetes intervention.  #@NEW_LINE#@#  But a first set in any usability study is to understand the accuracy of the information given to the usersthis paper was written with this step in mind.  #@NEW_LINE#@#  


Results  #@NEW_LINE#@#  
Glucose_state_estimation_using_data_assimilation  #@NEW_LINE#@#  
The visualization of the personalized glucose forecasts from both models, the continuous glucose imputation, and the convergence to better forecasts as more data are accumulated for participant 1 is shown in Fig 1.  #@NEW_LINE#@#  To demonstrate the model forecasts at the beginning and how they improve over time, we have included plots of forecasts for days 15 and 2025.  #@NEW_LINE#@#  In these plots, the DA receives data as if it were collected in real time, makes forecasts, corrects the glucose trajectory and model parameters according to each individual measurement, and then repeats this process.  #@NEW_LINE#@#  There are four features in Fig 1 of note.  #@NEW_LINE#@#  First, the models seem to converge over time and provide better forecasts.  #@NEW_LINE#@#  Second, the models appear to generate accurate forecasts.  #@NEW_LINE#@#  Third, the glucose dynamics of both model-based DA outputs lie within the range of measured glucose values.  #@NEW_LINE#@#  And fourth, the off-data model dynamics differ substantially between models despite the similar accuracy of both model forecasts.  #@NEW_LINE#@#  
While the DA output looks reasonable in Fig 1, it is important to quantify the goodness of fit.  #@NEW_LINE#@#  Fig 2 shows the mean squared error between the real-time DA forecasts and the measurements over time for both models.  #@NEW_LINE#@#  There are three notable features in Fig 2 First, the models converge after about 50 measurementsat 8 glucose measurements per day, convergence is achieved with about one weeks worth of data.  #@NEW_LINE#@#  Second, while the ultradian model does better initially relative to the mean squared error, the models provide approximately equally accurate forecasts given two to three weeks of data.  #@NEW_LINE#@#  And third, the mean squared error improves over timemost of the point-wise mass of the mean squared error lies below the mean, implying that much of the post-convergence error is generated by a few large-error forecasts.  #@NEW_LINE#@#  

Comparing_DA_glucose_forecasting_to_Certified_Diabetes_Educator_forecasts  #@NEW_LINE#@#  
We have established that the DAs converge and generate accurate forecasts; the next question is to compare predictions generated by the model with those generated by human experts, here Certified Diabetes Educators.  #@NEW_LINE#@#  To be clear, we are not using the diabetes educators as a gold standard for the DA but rather as a gold standard for human-based forecasting of the glycemic impact of individual meals.  #@NEW_LINE#@#  There are two reasons why we want to compare diabetes educators to the UKF forecasts.  #@NEW_LINE#@#  First, while human-based glycemic forecast evaluation is not the topic of this paper, it is important that we demonstrate the difficulty of the task we are asking of patients, every time they eat, by showing how well a highly educated/trained individual performs at the task of forecasting glycemic impact of a given food intake.  #@NEW_LINE#@#  Second, we need to have a proof in principle from a clinical standpoint that the DA predictions of by-meal glycemic impact were comparable or better than to what a trained diabetes counselor would forecast for individual meals; i.e., demonstrating that the DA can do as well as the best trained humans at forecasting glycemic impact.  #@NEW_LINE#@#  By doing this we can establish a proof in principle, from the clinical standpoint, that with little tuning the DA could automatically match or beat the state of the art in clinical care.  #@NEW_LINE#@#  
Before we present the results, there are some important caveats related to this analysis and comparison.  #@NEW_LINE#@#  First, comparison we present here is relatively underpowered.  #@NEW_LINE#@#  We compare only 14 experimentsmealsfor three experimental set-ups, participant ones glucose forecasts and measurements one hour and two hours post-meal and participant twos glucose forecasts and measurements two hours post meal.  #@NEW_LINE#@#  Recall that the dataset for participant 1 typically had two postprandial blood glucose measurements, while the dataset for participant 2 typically had only one postprandial blood glucose measurement.  #@NEW_LINE#@#  Because of this, we do not have one-hour correlations for participant 2.  #@NEW_LINE#@#  Participant 3 did not have enough data to calculate statistically significant one or two-hour post meal correlations between measured and forecasted glucose.  #@NEW_LINE#@#  Some of the quantities we would like to calculate are not resolvable with these data, but we can make enough good estimates to make useful and important comparisons.  #@NEW_LINE#@#  Second, the educators generally estimate the glycemic impact of a meal not post-meal glucose at a precise time, making pin-point forecasts an unusual task for them.  #@NEW_LINE#@#  Because of this, we might expect the linear correlationthe quantity that captures accuracy the estimate of the meanto be well forecast by the diabetes educators while the MSEthe quantity that captures point-wise forecast errorto be more difficult for the diabetes educators.  #@NEW_LINE#@#  Third, the DAs are continuous models and generate a glucose forecast every minute regardless of the data present.  #@NEW_LINE#@#  The continuous glucose dynamics are oscillatorylike that of an oscillator driven by nutrition and damped by insulin and metabolismso the model output can differ by 100 mg/dl within a 15 minute interval over the first two hours after food has been consumed.  #@NEW_LINE#@#  The oscillations driven by meal consumption for both models can be seen in Figs.  #@NEW_LINE#@#  1 in S2 and S3 Appendices respectively.  #@NEW_LINE#@#  Because of this, we might expect that the model forecasts would have high MSE and low linear correlation with measurements at one hour post-meal and low MSE and high linear correlation at two hours post-meal.  #@NEW_LINE#@#  

Table 2 has the results of the comparison between the diabetes educator post-meal glucose forecast accuracy and the DA post-meal glucose forecast accuracy.  #@NEW_LINE#@#  The primary conclusion is that the DA forecasts compare favorably to the forecasts of the certified diabetes educators given the same data.  #@NEW_LINE#@#  This conclusion can be reached though five observations drawn from Table 2.  #@NEW_LINE#@#  First, the DAs do not have good point-wise accuracy one hour after a meal as expected.  #@NEW_LINE#@#  Second the DAs have better point-wise accuracy two hours after the meal in comparison with the point-wise accuracy of the diabetes educators, as expected.  #@NEW_LINE#@#  Third, the diabetes educators have the same point-wise accuracy at one and two hours after the meal, but their point-wise accuracy is higher than we had expected.  #@NEW_LINE#@#  Fourth it is difficult to compare the linear correlationthe estimate of the post-meal meanbetween the post-meal measurement and forecasts of the diabetes educators and the DAs for participant one because of data sparsity.  #@NEW_LINE#@#  And fifth, the linear correlations between the between the two hour post-meal measurement and forecasts of the diabetes educators and the DAs for for participant two were roughly comparable.  #@NEW_LINE#@#  
It is, of course, relatively easy for us to improve the DA performance such that the DAs will outperform the diabetes educators if we tune the DA hyper-parameters by hand to a given individual.  #@NEW_LINE#@#  But, one of the key points of this paper is to demonstrate that the DAs, with no human intervention, can automatically generate a glucose forecast that is of similar or better quality as a highly trained human expert.  #@NEW_LINE#@#  Given the likelihood that knowledge of Certified Diabetes Educators greatly exceeds knowledge of a typical individual with diabetes, it is likely that DA-generated predictions will be more accurate than those generated by individuals with diabetes and therefore of potential help to individuals with type 2 diabetes.  #@NEW_LINE#@#  

DA-based_personalized_medicine__Model_personalization_and_adaptation  #@NEW_LINE#@#  
People, their metabolism, their behavior, and their presentation of diabetes are both personal and dynamic.  #@NEW_LINE#@#  To be useful, the DA must both personalize to the individual and adapt to changes in the individual over time.  #@NEW_LINE#@#  The models forecast glucose based on three features: glucose measurements, carbohydrate measurements, and model state defined by the parameter settings.  #@NEW_LINE#@#  While glucose and carbohydrate dynamics change on fast time scales (order minutes to hours), the baseline endocrine state and the model parameters that represent it are slower moving variables with dynamics evolving on the order of days to months.  #@NEW_LINE#@#  
We estimate three parameters for each model every time a new measurement is encountered.  #@NEW_LINE#@#  The ultradian model parameters we personalize include the exchange rate for insulin between remote and plasma compartments, E, the volume of insulin distribution in the plasma, V1, and the time constant for plasma insulin degradation t1, all of which affect the glucose mean and variance [69].  #@NEW_LINE#@#  The meal model parameters that we estimate include the insulin volume, VI, and the glucose kinetics parameters k1 and k2, both of which are related to the severity of diabetes and also affect the glucose mean and variance.  #@NEW_LINE#@#  
To initially visualize and evaluate the adaptation of the models, we will first focus on HbA1c as a long-term clinically-motivated proxy for glucose.  #@NEW_LINE#@#  The relationship between HbA1c and glucose is understood physiologically and is well documented empirically [23]HbA1c is linearly related to the mean glucose value averaged over the previous 90 days.  #@NEW_LINE#@#  The time period necessary to estimate HbA1c can be considerably shorter than 90 days, and the lower bound on the length of this time window is unknown.  #@NEW_LINE#@#  The problem of predicting HbA1c can then be framed as the challenge of determining the true mean glucose over such a time window.  #@NEW_LINE#@#  However, because we are focusing on opportunities for real time decision support, it is of greater interest to relate short term behaviors to long-term outcomes.  #@NEW_LINE#@#  As such, we explore methods for computing accurate daily glucose averages that can be easily converted to proportional HbA1c values.  #@NEW_LINE#@#  Concretely, these daily HbA1c estimates represent the expected HbA1c outcome for a patient if they were to maintain that days mean glucose over 90 days.  #@NEW_LINE#@#  In Fig 3, we evaluate daily HbA1c estimates by computing daily mean glucose levels for patient-recorded measurements and continuous off-data model forecasts.  #@NEW_LINE#@#  

Fig 3 shows the carbohydrate consumption of participants 1 and 2, daily HbA1c estimates, and real HbA1c measurements.  #@NEW_LINE#@#  Embedded in Fig 3 are five important results.  #@NEW_LINE#@#  First, by observing the changes in carbohydrates, we can verify that participant 1 consistently reduced their carbohydrate intake over the course of the study.  #@NEW_LINE#@#  Participant 2 also reduced their carbohydrate consumption, but not consistently, and by the end of the study their mean glucose was trending upwards.  #@NEW_LINE#@#  Participant 1s HbA1c changed in the course of the study, potentially due to the change in carbohydrate consumption.  #@NEW_LINE#@#  For participant 2, the single HbA1c collected during the study is consistent with the HbA1c estimates from both glucose measurements and forecasts.  #@NEW_LINE#@#  Second, the results make evident the challenges related to estimating HbA1c on a time scale of days from only glucose measurements taken in the course of self-management.  #@NEW_LINE#@#  The culprit is sparsity of measurements; estimating a reliable and low-variance mean given 38 numbers taken from an oscillatory signal is non-trivial.  #@NEW_LINE#@#  Importantly, mean glucose may be more stable across days than is made apparent to patients by infrequent measurements.  #@NEW_LINE#@#  
Third, the smoothed, fast time scale HbA1c estimate computed from the continuous glucose forecasts provided by the DA is more reliable, stable, and accurate than an estimate based on glucose measurements collected with frequencies consistent with common practices of individuals with diabetes.  #@NEW_LINE#@#  It is possible that continuous or carefully selected glucose readings could be as good or better than DA smoothing, however, neither of these approaches are feasible for the majority of individuals with T2D.  #@NEW_LINE#@#  For participant 1, DA is able to overcome the data-quality deficit: the ultradian model forecasts participant 1s second HbA1c measurement nearly perfectly.  #@NEW_LINE#@#  The models track mean glucose well and are able to provide real-time forecasts that give us the ability to compute real-time smoothed mean glucose and HbA1c estimates, thus providing both a short-term glucose forecast and a long-term forecast of meals impact on glycemic control.  #@NEW_LINE#@#  However, which of these model outputs are most useful for self-management remains an open question.  #@NEW_LINE#@#  Fourth, both models track the HbA1c with expected accuracy.  #@NEW_LINE#@#  The glucose-measurement estimated HbA1c is well tracked by a smoothed DA-based HbA1c estimate.  #@NEW_LINE#@#  Fifth, the DA-based HbA1c forecasts seem to have a roughly 5-8 day lag behind nutrition as can best be observed in the plot of participant 2s HbA1c and carbohydrate dynamics.  #@NEW_LINE#@#  The carbohydrate and HbA1c trends are roughly 5 days out of phase.  #@NEW_LINE#@#  This suggests that, given the constraints imposed by real-world frequency of data collection, the DAs change the basic endocrine state on the order of 58 days, or 50 measurements.  #@NEW_LINE#@#  This rate of adaptation is consistent with the initial convergence rate that required roughly 58 days or 50 measurements to converge.  #@NEW_LINE#@#  However, the key point is that the DAs continuously adapt and correct the endocrine basic state, improving forecasting accuracy, on the order of 50 measurements or 58 days, a speed that is likely fast enough to be useful in the context of diabetes self-management.  #@NEW_LINE#@#  
The convergence and adaptation of the model parameters estimated by the DA are shown in Fig 4.  #@NEW_LINE#@#  This plot shows the evolution of three estimated parameters as new measurements are encountered.  #@NEW_LINE#@#  There are four notable results in these figures.  #@NEW_LINE#@#  First, the model parameters generally converge to a curve with much slower or no change after approximately 50 measurementsthis is consistent with the convergence rates we observed in the mean squared error in Fig 2.  #@NEW_LINE#@#  Second, both models adapt continuously to participant 1 who consistently decreased carbohydrate intake.  #@NEW_LINE#@#  The models show the adaptation to this change primarily in a single parameterthe exchange rate for insulin between remote and plasma compartments, E, of the ultradian model and the estimated insulin volume, VI, of the meal model.  #@NEW_LINE#@#  Third, participant 3 did not have enough measurements to converge to a personalized state, but it is clear that the convergence was underway because several of the parameters appear to be leveling off to a constant state, following a qualitatively similar path as participant 2s parameter convergence.  #@NEW_LINE#@#  This helps establish a measurement constraint, participant 3 has only 24 measurements and while the DA can issue better forecasts than a linear regression, the DA appears to need closer to 50 measurements to personalize.  #@NEW_LINE#@#  And fourth, the participants were all in relatively different health states and the models evolved through distinctly different health states, providing evidence of personalization.  #@NEW_LINE#@#  

Model_selection__Identifying_the_best_model_to_drive_the_DA_for_a_person_and_circumstance  #@NEW_LINE#@#  
We have no first principles type understanding of systems physiology, instead mechanistic models are constructed using empirical observation and stylized facts as is often done in economics [70].  #@NEW_LINE#@#  Our object of study here, the endocrine system, is a complex, high dimensional physiologic system that depends on spatial scales from the molecular to the societal and time scales from microseconds to decades.  #@NEW_LINE#@#  We do not know which model with what components will most accurately represent a given person in a given circumstance.  #@NEW_LINE#@#  Because of this, to achieve accurate personalized forecast of glucose, it is important to include several different models and to develop a methodology for selecting the most useful model for a given set of circumstances, or employ a model-averaging scheme [5557].  #@NEW_LINE#@#  For simplicity, here we have restricted our choices to two mechanistic models and focus on model selection, rather than model averaging.  #@NEW_LINE#@#  
There is neither an objectively best model nor an objectively best model evaluation methodology [55].  #@NEW_LINE#@#  To present a holistic picture and triangulate an understanding of what the different models do well and how they differ, we use four model selection techniques.  #@NEW_LINE#@#  Our first model evaluationmean glucoseis likely the most intuitive, but not the most robust or accurate evaluation metric.  #@NEW_LINE#@#  Second, as previously discussed and seen in Fig 2, we use the pointwise mean squared error.  #@NEW_LINE#@#  Third, we use an information criterion techniquethe Kullback-Leibler (KL)-divergence between the kernel density estimate of the real measurements and the kernel density estimate of the forecasts [64].  #@NEW_LINE#@#  The fourth method we use to evaluate model performance is the linear correlation between DA forecasts and measured glucose values.  #@NEW_LINE#@#  
Forecast means in Table 3 show measured and DA-based mean glucose estimates for all five participants.  #@NEW_LINE#@#  While all models produce reasonable results, the ultradian glucose forecasts generate the most accurate mean glucose estimates.  #@NEW_LINE#@#  This result is surprising because the ultradian model is the simpler model and does not reproduce the measured glucose distribution as accurately as the meal model, as seen in Fig 5.  #@NEW_LINE#@#  The accuracy of the continuous off-data forecast of the ultradian model is important because the continuous forecasts are produced every few minutes, generating enough glucose values to render an accurate short term, e.g., 24 hour HbA1c forecast that can illustrate long-term impact of immediate nutritional choices, an option that is usually unavailable.  #@NEW_LINE#@#  
The KL-divergence is a measure of the distance between two probability density functionshere the difference between glucose probability density function estimates.  #@NEW_LINE#@#  Small KL-divergence implies the graphs of the two probability density functions are similar, indicating good model estimates.  #@NEW_LINE#@#  Visual intuition of the KL-divergence can be gleaned from Fig 5 that shows the kernel density estimates of the glucose measurements and forecasts for participant 1.  #@NEW_LINE#@#  Formally, the KL divergence is defined by:  #@NEW_LINE#@#  
(8)  #@NEW_LINE#@#  
where p and q are probability densities and  is the Lebesgue measure.  #@NEW_LINE#@#  The KL-divergence between p and q is interpreted as the information lost when p is approximated by q.  #@NEW_LINE#@#  For us, the interpretation becomes more complex because of measurement biasesbiases caused by the missing values and the noise associated with them due to the self-monitoring data collection process for an individual with diabetes.  #@NEW_LINE#@#  Here we compare the kernel density estimates of real, sparse measurements, DA forecasts restricted to times where there are real glucose measurements, and continuous DA-based imputation of glucose.  #@NEW_LINE#@#  The differences between the kernel density estimates for these quantities shown in Fig 5 may be nontrivial.  #@NEW_LINE#@#  Without continuous blood glucose monitoring, the true continuous distribution of glucose is unknown.  #@NEW_LINE#@#  Nevertheless, combining the information in Table 3 with what we observe in Fig 5 suggests that while the measurements and model outputs all generate a similar mean glucose value, the graphs of the kernel density estimates are qualitatively different.  #@NEW_LINE#@#  Moreover, it does appear that the kernel density estimate of the meal model based forecasts most closely resembles the kernel density estimate of the measured glucose values, while the mean of the ultradian model forecasts is closer to the mean of measured glucose.  #@NEW_LINE#@#  This highlights why there is not an optimal method for model selection.  #@NEW_LINE#@#  Contrasting different evaluation metrics, different integrals, allows for a clearer picture of how well the models are performing.  #@NEW_LINE#@#  
The full summary of the model evaluation shown in Table 3 presents a consistent vision.  #@NEW_LINE#@#  For participants 1, 2, 4 and 5 the ultradian model generally matches or outperforms the meal model, except when it comes to the linear correlation between forecast and measurement likely because the ultradian model represents an estimate of the mean.  #@NEW_LINE#@#  For participant 3, the ultradian model outperforms the meal model.  #@NEW_LINE#@#  This implies that even in our simplified situation, there is clearly no best model for all patients and model evaluation metrics, although the ultradian model does appear to be the better choice unless estimation of a distributional or linear correlation based quantity is the desired goal.  #@NEW_LINE#@#  Most importantly, both models perform quite well, implying that any choice have the potential to yield accurate forecasts.  #@NEW_LINE#@#  

Model_averagingBlending_models_to_achieve_a_more_accurate_forecast  #@NEW_LINE#@#  

The_impacts_of_mechanisms_and_filtering_analysis  #@NEW_LINE#@#  
We have shown that the DA converges given our clinical data constraints, the DA personalizes to an individual, and that averaging models can help produce a better forecast.  #@NEW_LINE#@#  To demonstrate the impact and necessity of the state and parameter filters and the mechanistic UKF set up as well as comparing the DA to standard non-mechanism-based forecasting machines, we must turn off the various filters and implement different forecasting machinery and observe how the forecasts accuracy changes.  #@NEW_LINE#@#  Table 5 shows the mean forecasted glucose and the mean square error and KL-divergence between the measured and the forecast glucose values.  #@NEW_LINE#@#  This table prompts two comparisonsthe DA with different filters included and the dual UKF DA with the GPMR.  #@NEW_LINE#@#  
To demonstrate the impacts of the state and parameter filters, we consider three DAs: (i) no-filterwe set the initial glucose and nutrition to be the latest measurement and run it forward to the next measurement; (ii) state-filterwere we run the UKF state filter but not the parameter filter, and (iii) the dual UKF state and parameter filters.  #@NEW_LINE#@#  In this setting the mean for the state and no-filter is mostly determined by the initial parameter settings because the parameters are not changed.  #@NEW_LINE#@#  There are four results of note.  #@NEW_LINE#@#  First, the effects of the different filtering constructions was consistent between models.  #@NEW_LINE#@#  Second, we did not observe much difference between the state filter and the no-filter DAs.  #@NEW_LINE#@#  Third, the dual filter, which includes parameter correction, provides a substantial improvement over the no-filter and the state-only filters with respect to the accuracy of the mean and pointwise mean square error.  #@NEW_LINE#@#  Fourth, the KL-divergence is usually minimized by the no-filter and the state filter, but none of the KL-divergences are particularly large.  #@NEW_LINE#@#  
Comparing the dual UKF powered by mechanistic models with a non-mechanistic machine is difficult to make completely equitable or unbiased, largely because the natural input and training sets for the two different models are so different.  #@NEW_LINE#@#  The UKF really track and re-aligns the mechanistic model using whatever data are currently available, substituting model data for any missing data maintaining a continuous-time model of the system where as the GPMR is a regression that takes a full input vector and maps it to an output vector.  #@NEW_LINE#@#  It is possible that with a continuous glucose monitor data such a comparison between the GPMR and the UKF would be more equitable, but this is not the situation we address in this paper.  #@NEW_LINE#@#  The dual UKF forecasts were generated as previously discussed.  #@NEW_LINE#@#  The GPMR forecasts were generated using data for meals restricted to the situation where there is a pre-meal glucose taken within 15 minutes of eating the meal, a post-meal glucose taken within 45180 minutes of the beginning of the mealthe most recent post-meal glucose is always used as the post-meal glucoseand of course carbohydrate estimates.  #@NEW_LINE#@#  The GPRM is trained on the first 50 meals and when it encounters a new meal, it makes a forecast based on the pre-meal glucose and carbohydrate estimates, and then that meal is added to the training set.  #@NEW_LINE#@#  The GPMR can be very sensitive to nonstationarityparticipants 1 and 2 in particularand when it is, the its accuracy is highly sensitive to the training window length.  #@NEW_LINE#@#  We chose the training and forecasting procedure to minimize the dependence on the training window size.  #@NEW_LINE#@#  Relative to this construction we have four key results.  #@NEW_LINE#@#  First, the GPMR generally overestimates the mean glucose by a substantial amount, expect for participant 4.  #@NEW_LINE#@#  Second, the GPMR has a competitive MSEis is usually the second lowest compared with the dual UKF using the ultradian model.  #@NEW_LINE#@#  The KL divergence for the GPMR is low and usually preforms about as well as the no-filter DA, likely because both the processes are Gaussian without too much imposed mechanistic structure.  #@NEW_LINE#@#  And fourth, if we instead use a fixed window size, unless the meal training window is shortless than 50 mealsthe GPMR performs considerably more poorly than any of the dual UKF implementations.  #@NEW_LINE#@#  We will save more analysis of the GPMR for another time.  #@NEW_LINE#@#  

Building_blocks_for_a_diabetes_management_intervention  #@NEW_LINE#@#  
The underlying expectation of this research is that generating accurate predictions of individuals glycemic response to particular meals can inform their decision-making and improve their glycemic control.  #@NEW_LINE#@#  Our final objective, then, is to examine different ways of communicating predictions generated with DA that provide actionable information and convey different degrees of confidence and precision.  #@NEW_LINE#@#  The natural output of the model is a continuous forecast with a potentially indefinite endpoint, and there exist many different ways to present this information to individuals with diabetes in order to inform their decisions.  #@NEW_LINE#@#  Previous research suggested that visualizing these projections in a graphical way, as a continuous curve, can lead to improved understanding [71].  #@NEW_LINE#@#  Another possibility is to condense this continuous forecast into a projected range that communicates to the individual the anticipated glycemic impact of the meal.  #@NEW_LINE#@#  While traditional static error terms communicate average forecast uncertainty, they do not convey higher-order information (e.g.  #@NEW_LINE#@#  extreme values, velocity) that are relevant to understanding the case-specific effects of nutrition.  #@NEW_LINE#@#  Instead, we consider different ways of generating interval predictions that reflect expected fluctuations in blood glucose and have the added benefit of communicating forecast uncertainty.  #@NEW_LINE#@#  Specifically, we examine three dynamic forecast intervals derived from continuous DA output and characterize them by comparing the magnitude of their bounds with an empirical estimate of the confidence interval they represent.  #@NEW_LINE#@#  
The left plot of Fig 8 shows the last 25 glucose measurements and three model-derived dynamic bounds on a moving window, Â± standard deviation, Â± variance, and range (maximum minus minimum) of the continuous ultradian model-based glucose forecast 30120 minutes after a meal.  #@NEW_LINE#@#  The right plot shows percentage of measurements captured by those boundaries.  #@NEW_LINE#@#  Recalling Fig 1, the ultradian model has high amplitude oscillations while the meal model has limited oscillations; this dynamic difference has a profound impact on which model may provide the most useful forecast boundary.  #@NEW_LINE#@#  Generally, the ultradian model forecasts capture a higher percentage of future measurements.  #@NEW_LINE#@#  The variance is too wide to be useful for any of our participants.  #@NEW_LINE#@#  The ultradian model range provides a better balance of frequency of accuracy; the dynamic range of Â±1520 capturing 5060% of future measurements compared to standard deviation of Â±15 capturing 40% of future measurements.  #@NEW_LINE#@#  Here participant 3 is the exception with a standard deviation of Â±25 capturing 82% of future measurements.  #@NEW_LINE#@#  This difference demonstrates the complexity of translating a forecast that is a density into a quantity such as a single numberthe ideal range may have to be chosen automatically for a given person.  #@NEW_LINE#@#  These results are a proof in principle that a plausibly useful forecast range could be created.  #@NEW_LINE#@#  


Discussion  #@NEW_LINE#@#  
The broad goal of this research is to develop new ways to forecast postprandial blood glucose levels given an individuals preprandial blood glucose level and nutritional composition of a meal, particularly amount of carbohydrates.  #@NEW_LINE#@#  To achieve this goal we developed a DA and integrated it with two mechanistic endocrine models, a model averaging methodology, and a dynamical Gaussian process model regression, largely for comparison purposes.  #@NEW_LINE#@#  We can observe the DA personalizing the models by estimating model parameters for individuals in real-time with as few as 50 glucose measurements.  #@NEW_LINE#@#  We then formulated model selection to choose the right model for the individual in a way that is generalizable and allows for inclusion of additional models if necessary.  #@NEW_LINE#@#  Similarly, we constructed a model averaging methodology to demonstrate that more accurate predictions can be achieved by averaging models.  #@NEW_LINE#@#  Our reasons for selecting a DA framework were that it allows for incorporation of systems physiology knowledge into the forecast to reduce reliance on dense historical data, and to generate reliable predictions based on sparse data, consistent with existing self-monitoring guidelines and practices, typically available to individuals with diabetes.  #@NEW_LINE#@#  
We then tested the proposed models using data collected by three individuals with diabetes and two without diabetes.  #@NEW_LINE#@#  These datasets were selected because they illustrated different self-monitoring scenarios, had different unique properties, and allowed us to test the models under different sets of constraints.  #@NEW_LINE#@#  In our study, the DA: (i) estimated the data well in real time according to standard model evaluation metrics; (ii) produced forecasts that compared favorably with the forecasts of certified diabetes educators whose judgment the gold standard for devising personalized nutritional recommendations for individuals with diabetes and represents the best available human-based glucose forecasting; (iii) personalized the model to an individual and adapted as the individual changed, providing a personalized medicine approach to diabetes treatment; (iv) was integrated with model selection machinery that differentiated model types according to how they estimated the data, allowing a best model to be chosen; (v) preformed well given realistic self-monitoring data quality; (vi) had accurate output at a high enough frequency, potentially forming the basis for a self-management intervention, and (vii) could be averaged in real time to produce even more accurate forecasts.  #@NEW_LINE#@#  
An ability to accurately forecast postprandial glucose levels has a number of important clinical implications.  #@NEW_LINE#@#  There exists a considerable body of evidence showing that postprandial hyperglycemia contributes substantially to cardiovascular risks and other complications of diabetes [72], [73].  #@NEW_LINE#@#  Previous research argued that an ability to generate accurate predictions of postprandial blood glucose can enable personalized self-management interventions, for example personalized meal planning [31].  #@NEW_LINE#@#  We propose that the computational machinery described here could be applied more directly to display glucose forecasts to individuals in order to inform their nutritional choices.  #@NEW_LINE#@#  Yet communicating predictions with a degree of uncertainty in a useful way is non-trivial, as is evidenced from the extensive research on communicating weather forecasts [74].  #@NEW_LINE#@#  In the context of health and health management, the research on communicating risks and uncertainties has primarily focused on informing significant, potentially life-changing decisions, such as surgery, rather than such mundane common decisions as daily meal choices [75].  #@NEW_LINE#@#  Moreover, generating glucose forecasts in real time requires accurate macronutrient assessment of meals.  #@NEW_LINE#@#  Previous research has suggested leveraging crowdsourcing communities for generating timely and accurate nutritional assessments of meals based on these meals photographs [76].  #@NEW_LINE#@#  Still, more research is needed to identify ways to implement DA-based forecasting to facilitate nutritional decision-making in real-world settings.  #@NEW_LINE#@#  
Originally designed to guide satellites, control chemical plants and electrical grids, and forecast weather, DA has mostly been applied to data-rich situations outside of biomedicine.  #@NEW_LINE#@#  Inside the biomedical context, DA and control are used in pacemakers, to treat cancer, and to treat patients with type 1 diabetes.  #@NEW_LINE#@#  The unique advantage of DA is that it infuses data with human knowledge, thus allowing the model to quickly adapt to environmental changes, cope with highly nonlinear systems, and confront forecasting problems, all while reducing reliance on data in real time.  #@NEW_LINE#@#  This is particularly important for such complex multi-dimensional systems as the human endocrine system and blood glucose regulation.  #@NEW_LINE#@#  Previous research already established feasibility of using machine learning for forecasting individuals postprandial blood glucose levels based on nutrition, physical activity, and sleep, while incorporating individuals personal clinical and microbiome profiles [31].  #@NEW_LINE#@#  Moreover, this work showed that such predictions could be used to inform personalized nutritional interventions.  #@NEW_LINE#@#  However, because the traditional machine learning approaches do not incorporate knowledge of human physiology, they require massive amounts of relatively clean data that, in the case of diabetes, can only be generated with continuous glucose monitoring.  #@NEW_LINE#@#  Yet continuous glucose monitoring is not a recommended practice for the vast majority of individuals with diabetes, who continue to rely on infrequent blood glucose measures taken with commercial blood glucose meters.  #@NEW_LINE#@#  The DA approach is uniquely positioned to reduce the need for data and provide a viable solution with a high translational potential.  #@NEW_LINE#@#  
The DA methodology can also be used to demonstrate the difficulty of the problem-solving task facing individuals with type 2 diabetes.  #@NEW_LINE#@#  For the individuals without type 2 diabetes, the point-wise accuracy of the DA forecasts quickly converged to approximately the error present in the glucose measurementsa MSE of 250 translates to about 15 mg/dl of accuracy.  #@NEW_LINE#@#  In contrast, the point-wise predictive accuracy of the glucose forecasts for the participants with type 2 diabetes was on the order of 500approximately 22 mg/dlfor both the diabetes educators and the DA.  #@NEW_LINE#@#  This implies that people with type 2 diabetes seem to face a more difficult glycemic impact prediction task than people who do not have type 2 diabetes, as is reflected in both the diabetes educators and the DAs ability accurately forecast glucose.  #@NEW_LINE#@#  
Reaching beyond the direct clinical translation, the DA approach has the potential to forge a deeper understanding of physiology due to its dependency on mechanistic physiology for generating forecasts.  #@NEW_LINE#@#  The DA allows the ability to exchange and evaluate different mechanistic models with different mechanistic features and observe how adding or subtracting mechanistic components affects forecasts and inferences.  #@NEW_LINE#@#  In this way the DA enables causal analysis because it allows researchers to perturb the system that generates the observable data in time and observe the effectsin other words, perturb the mapping between the mechanistic models that govern the glucose-insulin dynamics [77].  #@NEW_LINE#@#  The potential of such causal and comparative analysis is apparent when observing the differences in the forecasts shown in Fig 5 and Table 3.  #@NEW_LINE#@#  Higher frequency measurements would enable further probing of what physiologic mechanisms are the most important drivers of glucose dynamics.  #@NEW_LINE#@#  Exchanging different mechanistic engines in the context of DA can promote a better understanding of the mechanisms of the generating process; this goal motivates several data-science challenges.  #@NEW_LINE#@#  Because forecasts can depend on the DA implementation, there is a need to evaluate the forecasting ability of different DAs.  #@NEW_LINE#@#  In addition, there is a need for a systematic methodology for relating models with different parameters and mechanisms to one another; if one model with few parameters is a subset of a larger model class, comparing the two only accomplishes a dimensionality reduction of parameter space, and does not probe fundamentally different physiology.  #@NEW_LINE#@#  Moreover, there is a need for an efficient means of choosing which model parameters to estimate.  #@NEW_LINE#@#  Finally, there is a need for efficient and accurate methods for patient-specific, real-time optimization of important DA hyper-parameters, such as assumed measurement and process noise.  #@NEW_LINE#@#  
By design, we restricted our data set to five differently measured, distinct individuals who were all measured relatively sparsely to delve deeply into how DA performs in a practical, patient-level diabetes setting, but this approach has limitations.  #@NEW_LINE#@#  We could not perform a population-scale analysis, nor could we evaluate which model best reproduced postprandial continuous glucose dynamics, as was done with machine learning models in [31].  #@NEW_LINE#@#  Nevertheless, we were able to show some boundaries for useful prediction and convergence (about 50 glucose measurements combined with recorded carbohydrates), and we were able to demonstrate how the knowledge embedded in the DA can make up for poor data conditions.  #@NEW_LINE#@#  Similarly, while the use of a mechanistic model and DA potentially requires substantially less data to achieve an accurate forecast, this choice narrows the ability to fit data and could exclude a good solution if the model cannot represent the physiology of the individual.  #@NEW_LINE#@#  The fact that forecasts for each individual converged to different levels of error is evidence of these person-specific model errors.  #@NEW_LINE#@#  Moreover, P3, P4, and P5 converged to mean error rates similar to the error of the glucometers used to make measurements (mean absolute forecast errors were under 15%, which is the maximum error tolerance permitted for most commercially available glucometers).  #@NEW_LINE#@#  
Our_vision_for_the_use_of_data_assimilation_in_clinical_and_biological_contexts  #@NEW_LINE#@#  

Conclusion  #@NEW_LINE#@#  
We found that the DA estimated future glucose in a personalized way and showed via model selection that different models have unique advantages, depending on the task (prediction, inference, etc.)  #@NEW_LINE#@#  and the data source (i.e.  #@NEW_LINE#@#  patient).  #@NEW_LINE#@#  There exist certain lower-bounds on data quality for DA-based forecasting, but found these constraints to be mild relative to typical self-management expectations.  #@NEW_LINE#@#  Overall, we believe that DA-based forecasting is accurate enough, frequently enough to form the basis for a self-management intervention.  #@NEW_LINE#@#  


Supporting_information  #@NEW_LINE#@#  
S1_Appendix_Dual_unscented_Kalman_filter  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pcbi.1005232.s001  #@NEW_LINE#@#  
(TEX)  #@NEW_LINE#@#  

S2_Appendix_Ultradian_endocrine_model  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pcbi.1005232.s002  #@NEW_LINE#@#  
(TEX)  #@NEW_LINE#@#  

S3_Appendix_Meal_endocrine_model  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pcbi.1005232.s003  #@NEW_LINE#@#  
(TEX)  #@NEW_LINE#@#  


Author_Contributions  #@NEW_LINE#@#  


Conceptualization: DJA ML BG HG GH LM.  #@NEW_LINE#@#  
Data curation: DJA ML LM.  #@NEW_LINE#@#  
Formal analysis: DJA ML BG GH LM.  #@NEW_LINE#@#  
Funding acquisition: GH LM DJA.  #@NEW_LINE#@#  
Investigation: LM ML DJA GH.  #@NEW_LINE#@#  
Methodology: DJA ML BG GH.  #@NEW_LINE#@#  
Project administration: DJA LM ML.  #@NEW_LINE#@#  
Resources: DJA GH LM.  #@NEW_LINE#@#  
Software: DJA ML.  #@NEW_LINE#@#  
Supervision: DJA LM.  #@NEW_LINE#@#  
Validation: DJA ML BG GH LM.  #@NEW_LINE#@#  
Visualization: DJA ML BG GH.  #@NEW_LINE#@#  
Writing  original draft: DJA.  #@NEW_LINE#@#  
Writing  review & editing: DJA ML BG HG GH LM.  #@NEW_LINE#@#  



References  #@NEW_LINE#@#  



