article id="http://dx.doi.org/10.1371/journal.pone.0180080"  #@NEW_LINE#@#  
title  #@NEW_LINE#@#  
Putting the methodological brakes on claims to measure national happiness through Twitter: Methodological limitations in social media analytics  #@NEW_LINE#@#  

Abstract  #@NEW_LINE#@#  
With the rapid global proliferation of social media, there has been growing interest in using this existing source of easily accessible big data to develop social science knowledge.  #@NEW_LINE#@#  However, amidst the big data gold rush, it is important that long-established principles of good social research are not ignored.  #@NEW_LINE#@#  This article critically evaluates Mitchell et al.s (2013) study, The Geography of Happiness: Connecting Twitter Sentiment and Expression, Demographics, and Objective Characteristics of Place, demonstrating the importance of attending to key methodological issues associated with secondary data analysis.  #@NEW_LINE#@#  

Citation: Jensen EA (2017) Putting the methodological brakes on claims to measure national happiness through Twitter: Methodological limitations in social media analytics.  #@NEW_LINE#@#  PLoS ONE 12(9):  #@NEW_LINE#@#  
           e0180080.  #@NEW_LINE#@#  

        https://doi.org/10.1371/journal.pone.0180080  #@NEW_LINE#@#  
Editor: Johan Bollen, Indiana University Bloomington, UNITED STATES  #@NEW_LINE#@#  
Received: October 12, 2014; Accepted: May 22, 2017; Published:  September 7, 2017  #@NEW_LINE#@#  
Copyright:  Â© 2017 Eric Allen Jensen.  #@NEW_LINE#@#  This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.  #@NEW_LINE#@#  
Funding: The author received no specific funding for this work.  #@NEW_LINE#@#  
Competing interests:  The author has declared that no competing interests exist.  #@NEW_LINE#@#  
How does living in urban areas relate to well-being?  #@NEW_LINE#@#  Such an undertaking is part of a general program seeking to quantify and explain the evolving cultural characterthe storiesof cities, as well as geographic places of larger and smaller scales.  #@NEW_LINE#@#  [] Our overall aim in this paper is to investigate how geographic place correlates with and potentially influences societal levels of happiness.  #@NEW_LINE#@#  (p. 1)  #@NEW_LINE#@#  
Face_validity_of_operationalization  #@NEW_LINE#@#  
Mitchell et al.  #@NEW_LINE#@#  measure the overall average happiness of people located in cities[1] as follows:  #@NEW_LINE#@#  
Thus, words were given a single score that remained static regardless of context.  #@NEW_LINE#@#  
The level of quality that could be expected from this use of the Mechanical Turk service is unclear.  #@NEW_LINE#@#  However, even if individual words have been reliably scored for this study, the use of a simple dictionary method for categorizing the inherent happiness of a tweet is clearly prone to a substantial amount of error (e.g.  #@NEW_LINE#@#  due to the use of irony, different meanings of words in different contexts, words that negate meaning such as not, etc.).  #@NEW_LINE#@#  To take the examples cited in this article by the authors, while rainbow may be most commonly used in positive sentences, it is conceivable someone might say What a terrible disappointment that season finale was: It was like finding there is no pot of gold at the end of the rainbow!.  #@NEW_LINE#@#  The word rainbow in this negative phrase would be given a very happy score based on the studys methods.  #@NEW_LINE#@#  Likewise, someone might use earthquake in a metaphorical sense, for example, Meeting Samantha was like an earthquake.  #@NEW_LINE#@#  I am in love and my entire landscape has shifted!.  #@NEW_LINE#@#  The word never is defined as sad, so an optimistic tweet saying Never say never!  #@NEW_LINE#@#  would get a doubly sad score.  #@NEW_LINE#@#  There are innumerable examples of this kind.  #@NEW_LINE#@#  Essentially, this way of ascribing sentiment to tweets using a bag of words approach is likely to be prone to error.  #@NEW_LINE#@#  Indeed, this fact is widely understood within the social scientific discipline of linguistics, where issues such as word sense disambiguation [6] and linguistic compositionality have been studied for decades [7, 8].  #@NEW_LINE#@#  
Remarkably the authors claim the lack of precision associated with this method as a badge of objectivity:  #@NEW_LINE#@#  
To check for the accuracy in the categorization of tweets as happy or sad, the likely level of error in this sentiment analysis approach could have been quantified by having human coders blind score a random selection of tweets to see how well these scores corresponded to the automated score.  #@NEW_LINE#@#  However, this type of quality control check was not conducted.  #@NEW_LINE#@#  Instead, it is merely asserted that the happiness scores for the tweets are reliable.  #@NEW_LINE#@#  These sentiment scores (with their unknown levels of error) then become the basis for all the subsequent analyses.  #@NEW_LINE#@#  
Moreover, this kind of context-free sentiment analysis is fundamentally at odds with social media-based communication, as well as much of the methodological work that has been conducted in the natural language processing field in computer science.  #@NEW_LINE#@#  People using social media can respond to ideas in unpredictable ways, drawing upon a communication backdrop that may move back and forth between online social media and offline social or professional contexts.  #@NEW_LINE#@#  The ways in which some people react online or offline may in turn influence others, who may respond either online or offline.  #@NEW_LINE#@#  This makes the online setting a hive of mutual influence in which the direct, unfiltered communication of ideas between unaffiliated and disinterested individuals is a rare scenario.  #@NEW_LINE#@#  Therefore, taking context into account in at least some manner is a basic requirement for valid identification of message sentiment on Twitter or anywhere else online.  #@NEW_LINE#@#  Natural language processing researchers account for some of the contextual issues visible online through analyses of ngrams and domain sensitive lexical resources.  #@NEW_LINE#@#  However, there is still a major research gap in understanding the relationship between online and offline behavior.  #@NEW_LINE#@#  In sum, the happiness part of the analysis in Mitchell et al.s study [1] requires a more sophisticated sentiment measure.  #@NEW_LINE#@#  

The_importance_of_a_representative_sample  #@NEW_LINE#@#  
Mitchell et al.  #@NEW_LINE#@#  analyze 10 million tweets [1], an enormous sample size to be sure.  #@NEW_LINE#@#  But as we know, large sample sizes do not necessarily equate to good or even accurate research.  #@NEW_LINE#@#  To make valid generalizations, researchers must ensure data are representative of the target population.  #@NEW_LINE#@#  
Mitchell et al.  #@NEW_LINE#@#  use only the US-based geotagged tweets [1] (approximately 1% of messages) from within Twitters garden house feed (10% of all messages).  #@NEW_LINE#@#  This means that the sample was comprised of one-tenth of one percent of all Twitter messages during the 2011 calendar year.  #@NEW_LINE#@#  While the sample size is large in absolute terms, there is no evidence provided to indicate that this small percentage of the total number of tweets is representative of the broader population of Twitter messages and users, let alone the entire population (which is mostly comprised of non-users of Twitter).  #@NEW_LINE#@#  That is, there may be systematic bias in terms of who is represented in the Twitter garden hose.  #@NEW_LINE#@#  Indeed, it has already been demonstrated that those who geotag their tweets may be systematically different than the overall Twitter population [9].  #@NEW_LINE#@#  This methodological issue has been demonstrated in the UK in two recent studies, showing a demographic gap between Twitter users and the general population [10] and furthermore between those who geotag their tweets and the general population of Twitter users [5].  #@NEW_LINE#@#  In the United States, research by Pew Research Center [11] has shown demographic gaps based on age, gender, socio-economic status, ethnicity and community type (urban, rural or suburban).  #@NEW_LINE#@#  In addition to likely biases in terms of the demographic profile of users included in the sample, there is also the possibility that people may be more likely to turn on geotagging in certain circumstances thereby introducing a further uncontrolled source of bias.  #@NEW_LINE#@#  
When researchers find themselves with easily accessible data, there is a temptation to apply those data to interesting research questions and populations, even when there are limitations in the representativeness of the sample.  #@NEW_LINE#@#  In the present case, Mitchell et al.  #@NEW_LINE#@#  have used data based on social surveys using representative sampling of states and cities, and treated it as comparable to the geotagged Twitter data from the same states and cities.  #@NEW_LINE#@#  However, the demographic characteristics of Twitter users are different from the general population in a number of ways, which are only partially understood at this point.  #@NEW_LINE#@#  For example, there is a substantial gender bias towards men, who represent 71.8% of Twitter users according to one estimate [12].  #@NEW_LINE#@#  Therefore, there is reason to believe that combining these two sources of data is problematic.  #@NEW_LINE#@#  
A further limitation is the very concept of average happiness, which is used in this study.  #@NEW_LINE#@#  Given the high likelihood of sampling bias, the presentation of average happiness scores for all fifty states is questionable.  #@NEW_LINE#@#  For these average scores to be accurate the following would have to hold true:  #@NEW_LINE#@#  
In fact, none of the above points have been established in published research literature, thereby casting doubt on the entire study and its claims.  #@NEW_LINE#@#  

Big_data_analysis_is_secondary_analysis  #@NEW_LINE#@#  
The challenges affecting the kind of big data analysis discussed in this article have long affected social scientists attempting to use existing data to develop new knowledge.  #@NEW_LINE#@#  Known in the methodological literature as secondary analysis, there are well-understood limitations affecting such research [13, 14].  #@NEW_LINE#@#  
Finally, a basic precept of statistical analysis also bears repeating: Correlation is not causation.  #@NEW_LINE#@#  We must avoid a naÃ¯ve belief in the power of large sample sizes to overcome all sources of bias or confounding variables.  #@NEW_LINE#@#  Of course, the limitations identified in this article do not mean that social media studies should all be dismissed.  #@NEW_LINE#@#  Rather, like all other social research methods, they must establish a reasonable basis for the inferences and generalizations they present.  #@NEW_LINE#@#  Such studies will be on much firmer ground if they seek to generalize to particular categories of social media users, rather than to the general population.  #@NEW_LINE#@#  Moreover, efforts to use social media data to generalize to broader offline populations would need to be underpinned by supplemental evidence in the form of surveys or other field work to show what types of sampling bias these data might be introducing.  #@NEW_LINE#@#  

Conclusion  #@NEW_LINE#@#  
As people make their way around the web, they leave all kinds of digital traces.  #@NEW_LINE#@#  These forms of data, including social media, offer the real prospect of developing useful social research insights.  #@NEW_LINE#@#  However, this essay highlights the point that the enthusiasm for accessing and analyzing these digital traces should not outpace sound methodology.  #@NEW_LINE#@#  Indeed, recent work such as the Ribeiro et al.s benchmarking analysis [15] shows greater attention to the reliability of different sentiment analysis tools.  #@NEW_LINE#@#  
Research cannot start from the assumption that speech on Twitter can be straightforwardly treated as similar to offline conversation data.  #@NEW_LINE#@#  Rather, it is possible that a variety of conversational strategies and practices are unique to Twitter (just as they would be unique to other social media sites that set different speech parameters).  #@NEW_LINE#@#  Indeed, all of the factors that affect social reality offline also play out online: power, voice, symbolic representation, identity, leadership, struggles over scarce resources and visual representations continue to exert strong influence on the web.  #@NEW_LINE#@#  This raises complexities that must be addressed before claims about happiness and its causes can be approached using tweets and correlations.  #@NEW_LINE#@#  
Vast sample sizes increase the risk of identifying specious statistically significant results.  #@NEW_LINE#@#  A deductive, hypothesis-driven approach is required in order to minimize the risk of identifying significant statistical relationships that merely reflect random sampling variation rather than real patterns in the population.  #@NEW_LINE#@#  This article argued that long-established methodological principles governing secondary analysis in the social sciences hold the keys to understanding the methodological limitations discussed.  #@NEW_LINE#@#  As has been argued previously [16], Twitter data has serious methodological challenges that are rarely addressed by those who embrace it.  #@NEW_LINE#@#  When researchers approach a data set, they need to understandand publicly account fornot only the limits of the data set, but also the limits of which questions they can ask of a data set and what interpretations are appropriate.  #@NEW_LINE#@#  

Author_Contributions  #@NEW_LINE#@#  


Conceptualization: EJ.  #@NEW_LINE#@#  
Formal analysis: EJ.  #@NEW_LINE#@#  
Investigation: EJ.  #@NEW_LINE#@#  
Methodology: EJ.  #@NEW_LINE#@#  
Project administration: EJ.  #@NEW_LINE#@#  
Resources: EJ.  #@NEW_LINE#@#  
Writing  original draft: EJ.  #@NEW_LINE#@#  
Writing  review & editing: EJ.  #@NEW_LINE#@#  



References  #@NEW_LINE#@#  



