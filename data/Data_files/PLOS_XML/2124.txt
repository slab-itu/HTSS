article id="http://dx.doi.org/10.1371/journal.pone.0191417"  #@NEW_LINE#@#  
title  #@NEW_LINE#@#  
Towards the use of similarity distances to music genre classification: A comparative study  #@NEW_LINE#@#  

Abstract  #@NEW_LINE#@#  
Music genre classification is a challenging research concept, for which open questions remain regarding classification approach, music piece representation, distances between/within genres, and so on.  #@NEW_LINE#@#  In this paper an investigation on the classification of generated music pieces is performed, based on the idea that grouping close related known pieces in different sets or clusters and then generating in an automatic way a new song which is somehow inspired in each set, the new song would be more likely to be classified as belonging to the set which inspired it, based on the same distance used to separate the clusters.  #@NEW_LINE#@#  Different music pieces representations and distances among pieces are used; obtained results are promising, and indicate the appropriateness of the used approach even in a such a subjective area as music genre classification is.  #@NEW_LINE#@#  

Citation: Goienetxea I, Martínez-Otzeta JM, Sierra B, Mendialdua I (2018) Towards the use of similarity distances to music genre classification: A comparative study.  #@NEW_LINE#@#  PLoS ONE 13(2):  #@NEW_LINE#@#  
           e0191417.  #@NEW_LINE#@#  

        https://doi.org/10.1371/journal.pone.0191417  #@NEW_LINE#@#  
Editor: Enrique Hernandez-Lemus,  #@NEW_LINE#@#  
Instituto Nacional de Medicina Genomica, MEXICO  #@NEW_LINE#@#  

Received: April 19, 2017; Accepted: January 4, 2018; Published:  February 14, 2018  #@NEW_LINE#@#  
Copyright:  © 2018 Goienetxea et al.  #@NEW_LINE#@#  This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.  #@NEW_LINE#@#  
Data Availability: All data used in this study are the property of Bertsozale Elkartea (http://www.bertsozale.eus/en?set_language=en) and are available online via their database webpage: http://bdb.bertsozale.eus/en/web/doinutegia/bilaketa.  #@NEW_LINE#@#  
Funding: This work was supported by IT900-16 Research Team from the Basque Government.  #@NEW_LINE#@#  
Competing interests:  The authors have declared that no competing interests exist.  #@NEW_LINE#@#  
Introduction  #@NEW_LINE#@#  
Automatic music classification is a topic that is getting more and more attention with the development of the multimedia technologies and the growth of available information.  #@NEW_LINE#@#  It is used in music genre classification, tune family identification or to classify tunes in geographical regions for example, and approaches that use both symbolic information and audio information have been developed [1, 2].  #@NEW_LINE#@#  
Music genre classification is an important task since genre is a descriptor that is usually used to organize large collections of music, specially in the Internet, where it is often used in search queries.  #@NEW_LINE#@#  Many different approaches have been developed to identify music genre in audio or symbolic representation, like Support Vector Machines [3, 4], similarity measures of symbolic representation [5], neural networks [6, 7] or deep learning methods [8].  #@NEW_LINE#@#  
Automatic music generation has interested people for centuries and many different algorithms have been developed since the first steps in automatic music composition, like knowledge based systems, evolutionary and other population-based methods, fractals or statistical models [9].  #@NEW_LINE#@#  
The developed methods for music generation can be classified in several categories, like stochastic methods, knowledge-based systems and artificial intelligence systems.  #@NEW_LINE#@#  Stochastic methods involve random variables and are the simplest to generate.  #@NEW_LINE#@#  Some early examples can be the Musikalisches Würfelspiel or musical dice games, like the one published in 1792 that was attributed to Mozart [10].  #@NEW_LINE#@#  
Knowledge-based systems use series of sets of rules or grammars to guide the composition of melodies, expanding high-level symbols into sequences of symbols [9].  #@NEW_LINE#@#  These grammars can be learned from a corpus of a melodies or they can be invented.  #@NEW_LINE#@#  
Statistical models have been used in computational modelling of several musical style since they are able to capture some musical features that make it possible to generate new musical sequences that reflect an explicit musical style, and they can be learned from a corpus of melodies [11].  #@NEW_LINE#@#  
In order to use statistical models for coherent music generation the intra-opus problem needs to be considered: the generated piece must contain material that repeats through the piece.  #@NEW_LINE#@#  Almost all forms of music involve repetition [12], either of pitch sequences or at some more abstract levels, and that repetition gives a sense of meaning to music [13].  #@NEW_LINE#@#  Musical cohesion is analyzed in [14], where music is compared to linguistic discourse, and it is concluded that music is composed by semantically related segments, which support the coherence of the piece.  #@NEW_LINE#@#  Describing the coherence of a piece is currently a scientific challenge, and different approaches have been developed, like the description of acoustic structure, functional structure or semiotic structure.  #@NEW_LINE#@#  Semiotic structure is the description of segments in a piece using a set of symbols, where each symbol represents a class of similar segments [15].  #@NEW_LINE#@#  
Music generation methods using a segmental structure extracted from an existing piece have been developed, to generate music in the style of the original piece, but with different melodic content, like the method developed by Collins et al [16].  #@NEW_LINE#@#  This method discovers the repeated and transposed segment on a polyphonic piece and uses it to guide the generation of a new melody, which has different notes but the same coherence as the original piece.  #@NEW_LINE#@#  
This paper presents a folk melody classification method, which is based on similarity distances of symbolic representation of music, and which is combined with an automatic generation method.  #@NEW_LINE#@#  An unsupervised classification of a folk melody corpus is made and the discovered sets are used to generate new melodies, which are then classified into the discovered clusters.  #@NEW_LINE#@#  
The chosen corpus is a collection of bertso melodies.  #@NEW_LINE#@#  Bertsolaritza or bertsolarism is the art of singing improvised songs in Basque (bertsos), respecting various melodic and rhyming patterns.  #@NEW_LINE#@#  It is defined as a sung, rhymed and metered discourse by the book The Art of Bertsolaritza: Improvised Basque Verse Singing [17].  #@NEW_LINE#@#  There is evidence of bertso singing and written bertso poem samples since the 15th century, and it is a very popular art nowadays in the Basque Country.  #@NEW_LINE#@#  
Bertsos are sung in many different occasions, like informal lunches with friends, homage ceremonies or competitions and any topic can occur in a bertso.  #@NEW_LINE#@#  Many bertsolari competitions take place every year in the Basque Country, and every four years the national championship final is held, with around 15000 people in attendance.  #@NEW_LINE#@#  
The main technical aspects of the bertso are the rhyme, meter and melody, which can be classified into traditional folk melodies (the great majority), modern melodies that coincide with one of the traditional metres and melodies that are specifically composed.  #@NEW_LINE#@#  Experts say the chosen melody for singing a bertso and the manner in which it is sung can be the key for the communicative success of the bertsolari, since the chosen melody must be able to combine with the created lyrics to transmit what the bertsolari wants to express with the bertso.  #@NEW_LINE#@#  
This paper is structured as follows; Section related work overviews the work that has been done in music classification, Section proposed approach describes the approach we propose, Sections experimental setup and experimental results present the experimental setup designed to test the method and the results obtained, and finally Section conclusions and future works presents the conclusions that have been extracted from this work.  #@NEW_LINE#@#  

Related_work  #@NEW_LINE#@#  
Several approaches have been used in the literature to deal with music classification for different tasks, like tune family identification or automatic music genre classification.  #@NEW_LINE#@#  The idea behind many of them is to obtain a representation of the analyzed music and afterwards build a model which would be able to classify the characteristics of the music treated on the approach, namely genre, structure, artist, composer, and so forth.  #@NEW_LINE#@#  
Automatic music genre classification is a task that has attracted the interest of the music community for more than two decades, and several similarity methods and machine learning techniques have been studied in the literature to deal with it.  #@NEW_LINE#@#  Kotsifakos et al.  #@NEW_LINE#@#  [5] deal with music genre classification for symbolic music, and specifically MIDI, by combining the recently proposed novel similarity measure for sequences, SMBGT, with the k-Nearest Neighbor (k-NN) classifier.  #@NEW_LINE#@#  For all MIDI songs they first extract all of their channels and then transform each channel into a sequence of 2D points, providing information for pitch and duration of their music notes.  #@NEW_LINE#@#  
Mendel and Ellis [4] present an approach based on support vector machines to classify songs based on global features.  #@NEW_LINE#@#  
Chai and Vercoe [18] worked on the classification of folk music pieces coming from different countries using monophonic melodies by means of hidden Markov models.  #@NEW_LINE#@#  In this paper the authors state that This shows that melodies of folk music do carry some statistical features to distinguish them.  #@NEW_LINE#@#  
Bergstra, J et al.  #@NEW_LINE#@#  [19] present an algorithm based on ADABOOST that predicts musical genre and artist from an audio waveform.  #@NEW_LINE#@#  
Xu et al.  #@NEW_LINE#@#  [20] propose effective algorithms to automatically classify and summarize music content.  #@NEW_LINE#@#  Support vector machines are applied to classify music into pure music and vocal music by learning from training data.  #@NEW_LINE#@#  Based on calculated features, a clustering algorithm is applied to structure the music content.  #@NEW_LINE#@#  
Fu et al.  #@NEW_LINE#@#  [21] deal with music information retrieval (MIR), which addresses the problem of querying and retrieving certain types of music from large music data set.  #@NEW_LINE#@#  
Pinquier et al.  #@NEW_LINE#@#  [22] deal with a novel approach to speech/music segmentation.  #@NEW_LINE#@#  Three original features, entropy modulation, stationary segment duration and number of segments are extracted.  #@NEW_LINE#@#  They are merged with the classical 4Hz modulation energy.  #@NEW_LINE#@#  
Zhang et al.  #@NEW_LINE#@#  [8] propose the use of computational deep learning modules for extracting invariant and discriminative audio representations which can then be used to classify music in different genres.  #@NEW_LINE#@#  
Sturn [23] argue that an evaluation of system behaviour at the level of the music is required to usefully address the fundamental problems of music genre recognition (MGR), and indeed other tasks of music information retrieval, such as autotagging.  #@NEW_LINE#@#  
A challenging open question in music classification is which music representation (i.e., audio features) and which machine learning algorithm is appropriate for a specific music classification task.  #@NEW_LINE#@#  The goal is to find a set of linear mappings from several feature spaces to the semantic space spanned by the class indicator vectors [24].  #@NEW_LINE#@#  Valverde-Rebaza et al.  #@NEW_LINE#@#  [25] present a novel feature vector obtained directly from a description of the musical structure described in MIDI files for music representation.  #@NEW_LINE#@#  
Recently Febres and Jaffe [26] proposed a new music representation and classification system based on extracting the Minimal Entropy Description of polyphonic music files.  #@NEW_LINE#@#  The Minimal Entropy Description is the sequence of characters forming symbols for which the corresponding entropy is minimal, and this representation is used to compare computer files associated to a score, considering already available parameters such as their symbolic diversity and entropy.  #@NEW_LINE#@#  
In the work of Lee et al.  #@NEW_LINE#@#  [27] the bag of words (BoW) representation of modulation spectral analysis of spectral as well as cepstral features are constructed for music genre classification.  #@NEW_LINE#@#  This is an approach used as well in text classification [28] which can be improved by means of a Singular Value Decomposition approach [29].  #@NEW_LINE#@#  
Recent success with deep neural network architectures on large-scale datasets has inspired numerous studies in the machine learning community for various pattern recognition and classification tasks such as automatic speech recognition, natural language processing, audio classification and computer vision [3032].  #@NEW_LINE#@#  Music genre classification has been done as well; Rajann et al.  #@NEW_LINE#@#  [33] show that neural networks are comparable with classic learning models when the data is represented in a rich feature space.  #@NEW_LINE#@#  Chun and Hong [34] used a BP neural network (BPNN) music classification method.  #@NEW_LINE#@#  
In this paper, Basque Folk music is used to perform the experiments; Bassiou et al.  #@NEW_LINE#@#  dealed with Greek folk music genre classification [35].  #@NEW_LINE#@#  Hillewaere et al.  #@NEW_LINE#@#  worked on automatic classification of dances using the Dance-9 corpus [36].  #@NEW_LINE#@#  

Proposed_approach  #@NEW_LINE#@#  
In this paper a three step method is presented to analyze a melody collection and create K clusters of similar melodies, use each of the clusters to generate 10 new pieces and classify each of the new generated pieces in one of the clusters.  #@NEW_LINE#@#  A schema of the process is shown on Fig 1.  #@NEW_LINE#@#  
Schema of the method presented in this work.  #@NEW_LINE#@#  


              https://doi.org/10.1371/journal.pone.0191417.g001  #@NEW_LINE#@#  
Corpus  #@NEW_LINE#@#  
In this work a collection of 100 bertso melodies of the corpus Bertso doinutegia is used.  #@NEW_LINE#@#  Bertso doinutegia is a collection of 2382 bertso melodies, created by Joanito Dorronsoro and published for the first time on 1995.  #@NEW_LINE#@#  It is updated every year by Xenpelar Dokumentazio Zentroa with new melodies that are used in bertso competitions and exhibitions.  #@NEW_LINE#@#  Entries in the collection are MIDI files which have a melody name, the name or type of the strophe, type of the melody (genre), creator, bertsolari who has used it, name and location of the person who has collected the melody, and year of the collection.  #@NEW_LINE#@#  Melodies have been manually classified in 17 genres according to their melodic features and the lyrics that are usually related to them.  #@NEW_LINE#@#  
To perform the classification task presented in this work, the melodies in the collection are represented using a viewpoint representation, presented in [37].  #@NEW_LINE#@#  A viewpoint  is a function that maps an event sequence e1, , e to a more abstract derived sequence (e1), , (e), comprising elements in the codomain of the function .  #@NEW_LINE#@#  Two viewpoints have been selected to represent the pieces in the corpus; pitch class interval (intpc) which computes the shortest distance in pitch class space between two unordered pitch classes (mod 12 interval), and five point contour (5pc) which represent the contour between two consecutive notes.  #@NEW_LINE#@#  A five point representation is used for contour, where ld and lu records whether a note is approached by a leap of three or more semitones (down or up), sd and su represent a step (smaller than three semitones) approximation and eq represents a unison.  #@NEW_LINE#@#  Fig 2 shows the viewpoint representation of the first two bars of the melody Abiatu da bere bidean, where the pitch class interval and five point contour representations of the notes in the segment can be seen, along with their pitch numbers.  #@NEW_LINE#@#  

Matrices  #@NEW_LINE#@#  
In order to discover similarities between the different pieces in the corpus they are represented using matrices that capture their melodic information.  #@NEW_LINE#@#  Using the intpc and 5pc viewpoints two matrix types are defined; interval matrices and contour matrices.  #@NEW_LINE#@#  Interval matrices are 12×12 matrices which count the number of transitions between all the interval pairs that occur in each melody.  #@NEW_LINE#@#  In order to build them the mod 12 interval between each contiguous note pair is computed.  #@NEW_LINE#@#  Then, the number of occurrences of each possible interval transition is computed.  #@NEW_LINE#@#  On the other hand, contour matrices are 5×5 matrices which count the number of transitions between all the contour pairs of each piece.  #@NEW_LINE#@#  To build the contour matrices the contour transition between each pair of notes is computed and represented using the five point representation presented on Section corpus.  #@NEW_LINE#@#  Then, the number of occurrences of each possible contour transition is computed.  #@NEW_LINE#@#  A contour matrix and an interval matrix are computed for each piece in the corpus.  #@NEW_LINE#@#  An example of a contour matrix and an interval matrix extracted from the piece in Fig 3 are shown in Figs 4 and 5.  #@NEW_LINE#@#  
To compute a position in the contour matrix, for example the [ld,sd], the number of times in the piece where a contour leap down (an interval larger than two semitones down) is followed by a contour step down (a step of one or two semitones down) is counted, which in this piece is 5.  #@NEW_LINE#@#  On Fig 3 these sequences have been highlighted to illustrate better where these sequences can be found on the example score shown.  #@NEW_LINE#@#  

Unsupervised_classification  #@NEW_LINE#@#  
With the matrices obtained in the previous step, a method to group together similar songs has been developed through an unsupervised learning process.  #@NEW_LINE#@#  
In order to discover relationships among the songs, an agglomerative hierarchical clustering algorithm has been used (Sequential Agglomerative Hierarchical Non-overlapping algorithm (SAHN)) [38].  #@NEW_LINE#@#  This algorithm starts with a partition where each case is associated to a different cluster, therefore there are so many clusters as different cases.  #@NEW_LINE#@#  At each subsequent step the algorithm merges two clusters following certain optimization criteria, until all the data belongs to the same cluster.  #@NEW_LINE#@#  The output of the algorithm is a hierarchy along with the merging steps.  #@NEW_LINE#@#  Then, if a partition with N clusters is wanted, it is necessary to traverse the hierarchy until the right cutting point is found.  #@NEW_LINE#@#  The criteria to merge two clusters in the building phase is the complete linkage method, where the distance between two clusters is the maximum distance between their individual components.  #@NEW_LINE#@#  
In Fig 6 is shown an example of a dendrogram showing the clusters created after applying the SAHN method to the set of numbers {1,2,6,10,11,30,31,33,36,38,45,46,50}.  #@NEW_LINE#@#  As it can be seen from the figure, sets of numbers that are very close to each other according to the complete linkage method are grouped together lower in the hierarchy, while the sets that are father apart are grouped in the top.  #@NEW_LINE#@#  If we are interested in the partition with a given number of clusters, it is necessary to check the level of the dendrogram where such partition is created.  #@NEW_LINE#@#  For example, the red vertical line of Fig 6 shows the level of the dendrogram where a partition of four clusters is created.  #@NEW_LINE#@#  These clusters are {10,11}, {1,2,6}, {45,46,50} and {30,31,33,36,38}.  #@NEW_LINE#@#  
In the research described in this paper matrices representations are used, and therefore suitable distances between matrices are needed.  #@NEW_LINE#@#  Several distances have been tested.  #@NEW_LINE#@#  These distances are the following ones:  #@NEW_LINE#@#  
In the following paragraphs we will explain them briefly:  #@NEW_LINE#@#  

Music_generation  #@NEW_LINE#@#  
To generate new melodies a music generation method based on statistical models and a coherence structure is used.  #@NEW_LINE#@#  The coherence structure of a piece describes which segments are related on a piece, where the relations between segments can be exact repetitions or transpositions.  #@NEW_LINE#@#  Transposed segments are segments that have the same interval sequence, but different notes.  #@NEW_LINE#@#  A coherence structure is extracted from a template piece and is then used to guide the generation process in order to get new coherent melodies.  #@NEW_LINE#@#  As a result of the process pieces that have the same coherence structure of the template, but different melodic content, are created.  #@NEW_LINE#@#  


Experimental_setup  #@NEW_LINE#@#  
A set of 100 random pieces of the corpus described in Section corpus used to extract a representation of pitch class interval and five point contour viewpoints of each piece, from which the contour and interval matrices of each melody are computed.  #@NEW_LINE#@#  These matrices are then used to perform an unsupervised classification and group similar songs into clusters.  #@NEW_LINE#@#  These clusters are then used to build statistical models that are used in the automatic music generation process.  #@NEW_LINE#@#  
A first experiment with the melody named Abiatu da bere bidean, which is part of the corpus, but is not part of the 100 piece set, is used to extract the coherence structure that guides the generation, along with the statistical models computed from the clusters identified in the classification process.  #@NEW_LINE#@#  10 different generations have been made for each cluster, and they have been represented as contour and interval matrices to be classified in the next step.  #@NEW_LINE#@#  Three extra experiments have been performed with three more melodies randomly chosen from the corpus.  #@NEW_LINE#@#  

Experimental_results  #@NEW_LINE#@#  
As commented in the previous section, two types of matrices have been obtained for each melody, and both have been used to test the proposed approach.  #@NEW_LINE#@#  
Contour  #@NEW_LINE#@#  
Obtained classification accuracies are shown in Table 1.  #@NEW_LINE#@#  As it can be appreciated, obtained results are very different regarding the used distance and the number of cluster selected.  #@NEW_LINE#@#  It can be inferred, indeed, that there is a distance, EMD, which out-stands clearly from the other when a low number of clusters is used.  #@NEW_LINE#@#  As a matter of fact, the best results are obtained using this EMD distance for cluster numbers 2 and 4; concerning to other number of clusters, normalized distances appear to be the best choice, being M-norm which obtains the best mean among all.  #@NEW_LINE#@#  It is worth remarking the result obtained by 1-norm distance when six clusters are used: it obtains by far the best result among all the distances used (0.583).  #@NEW_LINE#@#  

Interval  #@NEW_LINE#@#  
The same experiment has been repeated, using Interval type matrices, and the obtained accuracy results have been presented in Table 2.  #@NEW_LINE#@#  In this case, EMD distance out-stands as the best one in the performed experiments; best results are obtained using this distance for 3 to 6 clusters, and the best mean is obtained with this distance as well.  #@NEW_LINE#@#  Remarkable result of Manhattan distance for two clusters (0.875), which makes it candidate for low cluster situations; it obtains the second best mean among all distances.  #@NEW_LINE#@#  

Extra_experiments  #@NEW_LINE#@#  
In order to provide a better overview of the proposed approach, a set of extra experiments have been set up; 3 pieces have been randomly selected for the corpus.  #@NEW_LINE#@#  These new three melodies are Aita semeak tabernan daude I (which from now on will be identified with the melody ID 1360), Gure herriko bikariuak (melody ID 1476) and Zazpi ahizparen gai den oihala I (melody ID 1599).  #@NEW_LINE#@#  The approach presented in this paper has been applied taking as template piece each melody of the new experiment set.  #@NEW_LINE#@#  
Tables 3 and 4 show the obtained results for the first piece (melody ID 1360) for contour and interval representation respectively.  #@NEW_LINE#@#  As it can be seen, the same result is obtained for the 2 clusters scenario, but the results differ between both representations in the remaining cluster numbers considered.  #@NEW_LINE#@#  Interval representation is slightly better, although the best distance mean is obtained by M-norm in the Contour case.  #@NEW_LINE#@#  Different distances obtain the best result for different cluster numbers, which indicates that the appropriate one should be carefully selected for each considered case.  #@NEW_LINE#@#  
Regarding the second piece (melody ID 1476), obtained results are shown in Tables 5 (contour) and 6 (interval).  #@NEW_LINE#@#  In this case, interval representation is the best one, being the best mean accuracy obtained using the EMD distance.  #@NEW_LINE#@#  When the number of clusters is 2 or 3, the M-norm distance is the one which obtains better results.  #@NEW_LINE#@#  
For the third selected musical piece (melody ID 1599) the obtained results are shown in Tables 7 and 8 for contour and interval representation respectively.  #@NEW_LINE#@#  Once again, interval is the best representation, and the results differ depending on the number of clusters used.  #@NEW_LINE#@#  The best mean is obtained by M-norm distance for contour representation.  #@NEW_LINE#@#  
It is worth mentioning that the results obtained in the extra experiments do not differ with the ones shown in Tables 1 and 2 which indicates that the proposed approach gives an accurate way to classify different songs once the model has been trained using an appropriate subset of representative melodies.  #@NEW_LINE#@#  


Conclusions_and_future_works  #@NEW_LINE#@#  
In this paper an investigation of the classification of automatically generated melodies is performed; the main idea that grouping close related known pieces in different sets or clusters, and afterwards generating new melodies in an automatic way, which are somehow inspired in each set.  #@NEW_LINE#@#  The new melodies are supposed to be classified to this set, using the same distance used to identify the clusters.  #@NEW_LINE#@#  
Although obtained results could be seen as not so good for other kind of data we do not expect a medical research giving us a 66% of suffering a disease, or a industrial task telling us that certain piece is among tolerance-threshold on a 56% probability it has to be remarked the artistic environment the performed experiment have been carried out, in an area which is no deterministic, and in genres that could be confused among each other.  #@NEW_LINE#@#  
Nevertheless, obtained results indicate the appropriateness of the whole process: results over 0.5 can be considered encouraging, especially when the cluster number is 4 or more.  #@NEW_LINE#@#  Some extra experiments have been performed using three different songs as template, and using the previously obtained clustering as classification model.  #@NEW_LINE#@#  Obtained results are similar to the previous ones, which indicates the soundness of the proposed approach.  #@NEW_LINE#@#  
As future work a deeper analysis is envisaged, and a combination of both representations (contour and interval) in order to obtain a better idea of the genre divisions obtained by the clustering process.  #@NEW_LINE#@#  Another open line remain in the use of different distances to classify the new generated melodies and to divide the existing songs in different clusters.  #@NEW_LINE#@#  On the music generation topic the rhythm generation and the use of harmonic information to generate melodies are lines that should also be studied in the future.  #@NEW_LINE#@#  

References  #@NEW_LINE#@#  



