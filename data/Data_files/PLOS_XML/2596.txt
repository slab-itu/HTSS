article id="http://dx.doi.org/10.1371/journal.pcbi.1006236"  #@NEW_LINE#@#  
title  #@NEW_LINE#@#  
Optimal multi-source forecasting of seasonal influenza  #@NEW_LINE#@#  

Abstract  #@NEW_LINE#@#  
Forecasting the emergence and spread of influenza viruses is an important public health challenge.  #@NEW_LINE#@#  Timely and accurate estimates of influenza prevalence, particularly of severe cases requiring hospitalization, can improve control measures to reduce transmission and mortality.  #@NEW_LINE#@#  Here, we extend a previously published machine learning method for influenza forecasting to integrate multiple diverse data sources, including traditional surveillance data, electronic health records, internet search traffic, and social media activity.  #@NEW_LINE#@#  Our hierarchical framework uses multi-linear regression to combine forecasts from multiple data sources and greedy optimization with forward selection to sequentially choose the most predictive combinations of data sources.  #@NEW_LINE#@#  We show that the systematic integration of complementary data sources can substantially improve forecast accuracy over single data sources.  #@NEW_LINE#@#  When forecasting the Center for Disease Control and Prevention (CDC) influenza-like-illness reports (ILINet) from week 48 through week 20, the optimal combination of predictors includes public health surveillance data and commercially available electronic medical records, but neither search engine nor social media data.  #@NEW_LINE#@#  

Author_summary  #@NEW_LINE#@#  
In the United States, seasonal influenza causes thousands of deaths and hundreds of thousands of hospitalizations.  #@NEW_LINE#@#  The annual timing and burden of the flu season vary considerably with the severity of the circulating viruses.  #@NEW_LINE#@#  Epidemic forecasting can inform early and effective countermeasures to limit the human toll of severe seasonal and pandemic influenza.  #@NEW_LINE#@#  With a growing toolkit of sophisticated statistical methods and the recent explosion of influenza-related data, we can now systematically match models to data to achieve timely and accurate warning as flu epidemics emerge, peak and subside.  #@NEW_LINE#@#  Here, we introduce a framework for identifying optimal combinations of data sources, and show that public health surveillance data and electronic health records collectively forecast seasonal influenza better than any single data source alone and better than influenza-related search engine and social media data.  #@NEW_LINE#@#  

Citation: Ertem Z, Raymond D, Meyers LA (2018) Optimal multi-source forecasting of seasonal influenza.  #@NEW_LINE#@#  PLoS Comput Biol 14(9):  #@NEW_LINE#@#  
           e1006236.  #@NEW_LINE#@#  

        https://doi.org/10.1371/journal.pcbi.1006236  #@NEW_LINE#@#  
Editor: Mark M. Tanaka,  #@NEW_LINE#@#  
University of New South Wales, AUSTRALIA  #@NEW_LINE#@#  

Received: January 30, 2018; Accepted: May 28, 2018; Published:  September 4, 2018  #@NEW_LINE#@#  
Copyright:  Â© 2018 Ertem et al.  #@NEW_LINE#@#  This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.  #@NEW_LINE#@#  
Data Availability: Data are available from the AthenaHealth for researchers who meet the criteria for access to confidential data.  #@NEW_LINE#@#  Data is restricted to ensure patient confidentiality and prevent disclosure of PHI.  #@NEW_LINE#@#  Data is de-deidentified, but it is athenahealths policy to require a legal data use agreement between athena and the researcher prior to providing the data.  #@NEW_LINE#@#  Please reach out to Josh Gray, Vice President of athenaResearch at athenahealth: jogray@athenahealth.com.  #@NEW_LINE#@#  
Funding: We would like to acknowledge funding from Defense Threat Reduction Agency (US) HDTRA1-14-C-0114 and NIH/NIGMS MIDAS grant U01 GM087719.  #@NEW_LINE#@#  The funders had no role in study design, data collection, and analysis, decision to publish, or preparation of the manuscript.  #@NEW_LINE#@#  
Competing interests:  The authors have declared that no competing interests exist.  #@NEW_LINE#@#  
Introduction  #@NEW_LINE#@#  
Seasonal influenza epidemics annually result in significant global morbidity and mortality [1], and influenza pandemics can cause catastrophic levels of death, social disruption, and economic loss [2].  #@NEW_LINE#@#  Early detection and forecasting of both emergence and peak epidemic activity can inform an effective allocation of resources, surge planning, and public health messaging [1, 35].  #@NEW_LINE#@#  Thus, public health and scientific communities have prioritized the development of influenza forecasting technologies [611].  #@NEW_LINE#@#  
There are a growing number and variety of readily available disease-related data sources that may ultimately be integrated into or even replace traditional systems.  #@NEW_LINE#@#  The Center for Disease Control and Prevention (CDC) relies on data from two primary national influenza surveillance systems: (1) the U.S. World Health Organization (WHO) and National Respiratory and Enteric Virus Surveillance System (NREVSS) collaborating laboratories (henceforth, WHO US) and (2) the US Outpatient Influenza-like Illness Surveillance Network (ILINet).  #@NEW_LINE#@#  Recently, Meaningful Use [12], a CDC led effort, is advancing the expansion of syndromic surveillance systems such as ESSENCE to address a broader set of infectious disease surveillance objectives [1315].  #@NEW_LINE#@#  
Novel data sources for outbreak surveillance are also arising outside of public health.  #@NEW_LINE#@#  Notably, researchers at Google launched the Google Flu Trends service (GFT) in 2008 to provide real-time estimates of influenza prevalence based on disease-related search activity [16].  #@NEW_LINE#@#  They showed that time series tracking the volumes of influenza-related Google searches closely mirrored influenza data from ILINet.  #@NEW_LINE#@#  However, it failed to capture the emergence of the 2009 H1N1 pandemic and fell short in subsequent influenza seasons [1721], resulting in the termination of the program in August 2015 by the company.  #@NEW_LINE#@#  Epidemic-related data have also been extracted from not only search engines [22] but also interactive web-based applications (e.g., Flu Near You, InfluenzaNet) [23] and online social platforms such as Twitter (e.g., MappyHealth) [24, 25], Facebook [2429], and Wikipedia [30].  #@NEW_LINE#@#  While most of these data sources contain broad information, epidemic related data is passively mined and filtered.  #@NEW_LINE#@#  There are, however, a few participatory systems that directly solicit health data from voluntary participants [23].  #@NEW_LINE#@#  For example, InfluenzaNet, has over 50 000 volunteers from ten European countries [23].  #@NEW_LINE#@#  While many of these sources have been shown, individually, to estimate and predict influenza activity, we have yet to build forecasting models based on systematic comparisons and integration of complementary data.  #@NEW_LINE#@#  
Given the real-time availability of GFT at multiple geographic scales (from city to continental), many of the early forecasting methods used GFT as a test bed.  #@NEW_LINE#@#  Notably, Shaman et al.  #@NEW_LINE#@#  [8] pioneers the use of Kalman filters to predict seasonal GFT dynamics from historical GFT and humidity data and Nsoesie et al.  #@NEW_LINE#@#  [31] couples a simulation optimization method with a network-based epidemiological model to forecast regional influenza peaks.  #@NEW_LINE#@#  Another study forecasts GFT from a combination of GFT, temperature, and humidity data in a specific metropolitan area (Baltimore), and demonstrates that the integration of multiple data sources can improve forecast accuracy [7].  #@NEW_LINE#@#  
More recent forecasting efforts have directly targeted CDC ILINet, rather than GFT, using a variety of predictor data sources.  #@NEW_LINE#@#  Brooks et al.  #@NEW_LINE#@#  [6] apply a novel simulation-based Bayesian forecasting framework to forecast one season of ILINet from prior ILINet data.  #@NEW_LINE#@#  Their method first constructs prior distributions of seasonal flu curves by stochastically combining and transforming features of past flu seasons.  #@NEW_LINE#@#  As a season emerges, it updates the posterior distribution based on real-time observations and uses importance sampling to generate forecasts.  #@NEW_LINE#@#  Two other studies forecast ILINet from alternative data sourcesone evaluates the predictive performance of Google, Twitter, and Wikipedia, individually [32], and the other considers a multi-linear combination of internet source, digital surveillance, and electronic medical records data [33].  #@NEW_LINE#@#  
Such data sources vary considerably in both availability and reliability.  #@NEW_LINE#@#  Some are available in near-real time, whereas others are lagged by days or weeks; some deeply sample geographic or socioeconomic slices of a population, whereas others provide representative but sparse samples of an entire population.  #@NEW_LINE#@#  In particular, internet and social media data can be misleading, particularly during newsworthy epidemiological events [3436], but potentially provide a valuable real-time window into emerging events when combined with validated public health or medical data sources.  #@NEW_LINE#@#  Optimization allows us to systematically balance such trade-offs and quantify the informational content and complementarity of different categories of data.  #@NEW_LINE#@#  We argue that, for a given forecasting task, candidate data sources should be evaluated and integrated based on clear performance metrics, which may include, for example, measures of forecast accuracy or precision at one or across multiple time points.  #@NEW_LINE#@#  
Here, we introduce an optimization method for designing robust multi-source epidemic forecasting systems and apply it forecasting seasonal flu in the US.  #@NEW_LINE#@#  Our framework is intended to be plug-and-play, allowing researchers to evaluate large combinations of data sources with respect to their own forecasting model and performance metrics.  #@NEW_LINE#@#  In our case study, the candidate data sources include thousands of time series data sources from public health surveillance systems, electronic health records systems (EHR), search engines, and other website and social media applications.  #@NEW_LINE#@#  Our forecasting model is an extension of the flexible Bayesian machine learning method introduced in [6], modified to combine multiple predictors.  #@NEW_LINE#@#  Finally, our objective function considers overall similarity between historical data and out-of-sample forecasts, averaging across 16 recent flu seasons.  #@NEW_LINE#@#  Unlike recent multi-source forecasting studies (such as [33]), we present a framework to rigorously evaluate much larger sets of candidate data sources both at the national and regional level and select complementary combinations that maximize forecast performance metrics.  #@NEW_LINE#@#  This approach not only yields more accurate forecasts, but provides quantitative insight into the relative utility of data sources.  #@NEW_LINE#@#  

Materials_and_methods  #@NEW_LINE#@#  
Data_sources  #@NEW_LINE#@#  

Hierarchical_model_selection  #@NEW_LINE#@#  
We use greedy optimization with forward selection to iteratively identify combinations of predictor data sources that collectively result in the most accurate forecast for a target data source.  #@NEW_LINE#@#  Our approach consists of three steps, as shown in Fig 1.  #@NEW_LINE#@#  First, we individually forecast candidate data sources using an empirical Bayesian framework.  #@NEW_LINE#@#  Second, we use linear models to combine such individual forecasts into grand forecasts of a target time series.  #@NEW_LINE#@#  Finally, we build an optimal forecasting system (i.e., collection of predictor data sources) by sequentially adding candidate data sources that most improve the accuracy of historical out-of-sample forecasts of the target.  #@NEW_LINE#@#  Next sections describe these steps in detail.  #@NEW_LINE#@#  

Evaluating_forecasts  #@NEW_LINE#@#  
We use RMSE to evaluate forecasts and thereby select informative combinations of data sources.  #@NEW_LINE#@#  It measures the difference between predicted and actual time series, as given by  #@NEW_LINE#@#  
(5)  #@NEW_LINE#@#  
where xw and yw denote the observed and predicted values of the target data source, respectively, at week w of the season, for w = {1, 2, , n}.  #@NEW_LINE#@#  Post selection, we evaluate the quality of the forecasts using two additional metrics that address the timing and magnitude of the epidemic peak.  #@NEW_LINE#@#  Specifically, the peak week error (PWE) of a given season is the absolute difference between predicted and actual peak week, as given by  #@NEW_LINE#@#  
(6)  #@NEW_LINE#@#  
where p and  denote the weeks during which the observed and predicted time series, respectively, hit their maximum values.  #@NEW_LINE#@#  The peak magnitude error (PME) of a given season is the ratio of the absolute difference between the maximum observed and predicted values of the time series and the maximum observed value, as given by  #@NEW_LINE#@#  
(7)  #@NEW_LINE#@#  
where h and  denote the maximum values reached by the observed and predicted target time series, respectively.  #@NEW_LINE#@#  


Results  #@NEW_LINE#@#  
We analyzed several different sets of candidate data sources, with the goal of identifying subsets of data sources that provide accurate and timely forecasts of ILINet.  #@NEW_LINE#@#  For each round of data evaluation, we separately predicted each season between 1997 and 2014, excluding the 2009-2010 H1N1 pandemic.  #@NEW_LINE#@#  For simplicity, we assumed that all 16 seasons span from the 40th calendar week of a given year to the 20th calendar week of the subsequent year.  #@NEW_LINE#@#  For each season in each data source, we assume that we observe values during the first nine weeks of the season (i.e., the 40th through 48th calendar week) and then forecast ILINet levels for the remainder of the flu season.  #@NEW_LINE#@#  
Each experiment resulted in an optimized surveillance system, that is, a list of data sources prioritized by the order in which they were selected during optimization.  #@NEW_LINE#@#  We compare the optimized surveillance systems using three metrics that evaluate the accuracy of the overall (RMSE) and peak (PWE and PME) forecasts.  #@NEW_LINE#@#  
First, we consider an optimized system consisting of five data sources selected from among all 453 local, regional and national data sources, and compare it to two baseline systemsone using only ILINet to forecast itself and another using a combination of ILINet and WHO laboratory data to forecast ILINet (Table 1).  #@NEW_LINE#@#  ILINet is selected as the single most informative predictor when evaluated in conjunction with only WHO laboratory data or with all 453 available sources.  #@NEW_LINE#@#  The fully optimized system combines ILINet with WHO and three Athena state- and regional-level data sources (no internet-based data sources is chosen), suggesting that proprietary electronic medical record data may provide a more reliable source of real-time epidemiological data than freely available internet source data.  #@NEW_LINE#@#  In comparing the ILINet plus WHO system to the fully optimized system (All), we find that Athena data improves performance only marginally relative to the addition of all four data sources, which together reduce the historical RMSE by roughly 15%.  #@NEW_LINE#@#  


              https://doi.org/10.1371/journal.pcbi.1006236.t001  #@NEW_LINE#@#  
The optimization selected Athena data from HHS region 8, Illinois, and Georgia, from among all 435 Athena candidate time series.  #@NEW_LINE#@#  To assess the value of such local, state and regional data, we conducted an additional experiment, restricting the selection to only US-level candidate data sources.  #@NEW_LINE#@#  The resulting system includes two national Athena data sources (i.e., absolute and percent ILI visits across all facilities) and WordPress flu activity (Table 1).  #@NEW_LINE#@#  It yields better forecasts than the public health baselines, but is inferior to the optimized system that includes state and regional data.  #@NEW_LINE#@#  
While ILINet and WHO data are consistently selected as the most informative data sources, they tend to have greater time lags than some of the other real-time candidate data sources.  #@NEW_LINE#@#  To evaluate the viability of a real-time system using alternative national-level data, we optimized two additional systems, one excluding ILINet and the other excluding both ILINet and WHO data.  #@NEW_LINE#@#  Without ILINet, WHO is selected as the single most informative source and combined with four different national-level Athena data sources tracking flu-related visits and prescriptions (Table 1).  #@NEW_LINE#@#  The forecasts decline only slightly relative to systems that include ILINet.  #@NEW_LINE#@#  However, when both ILINet and WHO data are excluded, the expected performance drops considerably.  #@NEW_LINE#@#  For comparison, we optimized systems for forecasting state-level ILINet (California, New York, and Texas), and found that national-level surveillance data (ILINet and WHO US) are always selected among the top three most informative data sources, with forecasts enhanced by a variety of state and regional athenahealth variables.  #@NEW_LINE#@#  (See Table in S1 Table)  #@NEW_LINE#@#  
Forecasting_accuracy  #@NEW_LINE#@#  
The best five-source system (optimized from all available data sources) consistently produces accurate historical out-of-sample forecasts, as shown in Fig 2.  #@NEW_LINE#@#  After observing only the first nine weeks of the flu season, the system is able to predict the remaining 24 weeks of the season with an average RMSE under 1%.  #@NEW_LINE#@#  The forecasted 95% credible interval contained the historical ILINet value in 87% of all weeks across all 16 forecasts.  #@NEW_LINE#@#  However, the 2002-2003 and 2003-2004 forecasts capture the peaks but considerably overestimate prevalence towards the ends of the seasons (12 weeks out of 24 lie outside the 95% credible interval).  #@NEW_LINE#@#  Excluding these two seasons, 92.9% of all historical weeks fall within the forecasted 95% interval.  #@NEW_LINE#@#  In the system optimized from all national-level data sources except ILINet, accuracy drops to 66% of all historical weeks contained in the credible intervals.  #@NEW_LINE#@#  (See S1 Fig for detailed results).  #@NEW_LINE#@#  
Although these systems were optimized solely to minimize RMSE, the resulting forecasts perform quite well with respect to predicting the timing and magnitude of the epidemic peak.  #@NEW_LINE#@#  In over 85% of the seasons, the forecasts predict the peak to occur within two weeks of the actual peak; in over 85%, the predicted height of the peak is within 20% of its actual height.  #@NEW_LINE#@#  Since the Athena predictors are only available between 2011 and 2014, they provide no information for the first 13 of the 16 seasons.  #@NEW_LINE#@#  Consequently, we see a reduction in RMSE for the three most recent forecasts.  #@NEW_LINE#@#  
Performance curves for this optimized system indicate that additional data sources, beyond the five included, are not expected to improve performance considerably, according to our empirical results show in Fig 3.  #@NEW_LINE#@#  On their own, ILINet and WHO are the strongest predictors of future ILINet activity.  #@NEW_LINE#@#  Although the Athena data sources exhibit poor individual performance, they substantially improve forecast accuracy when combined with ILINet and WHO.  #@NEW_LINE#@#  The hierarchical selection method was thus able to integrate complementary data sources into a multi-source system that is expected to provide more reliable forecasts than single-source systems.  #@NEW_LINE#@#  This is also true for systems which exclude ILINet and WHO as candidate predictors.  #@NEW_LINE#@#  (See S2 Fig for detailed results).  #@NEW_LINE#@#  
We also build out-of-sample forecasts of ILINet using ILINet and WHO as predictors, using only (1) three years (2011-2014) and (2) five years of training data (2008-2014) to build the Bayesian prior distributions.  #@NEW_LINE#@#  In the original out-of-sample forecasts, we used 15 of the 16 available seasons to build priors for forecasting the remaining season.  #@NEW_LINE#@#  (See S3 and S4 Figs for more details).  #@NEW_LINE#@#  Performance increased with the duration of the training data, with average RMSE decreasing from 0.69 to 0.64 to 0.56 as we increase the training period from three to five to fifteen years.  #@NEW_LINE#@#  However, even the poorest set of forecasts (based on three years of training) are decent.  #@NEW_LINE#@#  In addition, we note that the original experiments selected Athena Health data as highly informative predictors, despite only being available for three years (2011-2014).  #@NEW_LINE#@#  


Discussion  #@NEW_LINE#@#  
There are a growing number of powerful methods for forecasting seasonal and pandemic flu (e.g.  #@NEW_LINE#@#  [6, 45]).  #@NEW_LINE#@#  To achieve earlier and more accurate predictions of epidemic emergence, growth, peaks and burden, researchers are developing sophisticated statistical methodssome adapted from mature forecasting sciences like meteorology [8]and creatively leveraging diverse sources of predictor data.  #@NEW_LINE#@#  The increasing public availability of disease-related data sources is promising yet daunting, with annually, hundreds of thousands of influenza-related tweets [42], several millions of page hits on Wikipedia to influenza-related pages [30], thousands of influenza-related blog posts on Wordpress [40] and hundreds of thousands of hospital and clinic visits.  #@NEW_LINE#@#  While many studies have demonstrated the promise of surveillance [46] and forecasting from novel data sources [33], we do not yet have rigorous methods for evaluating the utility of such data or identifying effective combinations of data for particular models and forecasting goals.  #@NEW_LINE#@#  
Over several years, we have developed a general framework for addressing exactly this challenge [20, 46, 47].  #@NEW_LINE#@#  For any public health surveillance goal, the approach is designed to systematically evaluate up to thousands of candidate data sources and identify complementary combinations of predictors that achieve the stated goal.  #@NEW_LINE#@#  For example, we have identified optimal zip codes for seasonal flu surveillance and early detection of pandemic flu in Texas [48], selected informative clinics for dengue surveillance in Puerto Rico [47], and developed software for optimal selection and integration of surveillance data sources for the Defense Threat Reduction Agencys (DTRAs) Biosurveillance Ecosystem (BSVE) [49].  #@NEW_LINE#@#  
In this study, we have used this framework to design multi-source surveillance systems for accurate forecasting of seasonal influenza, and, in the process, rigorously assess the performance and complementarity of diverse data sources.  #@NEW_LINE#@#  To do so, we combined two previously published methods.  #@NEW_LINE#@#  The first is an empirical Bayes strategy for forecasting seasonal flu from a single data source [6].  #@NEW_LINE#@#  Rather than imposing strong assumptions about transmission dynamics, it assumes that the forecasting target (typically, the currently emerging flu season) will roughly resemble past seasons in terms of the shape, peak week, peak magnitude, and pace of the epidemic curve.  #@NEW_LINE#@#  By combining and perturbing these features from prior seasonal data, we simulate distributions of plausible (hybrid) flu curves.  #@NEW_LINE#@#  Then, as a season unfolds, we predict future weeks by extrapolating from variates that most resemble recent activity.  #@NEW_LINE#@#  To forecast flu (target) from multiple data sources (predictors), we make empirical Bayes forecasts of each predictor separately and combine them into a target forecast using a linear model previously fit to historical predictor and target data.  #@NEW_LINE#@#  The second method is a greedy optimization that sequentially selects a maximally informative set of data sources to achieve a specified goal [47, 50].  #@NEW_LINE#@#  In our case, the candidate providers are a diverse set of public health, commercial health-care, internet query and social media data sources.  #@NEW_LINE#@#  Our public health goal is accurate forecasting of seasonal flu starting in calendar week 48.  #@NEW_LINE#@#  
The field has primarily focused on the development of statistical models that predict seasonal dynamics on multiple geopolitical scales, and only secondarily considered the quality of predictor data.  #@NEW_LINE#@#  Test bed data are often selected based on convenience.  #@NEW_LINE#@#  Until recently, Google Flu Trends data was free and abundant at multiple scales, and thus a popular choice [7, 10, 20, 31].  #@NEW_LINE#@#  A few studies have integrated multiple different types of data and shown that, for short-term forecasting (one to three weeks ahead), the combination of all independent flu predictors performs better than using single source [33].  #@NEW_LINE#@#  However, they have not systematically optimized the combination of data sources or quantified their relative contributions to forecast accuracy, as we have done here.  #@NEW_LINE#@#  Our study confirms that multi-source forecasting can outperform single-source forecasting, but only when complementary sources are identified and systematically integrated.  #@NEW_LINE#@#  
We optimized forecasting models from three classes of datatraditional public health surveillance data, electronic health records (EHR) from a data services company, and data aggregated from the influenza-related internet search and social network activity.  #@NEW_LINE#@#  A priori, each has pros and cons.  #@NEW_LINE#@#  Official surveillance systems are designed for the purpose of monitoring and predicting flu activity, and thus may provide more accurate and robust signals than the alternatives.  #@NEW_LINE#@#  However, surveillance data tends to be sparse and time-lagged.  #@NEW_LINE#@#  Internet source data can be abundant and immediately available, but provides only correlated activity that can be highly susceptible to extrinsic perturbations such as media events and modifications to source websites [34, 35].  #@NEW_LINE#@#  EHR data has the combined advantages of real-time availability and access to multi-dimensional flu data at various geographic scales.  #@NEW_LINE#@#  However, it is not freely available and may require statistical corrections for sampling biases.  #@NEW_LINE#@#  
Our analyses provide quantitative insights into harnessing these trade-offs for forecasting.  #@NEW_LINE#@#  First, when data sources are evaluated individually, we find that public health surveillance data yields the most accurate forecasts, followed by EHR data, and internet-source data trailing far behind.  #@NEW_LINE#@#  Second, optimized combinations of data sources (with or without ILINet) provide far better forecasts than any individual data source alone.  #@NEW_LINE#@#  Third, EHR data are always selected before internet-source data to augment public health data, suggesting that EHRs provide a more valuable source of complementary information.  #@NEW_LINE#@#  Forth, when CDC and WHO data are excluded, the optimal EHR and internet-source systems are unable to achieve comparable forecasting performance.  #@NEW_LINE#@#  Fifth, state-level EHR data improves forecasts significantly more than national-level EHR data.  #@NEW_LINE#@#  
While we believe that these insights are robust, they may reflect specific assumptions of our model, and not apply to other diseases, forecasting methods, or objective functions.  #@NEW_LINE#@#  First, the superior performance of the public health data source is likely biased by our choice of ILINet as the gold standard forecasting target.  #@NEW_LINE#@#  If we had instead sought to forecast athenahealth or GFT time series, these data sources may have been selected as their own top predictors.  #@NEW_LINE#@#  However, we believe that this choice of target is justified, as it is the only data source specifically designed to estimate flu prevalence in the US.  #@NEW_LINE#@#  Along with WHO it always selected as a top predictor for selected level forecasts.  #@NEW_LINE#@#  Second, we follow Brooks et al.  #@NEW_LINE#@#  [6] in assuming uniform distributions for peak height and peak week, constrained by historical observations.  #@NEW_LINE#@#  This might limit forecasting accuracy for seasons with atypically high, low, early or late peaks.  #@NEW_LINE#@#  To address this, one could assume distributions that include low probability extreme departures from past seasons.  #@NEW_LINE#@#  
We emphasize that this framework is designed to select optimal combinations of data sources for any combination of predictor data sources, multi-linear forecasting method and objective function.  #@NEW_LINE#@#  As a case study, we built optimal combinations of data sources for forecasting seasonal flu using a published univariate Bayesian empirical framework ([6]) that we extended to forecast with multiple data sources.  #@NEW_LINE#@#  The optimized systems provide reliable forecasts of the overall seasonal trends and epidemic peak, in most of the 16 historical out-of-sample evaluations.  #@NEW_LINE#@#  The data-driven selection of informative predictors revealed that public health surveillance data is invaluable for flu forecasting, and that, when rigorously integrated into forecasting models, proprietary electronic health record data can significantly increase accuracy, to a greater degree than freely available internet data.  #@NEW_LINE#@#  The same optimization framework, forecasting method and RMSE objective function could be readily applied to designing high performing multi-linear forecasting systems for other diseases, for which we have amble historic data, such as Dengue [5154] and Chikungunya [55].  #@NEW_LINE#@#  By modifying the objective function, we can alternatively build systems for forecasting early transmission dynamics or clinical severity of emerging outbreaks.  #@NEW_LINE#@#  

Supporting_information  #@NEW_LINE#@#  
S1_Algorithm_Hierarchical_data_source_selection  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pcbi.1006236.s001  #@NEW_LINE#@#  
(PDF)  #@NEW_LINE#@#  

S1_Table_Data_selected_for_forecasting_ILINet_in_three_US_states  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pcbi.1006236.s002  #@NEW_LINE#@#  
(PDF)  #@NEW_LINE#@#  

S1_Fig_Historical_flu_forecasts_from_1997-1998_through_2013-2014_(excluding_2009-2010)_from_two_of_the_optimized_five-source_systems  #@NEW_LINE#@#  
The All system was optimized from all candidate data sources; the All national without ILINet system was optimized from all national-scale data sources except ILINet.  #@NEW_LINE#@#  These correspond to the third and fifth systems listed in Table 1, respectively.  #@NEW_LINE#@#  Plots show the actual (black) and forecasted (red) time series with 95% credible intervals (gray).  #@NEW_LINE#@#  Across all 16 out-of-sample forecasts, we calculated the proportion of weeks in which the forecasted 95% credible interval contains the historical ILINet value, and found that the All and All national without ILINet systems achieved 87% and 66% accuracy, respectively.  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pcbi.1006236.s003  #@NEW_LINE#@#  
(PDF)  #@NEW_LINE#@#  

S2_Fig_Performance_curves_for_the_first_ten_selected_data_sources_when_all_possible_data_sources_are_included_as_candidate_predictors_(All)__when_ILINet_is_excluded_(All_without_ILINet)__and_when_both_ILINet_and_WHO_are_excluded_(All_without_ILINet_and_WHO)  #@NEW_LINE#@#  
The system was built through the sequential selection of data sources that minimize average RMSE across 16 out-of-sample forecasts.  #@NEW_LINE#@#  Selected data are listed in order of inclusion from left to right along the x-axis.  #@NEW_LINE#@#  Performance is indicated along y-axis in terms of RMSE, with open circles indicating individual performance of selected data sources, and closed circles and shading indicating the mean and range in performance across all 16 out-of-sample forecasts.  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pcbi.1006236.s004  #@NEW_LINE#@#  
(PDF)  #@NEW_LINE#@#  

S3_Fig_Forecasting_ILINet_from_ILINet_and_WHO_predictors__based_on_a_three-year_training_period_(2011-2014)  #@NEW_LINE#@#  
In the original forecasts, we used 15 of the 16 available seasons to build Bayesian priors and then forecasted the remaining season.  #@NEW_LINE#@#  Here, we use only three seasons to train the model and then forecast the preceding 13 seasons.  #@NEW_LINE#@#  The average RMSE across these forecasts is 0.69, which is considerably poorer than the average RMSE of 0.56 achieved with the original fifteen-year training periods.  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pcbi.1006236.s005  #@NEW_LINE#@#  
(PDF)  #@NEW_LINE#@#  

S4_Fig_Forecasting_ILINet_from_ILINet_and_WHO_predictors__based_on_a_five-year_training_period_(2008-2014)  #@NEW_LINE#@#  
In the original forecasts, we used 15 of the 16 available seasons to build Bayesian priors and then forecasted the remaining season.  #@NEW_LINE#@#  Here, we use only five seasons to train the model and then forecast the preceding 11 seasons.  #@NEW_LINE#@#  These forecasts have an average RMSE of 0.64, compared to average RMSEs of 0.56 for the original fifteen-year training period and 0.69 for the three-year training period shown in Fig S3 Fig  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pcbi.1006236.s006  #@NEW_LINE#@#  
(PDF)  #@NEW_LINE#@#  


References  #@NEW_LINE#@#  



