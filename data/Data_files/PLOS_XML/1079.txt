article id="http://dx.doi.org/10.1371/journal.pone.0170046"  #@NEW_LINE#@#  
title  #@NEW_LINE#@#  
The Potential of Automatic Word Comparison for Historical Linguistics  #@NEW_LINE#@#  

Abstract  #@NEW_LINE#@#  
The amount of data from languages spoken all over the world is rapidly increasing.  #@NEW_LINE#@#  Traditional manual methods in historical linguistics need to face the challenges brought by this influx of data.  #@NEW_LINE#@#  Automatic approaches to word comparison could provide invaluable help to pre-analyze data which can be later enhanced by experts.  #@NEW_LINE#@#  In this way, computational approaches can take care of the repetitive and schematic tasks leaving experts to concentrate on answering interesting questions.  #@NEW_LINE#@#  Here we test the potential of automatic methods to detect etymologically related words (cognates) in cross-linguistic data.  #@NEW_LINE#@#  Using a newly compiled database of expert cognate judgments across five different language families, we compare how well different automatic approaches distinguish related from unrelated words.  #@NEW_LINE#@#  Our results show that automatic methods can identify cognates with a very high degree of accuracy, reaching 89% for the best-performing method Infomap.  #@NEW_LINE#@#  We identify the specific strengths and weaknesses of these different methods and point to major challenges for future approaches.  #@NEW_LINE#@#  Current automatic approaches for cognate detectionalthough not perfectcould become an important component of future research in historical linguistics.  #@NEW_LINE#@#  

Citation: List J-M, Greenhill SJ, Gray RD (2017) The Potential of Automatic Word Comparison for Historical Linguistics.  #@NEW_LINE#@#  PLoS ONE 12(1):  #@NEW_LINE#@#  
           e0170046.  #@NEW_LINE#@#  

        https://doi.org/10.1371/journal.pone.0170046  #@NEW_LINE#@#  
Editor: Robert C. Berwick,  #@NEW_LINE#@#  
Massachusetts Institute of Technology, UNITED STATES  #@NEW_LINE#@#  

Received: October 18, 2016; Accepted: December 28, 2016; Published:  January 27, 2017  #@NEW_LINE#@#  
Copyright:  © 2017 List et al.  #@NEW_LINE#@#  This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.  #@NEW_LINE#@#  
Data Availability: The Supplementary Material contains additional results, as well as data and code to replicate the analyses.  #@NEW_LINE#@#  You can download it from: https://zenodo.org/badge/latestdoi/75610836 (DOI:10.5281/zenodo.192607).  #@NEW_LINE#@#  
Funding: As part of the GlottoBank Project, this work was supported by the Max Planck Institute for the Science of Human History and the Royal Society of New Zealand Marsden Fund grant 13¬UOA-121.  #@NEW_LINE#@#  This paper was further supported by the DFG research fellowship grant 261553824 Vertical and lateral aspects of Chinese dialect history (JML), and the Australian Research Councils Discovery Projects funding scheme (project number DE120101954, SJG).  #@NEW_LINE#@#  
Competing interests:  The authors have declared that no competing interests exist.  #@NEW_LINE#@#  
Introduction  #@NEW_LINE#@#  
Historical linguistics is currently facing a dramatic increase in digitally available datasets [15].  #@NEW_LINE#@#  The availability of data for more and more languages and language families challenges the ways in which we traditionally compare them.  #@NEW_LINE#@#  The comparative method has been the core method for linguistic reconstruction for the past 200 years [6], and is based on manually identifying systematic phonetic correspondences between many words in pairs of languages.  #@NEW_LINE#@#  However, there are too few expert historical linguists to analyse the worlds more than 7500 languages [7] and, consequently, only a small percentage of these languages have been thoroughly investigated leaving us in the dark about their history and relationships.  #@NEW_LINE#@#  This becomes especially evident in largely understudied linguistic areas like New Guinea, parts of South America, or the Himalayan region, and our lack of knowledge about these languages has immediate implications for our understanding of human prehistory.  #@NEW_LINE#@#  
Over the last two decades computational methods have been become more prevalent in historical linguistics.  #@NEW_LINE#@#  Advocates of computational methods emphasize the speed and replicability as the main advantage of computational techniques [8, 9].  #@NEW_LINE#@#  However, sceptics criticise the validity and accuracy of these methods as lagging far behind those achieved by human experts.  #@NEW_LINE#@#  [10].  #@NEW_LINE#@#  One approach in computational historical linguistics is to design fully-automated methods to identify language relationships with no input from researchers [11, 12].  #@NEW_LINE#@#  Although these methods may provide interesting insights into linguistic macroareas [13], their black-box character makes it difficult to evaluate the results, as judgements about sound correspondences and decisions of cognacy are hidden.  #@NEW_LINE#@#  This opacity makes it difficult to improve the algorithms.  #@NEW_LINE#@#  More problematically, however, it limits the scientific value of these methods, as we do not just want to know how languages are related, but why and which pieces of evidence support this conclusion.  #@NEW_LINE#@#  As a result, there is much suspicion about these methods in historical linguistics [1416].  #@NEW_LINE#@#  
Another approachthe one we take hereis to opt for a computer-assisted framework.  #@NEW_LINE#@#  In contrast to fully automated frameworks, computer-assisted frameworks seek to support and facilitate the task of language comparison by using human expertise where available to correct errors and improve the quality of the results.  #@NEW_LINE#@#  One of the core tasks of the comparative method is the identification of cognate words in multiple languages.  #@NEW_LINE#@#  If two words are cognate, this means that they are genetically related, and have descended from a common ancestor [17].  #@NEW_LINE#@#  Cognate identification, along with the identification of regular sound correspondences, is the basis for proving that two or more languages are genetically related.  #@NEW_LINE#@#  It is also the basis for the reconstruction of ancestral word forms in historically unattested languages, and for the genetic classification of language families.  #@NEW_LINE#@#  In practice, cognate identification is a time-consuming process that is based on an iterative manual procedure where cognate sets are proposed, evaluated, and either kept or rejected [18].  #@NEW_LINE#@#  
This process of manual cognate identification should be an ideal candidate for computer-assisted tasks.  #@NEW_LINE#@#  As a possible workflow, scholars could first run an automatic cognate detection analysis and then edit the algorithmic findings.  #@NEW_LINE#@#  Even an iterative workflow in which the data is passed between computers and experts would be fruitful.  #@NEW_LINE#@#  An important question which arises in this context concerns the quality of automatic methods for cognate detection: Are these methods really good enough to provide concrete help to a highly trained expert?  #@NEW_LINE#@#  In order to find an answer to this question, we tested four publicly available methods and one newly proposed method for automatic cognate detection on six test sets covering five different language families, evaluated the performance of these methods, and determined their shortcomings.  #@NEW_LINE#@#  

Materials_and_Methods  #@NEW_LINE#@#  
Materials  #@NEW_LINE#@#  
There are few datasets available for testing the potential of cognate detection methods on language data, As such, testing algorithms run the risk of over-fitting.  #@NEW_LINE#@#  When developing an algorithm, one usually trains it on some datasets.  #@NEW_LINE#@#  If those datasets are afterwards used to also test the algorithm, the accuracy should be quite high, but we cannot tell whether the method will work on datasets apart from the ones on which the algorithm was trained.  #@NEW_LINE#@#  For this reason, it is important to split the available data into a training set and a test set.  #@NEW_LINE#@#  In our case, the training set will be used to determine the best parameters for each of the algorithms we test, while the test set will be used to carry out the actual test of cognate recovery.  #@NEW_LINE#@#  
For this study, we took training data from existing sources [19], while a new test dataset was compiled from scratch.  #@NEW_LINE#@#  The new test set consists of six datasets from five language families.  #@NEW_LINE#@#  These data were collected from different sources, including published datasets [3, 2023], books [24], and ongoing research by scholars who allowed us to use parts of their data in advance (Uralex project, [25]).  #@NEW_LINE#@#  All datasets were formatted to tabular format and semi-automatically cleaned for various kinds of errors, like misspelled phonetic transcriptions, empty word slots, or obviously erroneous cognate judgments.  #@NEW_LINE#@#  We further linked all languages to Glottolog [7], and all wordlist concepts to the Concepticon [26].  #@NEW_LINE#@#  
Table 1 lists all datasets along with additional details, such as the number of words, concepts, languages, and cognate sets in the data.  #@NEW_LINE#@#  The diversity index given in the last column of the table is calculated by dividing the difference between cognate sets and meanings with the difference between words and meanings [19].  #@NEW_LINE#@#  This score, which ranges between 0 and 1, indicates whether large numbers of words in a given dataset are unrelated (high index) or are cognate (low index).  #@NEW_LINE#@#  As can be seen from the diversity indices listed in the table, our test sets have varying degrees of diversity, ranging from 0.07 (Romance, Saenko, 2015) to 0.57 (Uralic).  #@NEW_LINE#@#  
As mentioned above, training data is needed for parameter estimation.  #@NEW_LINE#@#  The key parameter we need to estimate is the best thresholds for cognate identification in some of the methods.  #@NEW_LINE#@#  As training data we employed the collection of benchmark datasets for automatic cognate detection by List [19], which also covers six datasets from five language families.  #@NEW_LINE#@#  Details for this dataset (number of words, concepts, languages, cognate sets, and the diversity index) are given in Table 2.  #@NEW_LINE#@#  This dataset is available online at http://dx.doi.org/10.5281/zenodo.11877.  #@NEW_LINE#@#  

Methods  #@NEW_LINE#@#  

Threshold_and_Parameter_Selection  #@NEW_LINE#@#  
Apart from the Turchin method, all analyses require a threshold which ranges between 0 and 1, denoting the amount of similarity needed to judge two items as cognate.  #@NEW_LINE#@#  In order to find the most suitable threshold for each of the three methods, we used the expert cognate decisions in our training set and ran the analyses on these data with varying thresholds starting from 0.05 up to 0.95.  #@NEW_LINE#@#  Fig 2 shows box-plots of the training analyses for the four methods, depending on the threshold.  #@NEW_LINE#@#  As can be seen from this figure, all methods show a definite peak where they yield the best results for all datasets.  #@NEW_LINE#@#  In order to select the best threshold for each of the four methods, we selected the threshold which showed the best average B-Cubed F-Score (i.e.  #@NEW_LINE#@#  the best accuracy at recovering the known cognate sets).  #@NEW_LINE#@#  For the Edit Distance Method, the threshold was thus set to 0.75, for the SCA Method it was set to 0.45, for the LexStat Method, it was set to 0.60, and for the Infomap method, it was set to 0.55.  #@NEW_LINE#@#  The B-Cubed scores for these analyses are given in Table 6.  #@NEW_LINE#@#  These results indicate that the Infomap method performs best, followed by LexStat and SCA.  #@NEW_LINE#@#  Of the two worst-performing methods, the Turchin method performs worst in terms of F-Scores, but shows a much higher precision than the Edit-Distance method.  #@NEW_LINE#@#  


Results  #@NEW_LINE#@#  
We analyzed the datasets with each of the five methods described above, using the individual thresholds for each method, setting the number of permutations to 10,000, and using the default parameters in LingPy.  #@NEW_LINE#@#  For each analysis, we further calculated the B-Cubed scores to evaluate the performance of each method on each dataset.  #@NEW_LINE#@#  
Table 7 shows the averaged results of our experiments.  #@NEW_LINE#@#  While the LexStat method shows the highest precision, the Infomap method shows the highest recall and also the best general performance.  #@NEW_LINE#@#  The results are generally consistent with those reported by List [19] for the performance of Turchin, Edit Distance, SCA, and LexStat: The Turchin method is very conservative with a low amount of false positives as reflected by the high precision, but a very large amount of undetected cognate relations as reflected by the low recall.  #@NEW_LINE#@#  The Edit Distance method shows a much higher cognate detection rate, but at the cost of a high rate of false positives.  #@NEW_LINE#@#  The SCA method outperforms the Edit Distance, thus showing that refined distance scores can make a certain difference in automatic cognate detection.  #@NEW_LINE#@#  


              https://doi.org/10.1371/journal.pone.0170046.t007  #@NEW_LINE#@#  
However, as the performance of LexStat and Infomap shows: Language-specific approaches for cognate detection clearly outperform language-independent approaches.  #@NEW_LINE#@#  The reason for this can be found in the specific similarity measure that is employed by the methods: the better performing methods are not based on surface similarities, but on similarities derived from previously inferred probability scores for sound correspondences.  #@NEW_LINE#@#  These methods are therefore much closer to the traditional comparative method than methods which employ simple surface similarities between sounds.  #@NEW_LINE#@#  Our experiment with the Infomap algorithm shows that a shift from simple agglomerative clustering approaches to a network perspective may further strengthen the results.  #@NEW_LINE#@#  Similarity networks have been successfully employed in evolutionary biology for some time now and should now become a fruitful topic of research in computational historical linguistics as well.  #@NEW_LINE#@#  
Dataset_Specific_Results  #@NEW_LINE#@#  
There are interesting differences between method performance across language datasets, with marked variation in cognate identification accuracy between different languages.  #@NEW_LINE#@#  Fig 3 shows the performance of the methods on the individual test sets, indicating which method performed best and which method performed worst.  #@NEW_LINE#@#  These results confirm the high accuracy of the LexStat method and the even better accuracy of the Infomap approach.  #@NEW_LINE#@#  All methods apart from the Turchin method perform the worst on the Chinese data.  #@NEW_LINE#@#  Since compounding is very frequent in Chinese, it is difficult to clearly decide which words to assign to the same cognate set.  #@NEW_LINE#@#  Often, words show some overlap of cognate material without being entirely cognate.  #@NEW_LINE#@#  This is illustrated in Fig 4, where cognates and partial cognates for Germanic and Sinitic languages are compared.  #@NEW_LINE#@#  We followed a strict procedure by which only words in which all morphemes are cognate are labelled as cognate [62], rather than loosely placing all words sharing a single cognate morpheme in the same cognate set [63].  #@NEW_LINE#@#  Since neither of the algorithms we tested is specifically sensitive for partial cognate relations (for a recent proposal for this task, see [53]), they all show a very low precision, because they tend to classify only partially related words as fully cognate.  #@NEW_LINE#@#  
The Turchin method has three extreme outliers in which it lags far behind the other methods: Chinese, Bahnaric and Romance.  #@NEW_LINE#@#  There are two major reasons for this.  #@NEW_LINE#@#  First, the Turchin method only compares the first two consonants and will be seriously affected by the problem of partial cognates discussed above.  #@NEW_LINE#@#  These partial cognates are especially prevalent in Chinese and Bahnaric where compounding is an important linguistic process.  #@NEW_LINE#@#  Second, a specific weakness of the Turchin method is the lack of an alignment and words are not exhaustively compared for structural similarities but simply mapped in their first two initial consonants.  #@NEW_LINE#@#  When there is substantial sound change, as is evident in both Bahnaric and some branches of Romance, this may lead to an increased amount of false negatives.  #@NEW_LINE#@#  Since the Turchin method only distinguishes 10 different sound classes and only compares the first two consonant classes in each word in the data, it is very likely to miss obvious cognates.  #@NEW_LINE#@#  The main problem here is that the method does not allow for any transition probabilities between sound classes, but treats them as discrete units.  #@NEW_LINE#@#  As a result, it is likely that the Turchin method often misses valid cognate relations which are easily picked up by the other methods.  #@NEW_LINE#@#  This shortcoming of the Turchin approach is illustrated in Fig 5, where the amount of true positives and negatives is contrasted with the amount of false positives and negatives in each dataset and for each of the five methods.  #@NEW_LINE#@#  This figure indicates that the Turchin method shows exceptionally high amounts of false negatives in Bahnaric and Romance.  #@NEW_LINE#@#  The clear advantage of the Turchin method is its speed, as it can be computed in linear time.  #@NEW_LINE#@#  Its clear disadvantage is its simplicity which may under certain circumstances lead to a high amount of false negatives.  #@NEW_LINE#@#  
The Edit-Distance method also performs very poorly.  #@NEW_LINE#@#  While, on average, it performs better than the Turchin approach, it performs considerably worse on the Chinese and Huon test sets.  #@NEW_LINE#@#  The reason for this poor performance can be found in a high amount of false positives as shown in Fig 5.  #@NEW_LINE#@#  While the Turchin method suffers from not finding valid cognates, the Edit-Distance method suffers from the opposite problemidentifying high amounts of false cognates.  #@NEW_LINE#@#  Since false positives are more deleterious for language comparison, as they might lead to false conclusions about genetic relationship [15], the Edit-Distance method should be used with very great care.  #@NEW_LINE#@#  Given that the SCA method performs better while being similarly fast, there is no particular need to use the Edit-Distance method at all.  #@NEW_LINE#@#  
In Fig 6, we further illustrate the difference between the worst and the best approaches in our study by comparing false positives and false negatives in Turchin and Infomap across all language pairs in the Chinese data.  #@NEW_LINE#@#  As can be seen from Fig 5, the Turchin approach has about as many false positives as false negatives.  #@NEW_LINE#@#  The Infomap approach shows slightly more false positives than false negatives.  #@NEW_LINE#@#  This general picture, however, changes when looking at the detailed data plotted in Fig 6.  #@NEW_LINE#@#  Here, we can see that false positives in the Turchin approach occur in almost all dialect pairings, while the major number of cognates is missed in the mainland dialects (bottom of the y-axis).  #@NEW_LINE#@#  Infomap, on the other hand, shows drastically fewer false positives and false negatives, but while false negatives can be mostly observed in the Northern dialects (bottom of y-axis), false positives seem to center around the highly diverse Southern dialects (top of the y-axis).  #@NEW_LINE#@#  This reflects the internal diversity in Northern and Southern Chinese dialects, and the challenges resulting from it for automatic cognate detection.  #@NEW_LINE#@#  While word compounding is very frequent in the North of China, where almost all words are bisyllabic and bimorphemic, the Southern dialects often preserve monosyllabic words.  #@NEW_LINE#@#  While Northern dialects are rather homogeneous, showing similar sound systems and a rather large consonant inventories, Southern dialects have undergone many consonant mergers in their development, and are highly diverse.  #@NEW_LINE#@#  The unique threshold for cognate word detection overestimates similarities among the Southern dialects (upper triangle, left quarter), while it underestimates similarities among Northern dialects compared to Southern dialects (lower triangle, left quarter).  #@NEW_LINE#@#  What further contributes to this problem is also the limited size of the word lists in our sample, which make it difficult for the language-specific algorithms to acquire enough deep signal.  #@NEW_LINE#@#  


Discussion  #@NEW_LINE#@#  
In this study we have applied four published methods and one new method for automated cognate detection to a set of six different test sets from five different language families.  #@NEW_LINE#@#  By training our data on an already published dataset of similar size, we identified the best thresholds to obtain a high accuracy for detecting truly related words for four out of the five methods (Edit-Distance: 0.75, SCA: 0.45, LexStat: 0.6, Infomap: 0.55).  #@NEW_LINE#@#  Using these thresholds, we tested the methods on our new gold standard, and found that most methods identified cognates with a considerable amount of accuracy ranging from 0.82 (Tuchin) to 0.89 (Infomap).  #@NEW_LINE#@#  Our new method, which builds on the LexStat method but employs the Infomap algorithm for community detection to partition words into cognate sets, outperforms all other methods in almost all regards, slightly followed by the LexStat approach.  #@NEW_LINE#@#  Given that the LexStat method and our Infomap approach are based on language-specific language comparison, searching for similar patterns in individual language pairs, our results confirm the superiority of cognate detection approaches which are closer to the theoretical foundation of the classical comparative method in historical linguistics.  #@NEW_LINE#@#  The Consonant Class Matching method by Turchin et al.  #@NEW_LINE#@#  confirmed worst in our experiment, followed by the Edit-Distance approach, which was criticized in earlier work [15].  #@NEW_LINE#@#  While the major drawback of the Turchin approach is a rather large amount of false negatives, the Edit-Distance approach shows the highest amount of false positives in our test.  #@NEW_LINE#@#  
The method of choice may well depend on the task to which cognate detection is to be applied.  #@NEW_LINE#@#  If the task is to simply identify some potential cognates for future inspection and annotation, then a fast algorithm like the one by Turchin et al.  #@NEW_LINE#@#  should provide enough help to get started.  #@NEW_LINE#@#  This practice, which is already applied by some scholars [64], is further justified by the rather small amount of false positives.  #@NEW_LINE#@#  While the use of the Turchin method may be justified in computer-assisted workflows, the use of the Edit-Distance approach should be discouraged, since it lacks the speed advantages and is very prone to false positives.  #@NEW_LINE#@#  
When searching for deeper signals in larger datasets, however, we recommend using the more advanced methods, like SCA, LexStat or our new Infomap approach.  #@NEW_LINE#@#  LexStat and Infomap have the great advantage of taking regular sound correspondences into account.  #@NEW_LINE#@#  As a result, these methods tend to refuse chance resemblances and borrowings.  #@NEW_LINE#@#  Their drawback is the number of words needed to carry out the analysis.  #@NEW_LINE#@#  As we know from earlier tests [65], language-specific methods require at least 200 words for moderately closely related languages.  #@NEW_LINE#@#  When applied to datasets with higher diversity among the languages, the number of words should be even higher.  #@NEW_LINE#@#  Thus, when searching for cognates in very short word lists, we recommend using the SCA method to achieve the greatest accuracy.  #@NEW_LINE#@#  However, as demonstrated by the poorer performance of all methods on the Chinese language data where compounding has played a major role in word formation, language family specific considerations about the methods and processes need to be taken into consideration.  #@NEW_LINE#@#  
Our results show that the performance of computer-assisted automatic cognate detection methods has advanced substantially, both with respect to the applicability of the methods and the accuracy of the results.  #@NEW_LINE#@#  Moreover, given that the simple change we made from agglomerative to network-based clustering could further increase the accuracy of the results, shows that we have still not exhausted the full potential of cognate detection methods.  #@NEW_LINE#@#  Future algorithms may bring us even closer to experts judgments, and it seems worthwhile to invest time to increase the performance of our algorithms.  #@NEW_LINE#@#  Essential tasks for the future include (a) the work on parameter-free methods which do not require user-defined thresholds and state the results as probabilities rather as binary decisions, (b) the further development of methods for partial cognate detection [53], (c) approaches that search for cognates not only in the same meaning slot but across different meanings [66], and (d) approaches that integrate expert annotations to allow for a true iterative workflow for computer-assisted language comparison.  #@NEW_LINE#@#  A key problem to solve is the performance of these methods on larger datasets that trace language relationships to a greater depth.  #@NEW_LINE#@#  Most of our test cases in this paper are shallow families or subgroups of larger families.  #@NEW_LINE#@#  Deeper relationships between languages spoken in more complicated language situations are where the real challenge lies.  #@NEW_LINE#@#  
Currently automatic cognate detection algorithms are highly accurate at detecting a substantial proportion of the cognates in a lexical dataset.  #@NEW_LINE#@#  Tools like LingPy are already at a stage where they can act as a computer-assisted framework for language comparison.  #@NEW_LINE#@#  These tools therefore provide a powerful way of supplementing the historical linguistics toolkit by enabling linguists to rapidly identify the cognate sets which can then be checked, corrected, and augmented as necessary by experts.  #@NEW_LINE#@#  In regions where there has been an absence of detailed historical comparative work, these automated cognate assignments can provide a way to pre-process linguistic data from less well studied languages and speed up the process by which experts apply the comparative method.  #@NEW_LINE#@#  Additionally, these tools can be employed for exploratory data analysis of larger datasets, or to arrive at preliminary classifications for language families which have not yet been studied with help of the classical methods.  #@NEW_LINE#@#  

Acknowledgments  #@NEW_LINE#@#  
We thank the anonymous reviewers for helpful advice.  #@NEW_LINE#@#  We thank Outi Vesakoski and Jury Lehtinen (Uralic data from the Uralex project), Paul Sidwell (Bahnaric), George Starostin (Tujia), and M. Saenko (Romance) for sharing their data with us by either exchanging them directly or making them accessible online.  #@NEW_LINE#@#  

Author_Contributions  #@NEW_LINE#@#  


Conceptualization: JML SJG RDG.  #@NEW_LINE#@#  
Data curation: JML.  #@NEW_LINE#@#  
Formal analysis: JML SJG.  #@NEW_LINE#@#  
Funding acquisition: SJG RDG.  #@NEW_LINE#@#  
Investigation: JML SJG.  #@NEW_LINE#@#  
Methodology: JML SJG.  #@NEW_LINE#@#  
Project administration: RDG.  #@NEW_LINE#@#  
Software: JML.  #@NEW_LINE#@#  
Validation: JML SJG RDG.  #@NEW_LINE#@#  
Visualization: JML SJG.  #@NEW_LINE#@#  
Writing  original draft: JML.  #@NEW_LINE#@#  
Writing  review & editing: JML SJG RDG.  #@NEW_LINE#@#  



References  #@NEW_LINE#@#  



