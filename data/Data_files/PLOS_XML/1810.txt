article id="http://dx.doi.org/10.1371/journal.pmed.1002427"  #@NEW_LINE#@#  
title  #@NEW_LINE#@#  
Association between the 2012 Health and Social Care Act and specialist visits and hospitalisations in England: A controlled interrupted time series analysis  #@NEW_LINE#@#  

Abstract  #@NEW_LINE#@#  
Background  #@NEW_LINE#@#  
The 2012 Health and Social Care Act (HSCA) in England led to among the largest healthcare reforms in the history of the National Health Service (NHS).  #@NEW_LINE#@#  It gave control of £67 billion of the NHS budget for secondary care to general practitioner (GP) led Clinical Commissioning Groups (CCGs).  #@NEW_LINE#@#  An expected outcome was that patient care would shift away from expensive hospital and specialist settings, towards less expensive community-based models.  #@NEW_LINE#@#  However, there is little evidence for the effectiveness of this approach.  #@NEW_LINE#@#  In this study, we aimed to assess the association between the NHS reforms and hospital admissions and outpatient specialist visits.  #@NEW_LINE#@#  

Methods_and_findings  #@NEW_LINE#@#  
We conducted a controlled interrupted time series analysis to examine rates of outpatient specialist visits and inpatient hospitalisations before and after the implementation of the HSCA.  #@NEW_LINE#@#  We used national routine hospital administrative data (Hospital Episode Statistics) on all NHS outpatient specialist visits and inpatient hospital admissions in England between 2007 and 2015 (with a mean of 26.8 million new outpatient visits and 14.9 million inpatient admissions per year).  #@NEW_LINE#@#  As a control series, we used equivalent data on hospital attendances in Scotland.  #@NEW_LINE#@#  Primary outcomes were: total, elective, and emergency hospitalisations, and total and GP-referred specialist visits.  #@NEW_LINE#@#  Both countries had stable trends in all outcomes at baseline.  #@NEW_LINE#@#  In England, after the policy, there was a 1.1% (95% CI 0.7%1.5%; p less_than 0.001) increase in total specialist visits per quarter and a 1.6% increase in GP-referred specialist visits (95% CI 1.2%2.0%; p less_than 0.001) per quarter, equivalent to 12.7% (647,000 over the 5,105,000 expected) and 19.1% (507,000 over the 2,658,000 expected) more visits per quarter by the end of 2015, respectively.  #@NEW_LINE#@#  In Scotland, there was no change in specialist visits.  #@NEW_LINE#@#  Neither country experienced a change in trends in hospitalisations: change in slope for total, elective, and emergency hospitalisations were 0.2% (95% CI 0.6%0.2%; p = 0.257), 0.2% (95% CI 0.6%0.1%; p = 0.235), and 0.0% (95% CI 0.5%0.4%; p = 0.866) per quarter in England.  #@NEW_LINE#@#  We are unable to exclude confounding due to other events occurring around the time of the policy.  #@NEW_LINE#@#  However, we limited the likelihood of such confounding by including relevant control series, in which no changes were seen.  #@NEW_LINE#@#  

Conclusions  #@NEW_LINE#@#  
Our findings suggest that giving control of healthcare budgets to GP-led CCGs was not associated with a reduction in overall hospitalisations and was associated with an increase in specialist visits.  #@NEW_LINE#@#  


Author_summary  #@NEW_LINE#@#  
Why_was_this_study_done?  #@NEW_LINE#@#  

What_did_the_researchers_do_and_find?  #@NEW_LINE#@#  

What_do_these_findings_mean?  #@NEW_LINE#@#  


Citation: Lopez Bernal JA, Lu CY, Gasparrini A, Cummins S, Wharham JF, Soumerai SB (2017) Association between the 2012 Health and Social Care Act and specialist visits and hospitalisations in England: A controlled interrupted time series analysis.  #@NEW_LINE#@#  PLoS Med 14(11):  #@NEW_LINE#@#  
           e1002427.  #@NEW_LINE#@#  

        https://doi.org/10.1371/journal.pmed.1002427  #@NEW_LINE#@#  
Academic Editor: Aziz Sheikh, Edinburgh University, UNITED KINGDOM  #@NEW_LINE#@#  
Received: April 26, 2017; Accepted: October 5, 2017; Published:  November 14, 2017  #@NEW_LINE#@#  
Copyright:  © 2017 Lopez Bernal et al.  #@NEW_LINE#@#  This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.  #@NEW_LINE#@#  
Data Availability: All relevant data are within the paper and its Supporting Information files.  #@NEW_LINE#@#  
Funding: This study was funded by a UK Medical Research Council Population Health Scientist Fellowship awarded to JLB  Grant Ref: MR/L011891/1, https://www.mrc.ac.uk/.  #@NEW_LINE#@#  No funding bodies had any role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.  #@NEW_LINE#@#  
Competing interests:  The authors have declared that no competing interests exist.  #@NEW_LINE#@#  
Abbreviations:  #@NEW_LINE#@#  
          CCG,  #@NEW_LINE#@#  
            Clinical Commissioning Group; CITS,  #@NEW_LINE#@#  
            controlled interrupted time series; DH,  #@NEW_LINE#@#  
            Department of Health; GP,  #@NEW_LINE#@#  
            general practitioner; HES,  #@NEW_LINE#@#  
            Hospital Episode Statistics; HSCA,  #@NEW_LINE#@#  
            Health and Social Care Act; NHS,  #@NEW_LINE#@#  
            National Health Service; PCT,  #@NEW_LINE#@#  
            primary care trust; RECORD,  #@NEW_LINE#@#  
            REporting of studies Conducted using Observational Routinely-collected health Data; SHA,  #@NEW_LINE#@#  
            Strategic Health Authority; SMR,  #@NEW_LINE#@#  
            Scottish Medical Records  #@NEW_LINE#@#  
Introduction  #@NEW_LINE#@#  
The 2012 Health and Social Care Act (HSCA) in England has been described as the biggest and most far reaching [reorganisation] in the history of the NHS [1, 2].  #@NEW_LINE#@#  The reforms centred around the introduction of general practitioner (GP) led Clinical Commissioning Groups (CCGs), which received about two-thirds of the National Health Service (NHS) budget (£66.8 billion in 20152016) to commission (plan and contract) secondary care, including hospital and specialist services [1].  #@NEW_LINE#@#  CCGs represent all GP practices in their local area, and the key difference from the previous commissioning structures was purported to be a major new role for GPs as key decision makers in the commissioning process [1, 3, 4].  #@NEW_LINE#@#  
Health policy experts and parliamentary and professional bodies have hypothesised that GP-led commissioning could potentially lead to reductions in referrals to specialist care, as either an intended or unintended consequence of the Act [510].  #@NEW_LINE#@#  They theorise that by giving the gatekeepers, who control access to specialist care, a greater role in budget holding and the purchasing of specialist care, they may be incentivised to reduce referrals [5, 6].  #@NEW_LINE#@#  Indeed, Smith and Mays suggest that the primary rationale for GP-led commissioning is to encourage a shift away from expensive secondary care towards more community-based care [6].  #@NEW_LINE#@#  Furthermore, 2 out of the 3 main reasons cited by the government for introducing the reforms centred around a need to control costs, although the mechanisms by which GP-led CCGs would achieve cost savings were not made explicit [4].  #@NEW_LINE#@#  While the potential for much-needed cost savings in the NHS as a result of reduced secondary care activity has been viewed positively, someincluding the National Audit Office and the Royal College of Surgeonshave raised concerns that a reduction in referrals as a consequence of the HSCA and policies introduced by CCGs could result in inequitable rationing of care and missed diagnoses and that their role in commissioning presents GPs with a conflict of interest [710].  #@NEW_LINE#@#  
CCGs and GPs could reduce secondary care activity through various means, including restricting referral criteria, developing community-based care models, investing in preventative healthcare, or promoting services to prevent readmissions [6, 9, 10].  #@NEW_LINE#@#  There also exist potential incentives for them to do so: reducing expensive care would allow CCGs to invest savings in other services.  #@NEW_LINE#@#  Furthermore CCGs are required to maintain a surplus; otherwise, they cannot access additional funding in the form of a Quality Premium of up to £5 per person within the population covered by the CCG person [11].  #@NEW_LINE#@#  In addition, there are incentives to individual GPs: savings from reduced specialist visits and hospitalisations could allow investment in community-based services provided by GP practices themselves; also, some CCGs have introduced direct payments of £6,000£11,000 to GP practices for reducing referral rates [7, 8].  #@NEW_LINE#@#  Nevertheless, whether these provide a real incentive in practice depends on how engaged GPs feel with the new commissioning organisations, how much responsibility they feel for their budgets, and how much influence they have on the commissioning process.  #@NEW_LINE#@#  Previous policies that have begun with an intention to place GPs at the centre of commissioning have ultimately resulted in the formation of bureaucratic bodies that have become detached from local practitioners [6].  #@NEW_LINE#@#  Furthermore, given existing evidence that increasing GP workload may increase referral rates, it is possible that the increased administrative burden associated with their new commissioning role could instead result in an increase in referrals [12, 13].  #@NEW_LINE#@#  
We use a controlled interrupted time series (CITS) design to compare changes in the trends of specialist referrals and hospital admissions in England before and after the HSCA with those in Scotland, where the reforms did not occur.  #@NEW_LINE#@#  We hypothesise that the 2012 HSCA was associated with a reduction in specialist visits and hospitalisations.  #@NEW_LINE#@#  

Methods  #@NEW_LINE#@#  
Ethics  #@NEW_LINE#@#  
Ethical approval was obtained from the London School of Hygiene and Tropical Medicine Observational/Interventions Research Ethics Committee (LSHTM Ethics Ref: 10505).  #@NEW_LINE#@#  

The_intervention  #@NEW_LINE#@#  
The 2012 HSCA introduced broad ranging and complex reforms to the NHS and public health services in England.  #@NEW_LINE#@#  These have been described in more detail elsewhere [1, 2, 4, 14, 15].  #@NEW_LINE#@#  The principal change was in the way secondary care services were commissioned within the NHS.  #@NEW_LINE#@#  Prior to 2012, regional healthcare administrative bodies known as primary care trusts (PCTs) and Strategic Health Authorities (SHAs) were responsible for all commissioning.  #@NEW_LINE#@#  These were abolished as part of the Act and were replaced by CCGs.  #@NEW_LINE#@#  CCGs are led by a governing body, which includes a representative from each member GP practice, lay members, a secondary care doctor, and a registered nurse [3].  #@NEW_LINE#@#  CCGs were first introduced in shadow form (working alongside PCTs) in April 2012 following the enactment of the HSCA; they then took over full budgetary responsibility in March 2013 [1].  #@NEW_LINE#@#  

Control  #@NEW_LINE#@#  
While a control is not required in interrupted time series studies, the primary comparison being between preintervention and postintervention trends within the study population, a control population can help to exclude additional confounding events and cointerventions.  #@NEW_LINE#@#  Healthcare is a largely devolved power in the United Kingdom and the HSCA only applied to England; therefore, we considered the other 3 nations of the UK (Northern Ireland, Scotland, and Wales) as potential controls.  #@NEW_LINE#@#  These are neighbouring countries with similar population demographics (S1 Table), similar health systems, and shared political structures.  #@NEW_LINE#@#  Data equivalent to those in England were not available from Northern Ireland; therefore, it was excluded.  #@NEW_LINE#@#  We chose Scotland as the control, as preintervention data were more stable than for Wales.  #@NEW_LINE#@#  We also include an analysis as a supplementary appendix with Wales as the control (S2 Table, S1 and S2 Figs).  #@NEW_LINE#@#  

Data_and_study_population  #@NEW_LINE#@#  
We obtained quarterly data on all hospital admissions and outpatient specialist visits in NHS hospitals in England between April 2007 and December 2015 from the Health and Social Care Information Centre: Hospital Episode Statistics (HES) [16].  #@NEW_LINE#@#  Hospital admissions include all inpatients in NHS hospitals as well as NHS-funded inpatients in the private sector.  #@NEW_LINE#@#  NHS outpatient activity in England is hospital based; specialist visit data include outpatients in English NHS hospitals and NHS-funded outpatients in the private sector.  #@NEW_LINE#@#  Our outcomes were total hospital admissions, elective (planned) and emergency (unplanned) admissions, total first specialist visits (excluding follow-up appointments), and GP-referred first specialist visits.  #@NEW_LINE#@#  Equivalent data for Scotland were obtained from the NHS Scotland Information Services Division: Scottish Medical Records (SMR) [17].  #@NEW_LINE#@#  We obtained demographic data for England and Scotland from the Office for National Statistics including midyear population estimates (for denominators), age and sex distribution, crude birth rate, and crude death rate [18].  #@NEW_LINE#@#  The Scottish hospital admission data did not include obstetric and psychiatric hospitals and the outpatient visit data did not include visits to nurses, dentists, or other allied health professionals.  #@NEW_LINE#@#  We therefore excluded these categories from the English data to make the 2 datasets comparable.  #@NEW_LINE#@#  Data quality reports identified a coding error in the outpatient data prior to April 2010 (3 years before the introduction of the policy); we therefore excluded these data from the analysis [19].  #@NEW_LINE#@#  The raw data are provided in the supplementary appendix (S1 and S2 Data).  #@NEW_LINE#@#  A complete list of the data codes and algorithms used in the data extraction is also provided in the supplementary appendix (S3 and S4 data).  #@NEW_LINE#@#  

Statistical_analysis  #@NEW_LINE#@#  
We used a CITS design, which allowed us to control both for preintervention trends in the outcome and for potential confounding events that would have affected both the control and the study groups.  #@NEW_LINE#@#  Although a Poisson distribution is assumed for individual counts, we had very large numbers and the aggregate data were well approximated by a Gaussian distribution (log transformed).  #@NEW_LINE#@#  Therefore, we used a simple linear segmented regression model to estimate the change in trend in hospital admissions and outpatient visits following the introduction of the HSCA [20].  #@NEW_LINE#@#  In order to account for the year during which CCGs were in shadow form, we allowed a one-year phase-in period by excluding the second quarter of 2012 to the first quarter of 2013 from the analysis.  #@NEW_LINE#@#  We modelled the association as a slope change rather than an immediate level change because choice of providers and referral patterns were likely to change gradually when existing contracts expired and new models of care developed [1].  #@NEW_LINE#@#  Adjustments were made for any seasonal effect using a Fourier term [20].  #@NEW_LINE#@#  
We first estimated the slope changes in England and in Scotland independently.  #@NEW_LINE#@#  We then used an interaction model for the CITS to estimate the additional trend change in England over and above any change in Scotland, while controlling for any difference in the preintervention trends of the 2 groups (S1 Text).  #@NEW_LINE#@#  We examined the preintervention data a priori for linearity and autocorrelation at different lags using scatterplots, plots of residuals, and partial autocorrelation functions [20].  #@NEW_LINE#@#  A linear trend provided a reasonable fit for all outcomes in the primary model.  #@NEW_LINE#@#  We included an autoregressive term at the appropriate lag to adjust for any detected autocorrelation.  #@NEW_LINE#@#  All analyses were conducted using Stata version 14.  #@NEW_LINE#@#  

Protocol  #@NEW_LINE#@#  
The original study protocol from the ethics application is available as a supplementary appendix (S1 Protocol).  #@NEW_LINE#@#  The analysis has only differed from this protocol in that Scotland was selected as the primary control, as it had the most stable data; Wales was included as an additional control following reviewers recommendations.  #@NEW_LINE#@#  Northern Ireland was not included as equivalent data to that in England was not available.  #@NEW_LINE#@#  Furthermore, in this protocol, we also proposed including patient experience measures as secondary outcomes; this was ultimately not included within the current study but we plan to conduct a future study looking at the potential impact on patient experience.  #@NEW_LINE#@#  

Reporting  #@NEW_LINE#@#  
This study is reported as per the REporting of studies Conducted using Observational Routinely-collected health Data (RECORD) Statement (S1 Checklist).  #@NEW_LINE#@#  


Results  #@NEW_LINE#@#  
Population_characteristics  #@NEW_LINE#@#  
Age and sex distributions were similar in both England and Scotland (Table 1 and S1 Table).  #@NEW_LINE#@#  Both populations were slowly aging; the proportion aged 60 or older increased from 21.6% to 23.0% in England and from 22.3% to 24.0% in Scotland.  #@NEW_LINE#@#  The crude birth rate was consistently about 1.8 per 1,000 higher in England than in Scotland while the crude death rate was consistently about 1.5 per 1,000 lower.  #@NEW_LINE#@#  

Changes_in_outpatient_specialist_visits  #@NEW_LINE#@#  
Changes in trends of specialist visits are shown in Fig 1 and Table 2.  #@NEW_LINE#@#  Absolute counts and the rate per 1,000 for each quarter are presented in Table 3.  #@NEW_LINE#@#  In England, total specialist visits rose slowly by 0.5% per quarter (from 84.7 per 1,000 in quarter 2 [Q2] 2010 to 87.2 per 1,000 in Q1 2012) in the baseline.  #@NEW_LINE#@#  After the intervention, they rose approximately 3.6 times faster at 1.5% per quarter (from 90.0 per 1,000 in Q2 2013 to 104.6 per 1,000 in Q4 2015).  #@NEW_LINE#@#  This was equivalent to an increase in slope (additional quarterly increase) of 1.1% (95% CI 0.7%1.5%), which resulted in a 12.7% higher rate of specialist visits (647,000 additional visits) by the end of the postintervention period in Q4 2015, compared to the underlying (counterfactual) trend.  #@NEW_LINE#@#  The slope increase was even more marked for GP-referred visits.  #@NEW_LINE#@#  During the preintervention period, these had a flat trend at 48.3 visits per 1,000 per quarter (trend 1.000, 95% CI 0.9981.002).  #@NEW_LINE#@#  After the intervention, this trend increased by 1.6% per quarter (from 49.1 per 1,000 in Q2 2013 to 57.6 per 1,000 in Q4 2015).  #@NEW_LINE#@#  This was equivalent to an increase in slope of 1.6% (95% CI 1.2%2.0%) per quarter, which resulted in a 19.1% higher than expected rate of specialist visits (507,000 additional visits) by the end of the study period.  #@NEW_LINE#@#  For those outcomes that showed strong evidence of a trend change (total and GP-referred specialist visits in England), we have presented observed compared to expected counts in the postintervention period in Table 4.  #@NEW_LINE#@#  Total specialist visits had weak evidence of seasonal effect with peaks during Q3 (Fourier sin wave p = 0.055, cos wave p = 0.010).  #@NEW_LINE#@#  
Specialist visits in Scotland, however, showed no significant change after the policy.  #@NEW_LINE#@#  Total specialist visits and GP-referred specialist visits almost level at about 72 per 1,000 per quarter (preintervention trend 1.002, 95% CI 0.9991.006; postintervention trend 1.000, 95% CI 0.9961.003) and 47 per 1,000 per quarter (preintervention trend 1.002, 95% CI 0.9981.005, postintervention trend 1.000, 95% CI 0.9961.003), respectively, throughout the study period.  #@NEW_LINE#@#  
After controlling for trends in Scotland, the CITS analysis produced similar results.  #@NEW_LINE#@#  The magnitude of the change in slope in total specialist visits in England increased slightly to 1.4% (95% CI 0.6%2.1%) per quarter (a 15.9% higher rate by the end of the study period).  #@NEW_LINE#@#  The change in trend in GP-referred specialist visits increased to 1.9% (95% CI 1.1%2.7%) per quarter (a 22.5% higher rate than expected by the end of the study period).  #@NEW_LINE#@#  
The magnitude of the differential increase in trend in England was even greater when using Wales as a control series, although this was partly due to an independent reduction in the trend in Wales (S2 Table and S1 Fig).  #@NEW_LINE#@#  

Changes_in_inpatient_hospitalisations  #@NEW_LINE#@#  
Changes in trends in hospitalisations following the HSCA are shown in Fig 2 and Table 2.  #@NEW_LINE#@#  Absolute counts and the rate per 1,000 for each quarter are presented in Table 5.  #@NEW_LINE#@#  In England, there were slowly increasing trends in all hospitalisations during the baseline period.  #@NEW_LINE#@#  Total hospitalisations increased by 0.5% per quarter (from 60.1 per 1,000 in Q2 2007 to 65.5 per 1,000 in Q1 2012), elective admissions increased by 0.6% per quarter (from 31.7 to 35.7 per 1,000), and emergency admissions increased by 0.3% per quarter (from 22.9 to 24.5 per 1,000).  #@NEW_LINE#@#  Total hospitalisations and emergency hospitalisations had a seasonal effect with winter peaks in Q4 (emergency hospitalisations Fourier terms: sin wave p = 0.002, cos wave p = 0.039).  #@NEW_LINE#@#  There were no statistically significant changes in any of these trends following the HSCA.  #@NEW_LINE#@#  Slope changes were 0.2% (95% CI 0.6%0.2%), 0.2% (95% CI 0.6%0.1%), and 0.0 (95% CI 0.5%0.4%) per quarter for total, elective, and emergency hospitalisations, respectively.  #@NEW_LINE#@#  
Trends in Scotland were flatter during the baseline.  #@NEW_LINE#@#  Total hospitalisations increased by 0.2% per quarter (from 54.0 to 55.9 per 1,000), elective admissions increased by 0.20% per quarter (from 29.9 to 31.1 per 1,000), and emergency admissions increased by 0.2% per quarter (from 24.1 to 24.8 per 1,000).  #@NEW_LINE#@#  Again, there was no evidence of any change in these trends after the HSCA: slope changes were 0.3% (95% CI 0.7%0.2%), 0.1% (95% CI 0.7%0.4%) and 0.5% (95% CI 1.1%0.1%), respectively.  #@NEW_LINE#@#  
The results of the CITS analysis were again similar.  #@NEW_LINE#@#  The differential slope changes in England (that is, the additional quarterly change following the HSCA after controlling for trends in Scotland) were: 0.0% (95% CI 0.6%0.6%) per quarter for total hospitalisations, 0.1% (95% CI 0.7%0.5%) per quarter for elective hospitalisations, and 0.2% (95% CI 0.5%1.0%) per quarter for emergency hospitalisations.  #@NEW_LINE#@#  
Results using Wales as a control instead of Scotland were similar (S2 Table and S2 Fig).  #@NEW_LINE#@#  


Discussion  #@NEW_LINE#@#  
To our knowledge, this is the first study of the potential impact on secondary care activity of a universal, national policy that gave control of an unprecedented two-thirds of the English NHS budget to GP-led CCGs.  #@NEW_LINE#@#  Contrary to the underlying hypothesis, we found no evidence of a reduction in hospitalisations or specialist visits in England following the HSCA.  #@NEW_LINE#@#  Moreover, we found evidence of an increase over and above the underlying trend in specialist visits in England, with no comparable increase in Scotland, where this policy did not occur.  #@NEW_LINE#@#  This increase was equivalent to approximately 3.7 million additional specialist visits since the policy was implemented (compared to those expected), of which the majority (approximately 2.9 million) were GP referred.  #@NEW_LINE#@#  
We used a robust CITS design.  #@NEW_LINE#@#  By modelling long-term underlying trends, we controlled for secular changes in practice and artefactual changes due to regression to the mean.  #@NEW_LINE#@#  Selection bias is only an issue in the unlikely event that the population changed suddenly and substantially in contrast to the underlying trend and differentially from trends in the control.  #@NEW_LINE#@#  S1 Table shows that population characteristics maintained stable trends over the study period, suggesting that this is not an alternative explanation for our findings.  #@NEW_LINE#@#  Furthermore, we controlled for unknown confounding events coincident with the policy by including Scotland as a comparator.  #@NEW_LINE#@#  Our study is also based on a very large population with stable trends in the outcomes before and after the intervention; therefore, we are well powered to detect effects.  #@NEW_LINE#@#  Finally, the compulsory nature and large scale of the intervention again limits selection bias and increases both the internal and external validity of our results.  #@NEW_LINE#@#  
Our study has several limitations.  #@NEW_LINE#@#  First, it is possible that the observed changes in trends could have been due to other concurrent policies targeting these outcomes but that did not occur in the control population.  #@NEW_LINE#@#  Following a literature review, we found one such national policy: an enhanced service encouraging GPs to provide extra support for patients deemed at risk of unplanned admission to the hospital; however, this was introduced a year after the Act and only targeted 1 of our outcomes (emergency admissions) in which we did not see a change [21].  #@NEW_LINE#@#  We also considered the fact that the Act included a broad range of changes alongside GP-led commissioning and that observed changes in trends might be due to other aspects of the reforms.  #@NEW_LINE#@#  However, most of the other changes were support structures for the changes to commissioning (such as accountability systems and services regulating specialist care providers) that would be considered integral to the intervention itself, or structural changes to public health and preventative services that are likely to have little direct impact on hospitalisations or specialist visits [2, 4].  #@NEW_LINE#@#  Second, smaller-scale effects on certain specialties or diagnoses may have been diluted by the scale of our data.  #@NEW_LINE#@#  However, as the first study of this nationwide policy, and given the governments aim to address rising demands and treatment costs within the NHS as a whole [4], our goal was to examine the association between the policy and trends in specialist visits and hospitalisations.  #@NEW_LINE#@#  Third, while we have nearly 3 years of postintervention data, it is possible that some effects of GP-led commissioning have not yet become evident.  #@NEW_LINE#@#  For example, GPs may have chosen to invest more in preventative services, which can take several years to result in population-level reductions in disease.  #@NEW_LINE#@#  Finally, our study uses routine data that were not specifically created to answer this research question.  #@NEW_LINE#@#  However, we use the data in high-level aggregate analysis and only use final, rather than provisional, data, which are regarded as complete.  #@NEW_LINE#@#  Therefore, quarterly changes are unlikely to be due to issues such as data completeness or misclassification [22].  #@NEW_LINE#@#  
Following the introduction of the HSCA, the Department of Health (DH) called for research to evaluate its impact [23].  #@NEW_LINE#@#  Nevertheless, initial proposals were rejected, and, while the DH has published an evaluation focussing on the processes of the reforms, we were unable to find any studies looking at the impact of this policy on hospital activity [23, 24].  #@NEW_LINE#@#  There have been studies of previous policies that handed greater budgetary responsibility to GPs in the UK and in Israel [2532].  #@NEW_LINE#@#  However, the results of these studies are mixed and difficult to interpret, as all used simple pre-post designs, which do not take into account underlying trends in hospitalisations or specialist visits, and they examined smaller policies, which were voluntary and subject to volunteer selection bias.  #@NEW_LINE#@#  The lack of control for underlying trends in these studies is particularly important because study groups often appear to have had unusually high referral rates prior to the intervention (partly because budget allocations based on existing referral rates incentivized practices to inflate referrals before becoming budget holders) [27].  #@NEW_LINE#@#  Any reduction could therefore have simply been due to regression to the mean.  #@NEW_LINE#@#  
Our findings suggest that, on a national scale, the concerns raised around restrictions in access to specialist services and rationing of care have not been realised.  #@NEW_LINE#@#  However, the lack of decrease in hospitalisations and the unanticipated increase in specialist visits also suggest the theorised shift in care away from hospitals to less expensive community settings does not appear to have occurred and, if anything, the increase in specialist visits may have led to cost increases.  #@NEW_LINE#@#  There are a number of possible reasons why specialist visits and hospitalisations did not decrease.  #@NEW_LINE#@#  First, while CCGs intended to increase clinical involvement in commissioning, survey evidence suggests that some GPs do not feel fully engaged with their CCG [33].  #@NEW_LINE#@#  For example, the majority of GPs are CCG members but do not have a formal role in the governing body, and this group reported much lower levels of influence and ownership than governing body members.  #@NEW_LINE#@#  A lack of engagement with members may mean that many GPs feel detached from their CCG and under little pressure to make cost savings or unable to influence the way local health services are managed [33].  #@NEW_LINE#@#  Second, the financial incentive for CCGs to reduce costs and GPs to change referral patterns may have been too small or too indirect, and, while practice income may have increased by shifting some care from hospitals to community-based care provided by GPs, concerns about potential conflicts of interest could have discouraged this [7].  #@NEW_LINE#@#  Finally, it is also possible that referrals to specialists were already appropriate prior to the intervention, resulting in little scope for further reduction.  #@NEW_LINE#@#  This is supported by evidence that variations in referral rates in the NHS are primarily explained by characteristics of the patient population and not factors affecting GP services [34].  #@NEW_LINE#@#  
The increase in specialist visits in our study was surprising and may be an unintended consequence of the policy.  #@NEW_LINE#@#  We identified annual data on NHS costs for outpatient specialist visits from an independent source (S3 Fig).  #@NEW_LINE#@#  This also appears to show an increase in costs, corroborating our findings regarding upward trends in specialist visits.  #@NEW_LINE#@#  One explanation might be that the new responsibility for managing budgets has inadvertently increased administrative workload for GPs, resulting in less time to see patients.  #@NEW_LINE#@#  Under such circumstances, GPs may reduce their threshold for referral to avoid missing a diagnosis.  #@NEW_LINE#@#  There is some existing evidence to suggest that increased workload and reduced consultation time is associated with increased referral rates [12, 13], although other studies have shown no effect [35].  #@NEW_LINE#@#  We considered decreasing GP numbers or increasing supply of specialists as other potential explanations for this finding.  #@NEW_LINE#@#  However, although there was a slight decrease in the number of full-time equivalent GPs (from 0.69 to 0.67 per 1,000 population) between 2009 and 2010, this does not coincide with the increase in specialist visits, and the number of GPs remained stable from 2010 and, in fact, increased back to 0.69 per 1,000 population in 2014 [36].  #@NEW_LINE#@#  Number of specialists (full-time equivalent consultants) increased gradually over the study period from 0.67 per 1,000 population in 2009 to 0.76 per 1,000 population in 2014 and there was no deviation in this trend around the introduction of the HSCA [37].  #@NEW_LINE#@#  
In conclusion, we found no evidence that the introduction of GP-led commissioning in England was associated with a reduction in overall hospitalisations or specialist visits.  #@NEW_LINE#@#  In fact, there was an increase in specialist visits, which appears to have been paralleled by an increase in expenditure.  #@NEW_LINE#@#  This study begins to decipher the macro effects of these significant reforms to the organisation of NHS commissioning.  #@NEW_LINE#@#  However, many questions remain unanswered.  #@NEW_LINE#@#  Examples include the appropriateness of any change in rates of specialist visits and hospitalisations, the effect of this change on health outcomes, whether changes differed according to CCG and why, and the generalizability of our findings to other health systems.  #@NEW_LINE#@#  This study alone is unable to determine whether the HSCA can be regarded as a good or bad policy, and further research is needed to evaluate other important outcomes such as costs and quality of care.  #@NEW_LINE#@#  Nevertheless, in the context of similar findings from other large-scale health policy experiments [38], more effort may be needed to target specific costly or poorly evidenced practices (such as tonsillectomy, tympanostomy, or antibiotics prescribed for viral infections) rather than to count on broad, system-wide policy changes that often have unintended consequences.  #@NEW_LINE#@#  

Supporting_information  #@NEW_LINE#@#  
S1_Table_Population_characteristics_of_England_and_Scotland__20072014  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pmed.1002427.s001  #@NEW_LINE#@#  
(DOCX)  #@NEW_LINE#@#  

S2_Table_Trend_changes_in_specialist_visits_and_hospitalisations_following_the_intervention_in_England_versus_Wales  #@NEW_LINE#@#  
Coefficients for trend change are relative change in the slope gradient following the intervention.  #@NEW_LINE#@#  Trend change study versus control is the slope change in England over and above any change in Wales accounting for differences in baseline trends.  #@NEW_LINE#@#  All segmented regression models used log transformed Gaussian distribution.  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pmed.1002427.s002  #@NEW_LINE#@#  
(DOCX)  #@NEW_LINE#@#  

S1_Fig_Time_series_of_outpatient_specialist_visits_in_England_and_Wales  #@NEW_LINE#@#  
Red o = England, blue x = Wales.  #@NEW_LINE#@#  Lines = deseasonalized linear trend.  #@NEW_LINE#@#  Vertical lines delineate the intervention phase (between quarter 2 [Q2] 2014 and Q2 2013).  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pmed.1002427.s003  #@NEW_LINE#@#  
(DOCX)  #@NEW_LINE#@#  

S2_Fig_Time_series_of_inpatient_hospitalisations_in_England_and_Wales  #@NEW_LINE#@#  
Red o = England, blue x = Wales.  #@NEW_LINE#@#  Lines = deseasonalized linear trend.  #@NEW_LINE#@#  Vertical lines delineate the intervention phase (between quarter 2 [Q2] 2014 and Q2 2013).  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pmed.1002427.s004  #@NEW_LINE#@#  
(DOCX)  #@NEW_LINE#@#  

S3_Fig_National_Health_Service_(NHS)_reference_costs  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pmed.1002427.s005  #@NEW_LINE#@#  
(DOCX)  #@NEW_LINE#@#  

S1_Text_Controlled_interrupted_time_series_model  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pmed.1002427.s006  #@NEW_LINE#@#  
(DOCX)  #@NEW_LINE#@#  

S1_Checklist_REporting_of_studies_Conducted_using_Observational_Routinely-collected_health_Data_(RECORD)_statement  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pmed.1002427.s007  #@NEW_LINE#@#  
(DOCX)  #@NEW_LINE#@#  

S1_Protocol_  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pmed.1002427.s008  #@NEW_LINE#@#  
(DOCX)  #@NEW_LINE#@#  

S1_Data_  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pmed.1002427.s009  #@NEW_LINE#@#  
(XLSX)  #@NEW_LINE#@#  

S2_Data_  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pmed.1002427.s010  #@NEW_LINE#@#  
(XLSX)  #@NEW_LINE#@#  

S3_Data_  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pmed.1002427.s011  #@NEW_LINE#@#  
(PDF)  #@NEW_LINE#@#  

S4_Data_  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pmed.1002427.s012  #@NEW_LINE#@#  
(DOC)  #@NEW_LINE#@#  


References  #@NEW_LINE#@#  



