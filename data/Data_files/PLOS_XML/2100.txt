article id="http://dx.doi.org/10.1371/journal.pcbi.1005971"  #@NEW_LINE#@#  
title  #@NEW_LINE#@#  
Haptic communication between humans is tuned by the hard or soft mechanics of interaction  #@NEW_LINE#@#  

Abstract  #@NEW_LINE#@#  
To move a hard table together, humans may coordinate by following the dominant partners motion [14], but this strategy is unsuitable for a soft mattress where the perceived forces are small.  #@NEW_LINE#@#  How do partners readily coordinate in such differing interaction dynamics?  #@NEW_LINE#@#  To address this, we investigated how pairs tracked a target using flexion-extension of their wrists, which were coupled by a hard, medium or soft virtual elastic band.  #@NEW_LINE#@#  Tracking performance monotonically increased with a stiffer band for the worse partner, who had higher tracking error, at the cost of the skilled partners muscular effort.  #@NEW_LINE#@#  This suggests that the worse partner followed the skilled ones lead, but simulations show that the results are better explained by a model where partners share movement goals through the forces, whilst the coupling dynamics determine the capacity of communicable information.  #@NEW_LINE#@#  This model elucidates the versatile mechanism by which humans can coordinate during both hard and soft physical interactions to ensure maximum performance with minimal effort.  #@NEW_LINE#@#  

Author_summary  #@NEW_LINE#@#  
Humans are talented at coordinating movements with one another through a multitude of objects such as a hard table or a soft mattress.  #@NEW_LINE#@#  Depending on the softness of the object, the force we perceive from the partner can be strong enough to sense directional cues, or could be too weak to understand the partners movement intention.  #@NEW_LINE#@#  How do we coordinate physical movements governed by such differing mechanics?  #@NEW_LINE#@#  Our task is inspired by a pair moving through a dancefloor during Tango dancing; we tested subjects in pairs who jointly chased a moving target with their right hands, which were banded together by either a strong, medium or weak elastic band.  #@NEW_LINE#@#  By measuring the change in each partners performance at the task, and the muscular effort they exerted, we characterized the changes in each partners behavior as a function of the strength of the elastic band that coupled them together.  #@NEW_LINE#@#  By employing a computational simulation of the task, we tested different coordination mechanisms to see what explained the data best.  #@NEW_LINE#@#  We found that, regardless of the coupling strength, each subject infers the movement intention of their partner, but this process deteriorates with softer coupling.  #@NEW_LINE#@#  

Citation: Takagi A, Usai F, Ganesh G, Sanguineti V, Burdet E (2018) Haptic communication between humans is tuned by the hard or soft mechanics of interaction.  #@NEW_LINE#@#  PLoS Comput Biol 14(3):  #@NEW_LINE#@#  
           e1005971.  #@NEW_LINE#@#  

        https://doi.org/10.1371/journal.pcbi.1005971  #@NEW_LINE#@#  
Editor: Adrian M. Haith, Johns Hopkins University, UNITED STATES  #@NEW_LINE#@#  
Received: July 10, 2017; Accepted: January 15, 2018; Published:  March 22, 2018  #@NEW_LINE#@#  
Copyright:  © 2018 Takagi et al.  #@NEW_LINE#@#  This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.  #@NEW_LINE#@#  
Data Availability: All relevant data are within the paper and its Supporting Information files.  #@NEW_LINE#@#  
Funding: Funding was provided by ICT-231554 HUMOUR (AT, EB), ICT-601003 BALANCE (EB), ICT-611626 SYMBITRON (EB), EU-H2020 ICT-644727 COGIMON (AT, EB), UK EPSRC MOTION grant EP/NO29003/1 (EB).  #@NEW_LINE#@#  The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.  #@NEW_LINE#@#  
Competing interests:  The authors have declared that no competing interests exist.  #@NEW_LINE#@#  
Introduction  #@NEW_LINE#@#  
When moving into a new home, workers help each other to manipulate various objects such as hard tables and soft mattresses.  #@NEW_LINE#@#  They may verbally agree which room to move towards, but will rely on subtle haptic cues provided by touch and proprioceptive sensing to coordinate their movement through narrow corridors and stairs.  #@NEW_LINE#@#  Importantly, the mechanics of the object they transport will influence the haptic forces between the partners and may require them to adopt different interaction strategies.  #@NEW_LINE#@#  In the case of interaction through stiff coupling, previous studies have suggested that one follows the better partners lead [15].  #@NEW_LINE#@#  However, manipulating a soft object like a mattress, which has internal degrees of freedom, may require more complex forms of coordination as one can rely less on the partner to move the object skillfully, and the objects mechanics influences the perception of the partners force [6].  #@NEW_LINE#@#  On the other hand, a hard table directly transmits a partners mistakes, thereby disturbing ones motion, while a soft object can be helpful in this situation as the transmitted mistakes are less perturbing.  #@NEW_LINE#@#  Thus, the interaction strategy is likely to depend on the sensory information available from the interaction forces.  #@NEW_LINE#@#  Similar situations are encountered during direct physical contact between humans.  #@NEW_LINE#@#  For example, a therapist moving a patients hand would correspond to a hard interaction, whilst a parent helping their child to take their first steps is a soft interaction as the compliant arms mediate the interaction.  #@NEW_LINE#@#  To physically interact in such versatile scenarios with different coupling dynamics, humans may change their behavior depending on how hard or soft the interaction is, but we do not know whether nor how people do so.  #@NEW_LINE#@#  
What do we know about such physical interaction between humans?  #@NEW_LINE#@#  In the past decade, physical coordination has been investigated [25,713] using a variety of tasks and metrics to investigate the mechanism of physical coordination, but our understanding of the mechanism remains shallow [9,13].  #@NEW_LINE#@#  The interactive task can be either discrete [2] or continuous [11], where dyads are coupled directly through stiff mechanics such as a crank [14] or through robotic devices [15].  #@NEW_LINE#@#  Previous studies have used several metrics such as the energy exchanged between partners [3], dominance measures [4], distance from a goal [8,9] and magnitude of interaction force [11] to quantitatively analyze physical interaction.  #@NEW_LINE#@#  For example, a previous study examined stiffly coupled dyads rotating a crank to perform sequential reaching movements [14], and found force patterns of one partner purely accelerating the crank and the other slowing it, which the authors ascribed to the adoption of roles.  #@NEW_LINE#@#  However, it is not clear if these force patterns were evidence of role emergence or were artefacts of different movement speeds [13,16].  #@NEW_LINE#@#  Thus, there is a need to understand how people modify their coordination strategy depending on the coupling strength to the partner.  #@NEW_LINE#@#  
To understand how people change their interaction behavior, we developed an experiment that systematically examines how the coupling dynamics affects the performance and the muscular effort of two partners during an interactive task (see Fig 1A).  #@NEW_LINE#@#  We chose to study physical interaction in a continuous tracking task, where subjects follow a common, randomly moving target using their right hand [17].  #@NEW_LINE#@#  Such a continuous task has been shown [18] to cause coordination between partners mediated by an exchange of information on the current motion goal through haptics.  #@NEW_LINE#@#  We developed and tested computational models to explain how the two partners performance and effort change with the coupling dynamics (see Fig 1B).  #@NEW_LINE#@#  
(A) Experimental configuration to test physical interaction in 1 dimension.  #@NEW_LINE#@#  Subjects, recruited in pairs, were separated by a curtain and followed a common target using their wrist flexion/extension to control a cursor along a 1 dimensional arc.  #@NEW_LINE#@#  Their wrists were virtually coupled together through the dual robotic interface by a spring with computer-controlled elasticity.  #@NEW_LINE#@#  Only the target, which was a normally distributed cloud of spots, and ones own cursor were displayed on each subjects individual monitor.  #@NEW_LINE#@#  (B) The computational framework to test different strategies (in purple) that partners could adopt during interaction.  #@NEW_LINE#@#  In this approach, only the goal or what information is used to track the target is changed.  #@NEW_LINE#@#  The goal is tracked by a subject who generates a motor command to move their wrist.  #@NEW_LINE#@#  Two subjects are simulated in parallel, who experience the coupling force from the spring.  #@NEW_LINE#@#  In follow the leader, subjects switch to following the partner nearest to the target.  #@NEW_LINE#@#  In interpersonal goal integration, the partners target is inferred through haptics and is integrated with ones own target estimated from vision.  #@NEW_LINE#@#  Neuromechanical goal sharing is similar to interpersonal goal integration, but the weighting between the visual target and the partners target is influenced by the coupling dynamics.  #@NEW_LINE#@#  


              https://doi.org/10.1371/journal.pcbi.1005971.g001  #@NEW_LINE#@#  
How do partners respond to the different demands of the interaction with differing coupling mechanics?  #@NEW_LINE#@#  In a previous study, we used a tracking task to show that partners who are compliantly interacting together share their movement goals, which improves both partners predictions of the targets motion, resulting in improved tracking of the target for both partners [18].  #@NEW_LINE#@#  This occurs through the optimal sensory integration of information from vision and haptic sensing [19,20], and is also reported to occur between proprioception and force-sensing [6].  #@NEW_LINE#@#  Typically, the subjects uncertainty in each sensory modality is measured.  #@NEW_LINE#@#  Next, they are given different information for each sensory modality.  #@NEW_LINE#@#  For example, the experimenter asks subjects to determine the angle of a slanted plane, which can be determined visually or by haptically touching the surface through a robotic interface.  #@NEW_LINE#@#  The subject is given conflicting visual and haptic information, but their guess is found to be a weighted combination of the two, with the noisier sensory modality weighed less [19].  #@NEW_LINE#@#  A similar integration of sensory information was documented in dyads that track a common target whilst compliantly coupled to each other.  #@NEW_LINE#@#  However, rigidly coupled partners have been suggested to adopt roles [14,11] where one partner follows the lead of the more capable partner.  #@NEW_LINE#@#  In a previous study, we suggested that reaching tasks may be too short for roles to emerge [16], but leadership roles could emerge in a longer interactive tracking task where dyadic coordination was observed [18].  #@NEW_LINE#@#  Thus, we hypothesized that hard interactions are governed by a strategy of following the leader or the more capable partner, and compliant interactions can be explained by the sharing of movement goals, as was found in our previous study [18].  #@NEW_LINE#@#  We test this hypothesis by examining how a pair or dyad tracks a common moving target whilst their hands are coupled by a hard, medium or soft elastic band.  #@NEW_LINE#@#  

Results  #@NEW_LINE#@#  
We recruited 14 pairs of subjects, and asked each dyad to track the same randomly moving multi-sinusoidal target, which was displayed on two individual monitors as 10 circular spots distributed normally around the actual target position (see Fig 1A).  #@NEW_LINE#@#  Partners controlled their own cursor using their wrist flexion-extension to track this target, and each partner could only see the target and their own cursor.  #@NEW_LINE#@#  Partners were separated by a curtain throughout the experiment to mitigate biased behaviors due to social factors [21], and were prohibited from verbally interacting.  #@NEW_LINE#@#  Dyads experienced solo trials, where the two subjects tracked the target alone, and connected trials, where the dyad were physically coupled by a virtual elastic spring produced by a dual robotic interface [22] during the whole 40 second trial.  #@NEW_LINE#@#  The solo trials were used as a baseline to assess the effects of physical interaction.  #@NEW_LINE#@#  Task performance was measured by the tracking error, which is defined as the root-mean squared difference between the target and the cursor over the whole trial.  #@NEW_LINE#@#  Effort in each partner was quantified using surface electromyography of a wrist flexor-extensor muscle pair, with each muscle calibrated with respect to torque (see Experiments for details).  #@NEW_LINE#@#  The whole experiment consisted of 45 trials that were either solo or connected trials, which was determined by a binary die.  #@NEW_LINE#@#  The 45 trials were split into three blocks of 15 trials, where in each block the strength of the elastic spring was set such that partners experienced hard (K = 17.2 Nm/rad), medium (K = 1.7 Nm/rad) and soft coupling dynamics (K = 0.3 Nm/rad).  #@NEW_LINE#@#  All dyads experienced the medium block first, but the order of the soft and hard blocks was randomized.  #@NEW_LINE#@#  This ordering of the blocks did not influence the results (see Experiments for linear-mixed effects analysis).  #@NEW_LINE#@#  Furthermore, we observed no learning effect as the solo errors remained constant throughout the experiment (2(1) = 0.90, P0.34).  #@NEW_LINE#@#  
First, we examined how the coupling dynamics affected the partners tracking errors.  #@NEW_LINE#@#  We define the performance improvement as the change in the tracking error, i.e.  #@NEW_LINE#@#  the ratio of the difference 1  ec/e between a subjects error e in a solo trial and their error in the previous connected trial ec.  #@NEW_LINE#@#  Note that this error in the connected trial ec is similar for both partners during a hard interaction, but can be different for medium and soft interactions.  #@NEW_LINE#@#  In Fig 2A, the performance improvement is plotted as a function of the relative error 1  ep/e, the difference between a subjects error and their partners error ep in the same solo trial, enabling us to observe how each subject improved when interacting with a partner who was better or worse at the tracking.  #@NEW_LINE#@#  The plot of improvement as a function of the relative error is shown for the hard (red trace), medium (blue trace) and soft (green trace) interactions, where the lines come from the data that were fit using a linear mixed-effects model with the improvement as the dependent variable, and with linear and quadratic forms of the relative error and the log of the coupling stiffness as predictors (see Experiments for details).  #@NEW_LINE#@#  We compared two linear mixed-effects models, one with and the other without the coupling stiffness predictor, and found that the stiffness of the interaction significantly modulates the performance improvement (2(3) = 67.0, Pless_than1013).  #@NEW_LINE#@#  
(A) Improvement, defined as the tracking error in a solo trial minus the error in the preceding connected trial, as a function of the relative error, defined as the difference in tracking errors between the partners in the solo trial.  #@NEW_LINE#@#  The improvement was modulated as a function of the coupling stiffness such that the worse partner (positive in the horizontal axis) improved more with the hard than with the soft interaction.  #@NEW_LINE#@#  However, the hard interaction did not hinder the better partners performance.  #@NEW_LINE#@#  (B) Interaction effort, defined as the effort expended during a solo trial minus the effort in the preceding connected trial, as a function of the relative error.  #@NEW_LINE#@#  The effort was estimated as the sum of the mean muscle activations, normalized with respect to torque, from a wrist flexor and extensor pair.  #@NEW_LINE#@#  As with the improvement, the interaction effort is modulated by the softness of the interaction.  #@NEW_LINE#@#  Only the better partner in the hard and medium interactions exerted more effort in comparison to solo trials.  #@NEW_LINE#@#  


              https://doi.org/10.1371/journal.pcbi.1005971.g002  #@NEW_LINE#@#  
To examine how the partners were influenced by the coupling stiffness, we calculated the mean improvement of the better and worse partners, which was determined using their relative error, within each dyad for every level of coupling stiffness.  #@NEW_LINE#@#  A repeated-measures ANOVA determined that the interaction effect of the better/worse partner by the coupling stiffness significantly changed the mean improvement (F(2,44) = 15.5, Pless_than0.0012).  #@NEW_LINE#@#  Post-hoc Tukey-Kramer tests revealed that the better partners performance was similar for all coupling strengths, so they were not hindered by the worse partner during the hard interaction.  #@NEW_LINE#@#  On the other hand, the worse partners improvement was greater during hard interaction in comparison to medium (Pless_than0.04) and soft interactions (Pless_than0.005).  #@NEW_LINE#@#  Altogether, these results imply that a hard interaction enables a worse partner to achieve the same performance as the better partner, which could be due to the better partner leading the movement to facilitate the task with the worse partner.  #@NEW_LINE#@#  The worse partners improvement came at no cost to the better partners performance.  #@NEW_LINE#@#  
Next, we examined how the partners effort was affected by the coupling dynamics.  #@NEW_LINE#@#  The effort was measured from the mean absolute value of the electromyography signals from a wrist flexor-extensor muscle pair of each partner normalized to their torque-equivalent values (see Experiments for calibration procedure).  #@NEW_LINE#@#  We computed the interaction effort, c/  1, as the difference between the effort in the connected trial c and the effort in the proceeding solo trial .  #@NEW_LINE#@#  This interaction effort is plotted, in Fig 2B, as a function of the relative error for the hard (red), medium (blue) and soft interactions (green), where the lines are the fits to the data using a linear mixed-effects model with the interaction effort as the dependent variable and the relative error and the log of the coupling stiffness as the predictors (see Experiments for details).  #@NEW_LINE#@#  The linear mixed-effects analysis revealed that the interaction effort is dependent on the partners relative difference in performance (2(1) = 7.20, Pless_than0.008), and it is also linearly modulated by the log of the coupling stiffness (2(2) = 27.2, Pless_than105).  #@NEW_LINE#@#  We calculated the mean effort of the better and worse partners within each dyad for every level of coupling stiffness.  #@NEW_LINE#@#  A repeated-measures ANOVA, with a Greenhouse-Geisser correction for the violation of the sphericity assumption (Mauchlys test, 2(2) = 30.3, Pless_than106), determined that the coupling stiffness significantly changed the mean effort (F(2,44) = 9.56, Pless_than0.004).  #@NEW_LINE#@#  One-sample t-tests were conducted using a Bonferroni correction with a significance level of 0.05/6, which revealed that the mean interaction effort of the better partner during hard (t(12) = 4.21, Pless_than0.0012) and medium interactions (t(12) = 3.52, Pless_than0.0042) were different from zero.  #@NEW_LINE#@#  Hence, the better partner exerted more effort during the hard and medium interactions relative to when they did the task alone.  #@NEW_LINE#@#  This may be due to the better partner taking the lead of the movement, and counteracting the adverse movements made by the worse partner only when the coupling stiffness is strong enough to do so.  #@NEW_LINE#@#  
These results suggest that the coupling dynamics finely tune both the performance improvement and the interaction effort, and supports the hypothesis that the worse partner follows the lead of the better partner when the interaction is hard, which is consistent with the follow the leader model.  #@NEW_LINE#@#  However, partners may adopt a different behavior during soft interaction.  #@NEW_LINE#@#  To test whether a follow the leader model can explain the results of both the hard and soft interactions, we used a computational modelling framework of two partners tracking the same target to simulate the outcomes of the interaction and compared them with the empirical data (Fig 1B; see Computational framework to simulate interaction).  #@NEW_LINE#@#  This model was simulated by assuming that the haptic force provides an estimate of the relative position of the partners wrist.  #@NEW_LINE#@#  A subject can follow the partners wrist if it is nearer to the target than ones own wrist or, otherwise, follow the target (see follow the leader panel in Fig 1B).  #@NEW_LINE#@#  This model is inspired by decision-making studies where the best partners decision is taken by a group [23,24].  #@NEW_LINE#@#  Surprisingly, this follow the leader model predicted performance detriment for both the better and worse partners, and greatly overestimated the effort exerted by both partners (see Fig 3A).  #@NEW_LINE#@#  Although this model was intuitively plausible, the simulations demonstrate that it cannot explain the outcomes of even the hard interaction.  #@NEW_LINE#@#  
(A) Prediction of the improvement and interaction effort from the follow the leader model, where subjects switch to following the partners cursor if they are nearest to the target.  #@NEW_LINE#@#  The prediction overestimates the interaction effort by a large amount, and greatly underestimates the performance improvement.  #@NEW_LINE#@#  (B) Predictions from the interpersonal goal integration model, where the visual and haptic information of the target are combined to yield a better prediction of the targets motion.  #@NEW_LINE#@#  The haptic estimate of the target is obtained by forming a representation of the partner that identifies how the partners movement changes in response to the motion of the target, which is used to estimate the partners target.  #@NEW_LINE#@#  Unlike the data, this model does not exhibit any modulation in the improvement due to the coupling stiffness.  #@NEW_LINE#@#  


              https://doi.org/10.1371/journal.pcbi.1005971.g003  #@NEW_LINE#@#  
In a previous study [18], we showed that human behavior during soft interactions can be explained by a model where partners share their movement goals with each other.  #@NEW_LINE#@#  Can this interpersonal goal integration model predict the experimental outcomes when the interaction is hard?  #@NEW_LINE#@#  In interpersonal goal integration, the haptic information from the physical coupling is used to form a representation of the partner that relates the motion of the target with the partners movement.  #@NEW_LINE#@#  This representation of the partner is used to estimate the partners goal, i.e.  #@NEW_LINE#@#  their target, which can be combined with ones own visual estimate of the target.  #@NEW_LINE#@#  We simulated two partners who estimated each others goals in this manner (see interpersonal goal integration panel in Fig 1B), but the improvement and interaction effort did not match the empirical data.  #@NEW_LINE#@#  Namely, the improvement was not graded as a function of the coupling stiffness as observed in the experimental data (Fig 3B, left panel).  #@NEW_LINE#@#  Furthermore, this model systematically underestimated the interaction effort (Fig 3B, right panel).  #@NEW_LINE#@#  
Although the interpersonal goal integration model cannot predict the improvement and the interaction effort during the medium and soft interactions, its predictions for the hard interaction resemble the results from the experiment.  #@NEW_LINE#@#  It should be noted that the coupling stiffness will filter the transmitted haptic forces and modify them, especially if the interaction is soft [6].  #@NEW_LINE#@#  This may be a particularly important factor to consider in the context of the interpersonal goal integration model, where subjects must estimate their partners goal through the mechanics of the entity that mediates the interaction.  #@NEW_LINE#@#  Hard coupling will transmit the partners force faithfully, but soft mechanics filter the force relayed to the partner.  #@NEW_LINE#@#  Consequently, the estimate of the partners goal may be poor during soft interaction, and accurate when the interaction is hard.  #@NEW_LINE#@#  
To characterize how the softness of the coupling dynamics influences the estimate of the partners goal, we conducted a haptic tracking control experiment.  #@NEW_LINE#@#  8 subjects were recruited individually to track a target with visual feedback of the cursor, but not of the target (left panel of Fig 4A).  #@NEW_LINE#@#  Subjects received only haptic feedback through a virtual elastic band that connected the subjects wrist to the target.  #@NEW_LINE#@#  By measuring the tracking error as a function of the stiffness of the elastic band, we could assess how the estimation of the targets motion changes with the coupling stiffness.  #@NEW_LINE#@#  The haptic tracking errors are shown as a function of the log of the coupling stiffness in the right panel of Fig 4A.  #@NEW_LINE#@#  Indeed, the softer interaction resulted in poorer estimation of the targets movement, yielding larger tracking errors.  #@NEW_LINE#@#  
(A) Haptic tracking control experiment to measure how the tracking error, or the noise in the haptic information, increases with the coupling stiffness (plots are mean±standard error).  #@NEW_LINE#@#  8 individually recruited subjects received no visual feedback of the target, instead relying only on the haptic feedback from the elastic connection between the wrist and the target.  #@NEW_LINE#@#  (B) The tracking errors from the haptic tracking experiment were considered in the neuromechanical goal sharing model, which combines information from vision with the haptic sensing of the partners goal to improve tracking performance while taking into account the additional noise in haptic sensing arising from the softness of the interaction.  #@NEW_LINE#@#  The predictions from this model closely resemble the data, exhibiting modulation of both the improvement and interaction effort due to the coupling stiffness.  #@NEW_LINE#@#  This shows that the effort expended during interaction is not a strategy per se, but the outcome of maximizing the sensory information of the targets motion.  #@NEW_LINE#@#  


              https://doi.org/10.1371/journal.pcbi.1005971.g004  #@NEW_LINE#@#  
This extra error arising from the coupling dynamics can be used to modify the interpersonal goal integration model.  #@NEW_LINE#@#  In this novel neuromechanical goal sharing model (see Interaction strategies), the softness of the interaction is assumed to add extra noise to the haptic measurement of the partners goal.  #@NEW_LINE#@#  The predictions of the neuromechanical goal sharing model for the improvement and interaction effort are shown in Fig 4B.  #@NEW_LINE#@#  The predictions for both the improvement and the interaction effort correspond well to the data (see S1 Text for a rigorous comparison of the different models of interaction).  #@NEW_LINE#@#  The performance is correctly modulated by the coupling stiffness, which influences the estimate of the partners goal and, in turn, increases the effort necessary to carry out the tracking task successfully.  #@NEW_LINE#@#  Critically, the neuromechanical goal sharing model can explain a humans behavior during both hard and soft interactions.  #@NEW_LINE#@#  

Discussion  #@NEW_LINE#@#  
We systematically investigated how pairs of human subjects tracked a 1 dimensional target motion using the flexion-extension of the wrists, which were coupled by a virtual elastic band with different stiffness.  #@NEW_LINE#@#  By measuring the change in each partners muscular activity during this interactive task, we could identify how each persons effort depends on the other partners relative skill, and how the stiffness of the elastic band modulates this relationship.  #@NEW_LINE#@#  Furthermore, measuring the tracking performance on coupled relative to uncoupled trials as a function of the coupling stiffness provided insights into how the coupling dynamics affects each partners accuracy at tracking the target.  #@NEW_LINE#@#  This experimental approach might in future allow us to examine how partners physically cooperate in scenarios ranging from a physiotherapist assisting a patient to workers moving a table or a mattress together.  #@NEW_LINE#@#  
Our experiments revealed that the performance and the effort were tuned as a function of both the coupling stiffness and the partners individual skills.  #@NEW_LINE#@#  The worse partners performance improved more when the interaction with the better partner was stiffer.  #@NEW_LINE#@#  Importantly, the performance of the better partner was not hindered during the hard interaction with a worse partner, but this came at the cost of the better partner having to exert more effort than when doing the task alone.  #@NEW_LINE#@#  The increasingly larger effort exerted by the better partner during the medium and hard interactions suggested that the assignment of leadership [15] could explain the experimental results.  #@NEW_LINE#@#  However, the predicted outcomes of the computational simulations of this follow the leader model were starkly different from the data for both the soft and even the hard interactions.  #@NEW_LINE#@#  
The results can be better explained by the interpersonal goal integration model, proposed in a previous study [18], where the partners share their movement goals through the interaction forces.  #@NEW_LINE#@#  However, the best model accounted for the mechanics of the interaction between the partners and understand how it influences the partners performance and effort.  #@NEW_LINE#@#  Specifically, we showed how the haptic sensing is affected by the coupling dynamics in a haptic tracking experiment, and integrated this relationship into our model.  #@NEW_LINE#@#  This neuromechanical goal sharing model makes best use of the haptic information provided by the partner through the coupling dynamics to anticipate the targets movement.  #@NEW_LINE#@#  It predicts the trends observed in the performance improvement and interaction effort as a function of the relative difference in the partners task performance, and their modulation due to the coupling stiffness.  #@NEW_LINE#@#  It should be noted that the neuromechanical goal sharing model outperforms all other models tested in this study, but there are discrepancies between its predictions and the empirical data.  #@NEW_LINE#@#  This could be due to a variety of reasons, such as the variability that arises from two human subjects interacting and adapting to one another, or could be due to the assumption that all subjects experience the same overall reduction in the ability to estimate the partners goal.  #@NEW_LINE#@#  A less variable measure of the interaction effort may yield further insights into the effect of the coupling dynamics on interaction behavior.  #@NEW_LINE#@#  
The interpersonal goal integration model was able to explain the compliant interaction in our previous study [18], but not so during this task.  #@NEW_LINE#@#  This discrepancy is due to the limited data in our previous study where only the performance improvement for the medium interaction was measured, and not the interaction effort.  #@NEW_LINE#@#  The interpersonal goal integration model also reproduces the medium interaction in this study, but only if we ignore the hard and soft interactions and the interaction effort (see S2 Fig in S1 Text).  #@NEW_LINE#@#  Our new study provides additional empirical data for hard and soft interactions, and the muscular effort of each partner, that enabled us to comprehensively investigate the limits of the interpersonal goal integration model, and deepened our understanding of the goal sharing coordination mechanism.  #@NEW_LINE#@#  
Altogether, the experimental results and the computational modelling suggest that the coupling dynamics may determine the amount of information that can be communicated by physically interacting partners.  #@NEW_LINE#@#  In this regard, the central nervous system is aware of the coupling dynamics and its effect on the information from the interaction force [6], and weighs the sensory measurements from vision and haptics according to their noise [19].  #@NEW_LINE#@#  This can be considered as a form of morphological computation where the dynamics of the interaction of the limb and the environment are considered by the brain [25,26] to generate appropriate motor commands.  #@NEW_LINE#@#  
In comparison to other models, the neuromechanical goal sharing model could predict the trends in the human behavior of two subjects accomplishing the same task together.  #@NEW_LINE#@#  However, what happens in different interactive tasks where multiple solutions [27] can be taken, or when the partners must compete with one another?  #@NEW_LINE#@#  In such scenarios, it is still useful to estimate the partners goal, but it would not be integrated with ones own goal.  #@NEW_LINE#@#  Instead, a subject could plan their movement to accomplish their task whilst deliberately avoiding the partners goal.  #@NEW_LINE#@#  The ability to estimate the partners goal may be a common factor in all interactive tasks, and the collaborative or competitive nature of the task [28] could determine how subjects use this information to their advantage.  #@NEW_LINE#@#  

Materials_and_methods  #@NEW_LINE#@#  
Ethics_statement  #@NEW_LINE#@#  
The experiments were performed at the Department of Bioengineering at Imperial College London.  #@NEW_LINE#@#  The participants gave informed consent for their participation in the experiments, which were conducted according to the principles in the Declaration of Helsinki and approved by the Imperial College Research Ethics Committee.  #@NEW_LINE#@#  

Experiments  #@NEW_LINE#@#  
A one degree of freedom, dual robotic interface shown in Fig 1A was used for the experiment [22].  #@NEW_LINE#@#  Subjects controlled a cursor on a computer monitor using their wrist flexion/extension to track a moving target, which was composed of a multi-sine function of the form  #@NEW_LINE#@#  
(1)  #@NEW_LINE#@#  
where  is the time and  is Gaussian noise with standard deviation t that was fixed throughout the experiment, and was different for each subject.  #@NEW_LINE#@#  This visual noise was implemented through ten normally distributed spots about the target, creating a cloud which was updated every 400ms, and the standard deviation of the spots was kept constant through the experiment.  #@NEW_LINE#@#  The target movement was randomized through the selection of the initial time according to a uniform stochastic distribution in the interval between 030 seconds.  #@NEW_LINE#@#  
The tracking error was taken as the root-mean squared distance between the cursor and the target over a trial.  #@NEW_LINE#@#  28 subjects were asked to complete the tracking task in 9 male-male and 5 female-female pairs, who were separated by a curtain during the experiment to mitigate the influence of social factors [21].  #@NEW_LINE#@#  The experiment consisted of 45 trials, each trial lasting 40s.  #@NEW_LINE#@#  Connected trials, during which dyads were coupled through a virtual elastic band, were selected by a 50% dice throw.  #@NEW_LINE#@#  The experiment was split into 3 blocks of 15 trials where dyads experienced a different coupling stiffness K in each block of either 17.2 Nm/rad (hard interaction), 1.7 Nm/rad (medium interaction) or 0.3 Nm/rad (soft interaction).  #@NEW_LINE#@#  Dyads always experienced the medium interaction first.  #@NEW_LINE#@#  Thereafter, the order of the hard and soft interactions was randomized.  #@NEW_LINE#@#  
Surface electromyography (EMG) was used to collect data from the flexor carpi radialis (FCR) and extensor carpi radialis longus (ECRL) muscles.  #@NEW_LINE#@#  Subjects were asked to flex or extend their wrist while the device kept their wrist locked at 0 degrees, the subjects most comfortable position.  #@NEW_LINE#@#  The subject was asked to produce flexion and extension torques of 1, 2, 3 and 4 Nm for 2 seconds, first flexion then extension, with a rest period of 5 seconds between each activation to prevent fatigue.  #@NEW_LINE#@#  This EMG data was linearly regressed versus torque to estimate the relationship between muscular activity and torque.  #@NEW_LINE#@#  The effort measure used in this study uses these estimated torques values.  #@NEW_LINE#@#  
Another 8 subjects were recruited individually to carry out a haptic tracking control experiment.  #@NEW_LINE#@#  The target movement was the same as in Eq (1) and the cursor was visible but the target was invisible through the trial.  #@NEW_LINE#@#  However, the subject was physically coupled to the target via a spring with the same stiffness as the hard, medium and soft interactions to receive haptic feedback of the targets motion.  #@NEW_LINE#@#  Subjects tracked the haptic target for 40s, and experienced 5 trials of each coupling stiffness consecutively in the order of the hard, medium and soft interactions, respectively.  #@NEW_LINE#@#  
A linear mixed-effects model was employed to fit the improvement c = 1  ec/e, where e is the error of a subject in a solo trial and ec is the same subjects error on a connected trial, as a function of the relative error, p = 1  ep/e, where ep is the partners error in a solo trial, and the log of the coupling stiffness  = log10(K):  #@NEW_LINE#@#  
(2)  #@NEW_LINE#@#  
where 0 is the intercept, 1 to 5 are the parameters for each predictor and 03  is the unexplained variance of the improvement for each dyad .  #@NEW_LINE#@#  
A similar linear model was used to fit the effort data with the interaction effort E = /c  1, where  is the effort in a solo trial and c is the effort in a connected trial, as a function of the dependent variable, the relative error p and  as predictors:  #@NEW_LINE#@#  
(3)  #@NEW_LINE#@#  
In both of these linear models, we compared each model without the coupling stiffness term  and their interaction terms using a likelihood ratio test to demonstrate the significance of the coupling dynamics on the performance improvement and the interaction effort.  #@NEW_LINE#@#  The same test was conducted by replacing the predictor K with a categorical variable that labelled whether the dyads experienced the medium, hard then soft interactions or the medium, soft then hard interactions.  #@NEW_LINE#@#  This revealed that neither the performance improvement (2(3) = 2.53, P0.47) nor the interaction effort (2(2) = 0.48, P0.79) were affected by the ordering of the coupling stiffness that dyads experienced.  #@NEW_LINE#@#  Therefore, all dyads data were analyzed together.  #@NEW_LINE#@#  

Computational_framework_to_simulate_interaction  #@NEW_LINE#@#  
A model was developed in discrete time {i dt, i = 1,2,} to simulate how two partners coupled by an elastic band plan their movement to track a randomly moving target in 1 dimension.  #@NEW_LINE#@#  At every time index i the target with position ti must be estimated, then a motor command ui is generated to move the wrists position i to the target.  #@NEW_LINE#@#  First, we describe the state equation that governs the movement of the target, and then that of the wrist, and combine these two equations to formulate a single state equation of the full system.  #@NEW_LINE#@#  The movement of the target, which is assumed to be moving randomly via Gaussian noise in its velocity , is described by the first-order system  #@NEW_LINE#@#  
(4)  #@NEW_LINE#@#  
where  is the target state and  is the covariance matrix.  #@NEW_LINE#@#  
The control of the wrist, with state , is modelled as  with inertia I, i.e.  #@NEW_LINE#@#  in state-space format as  #@NEW_LINE#@#  
(5)  #@NEW_LINE#@#  
where  #@NEW_LINE#@#  
(6)  #@NEW_LINE#@#  
which is the control law to move the wrist towards the target, and Fi is the force from the elastic band, with stiffness K and damping D. The partners wrist, described by the state  is connected to ones own wrist through the elastic band that produces an elastic force,  #@NEW_LINE#@#  
(7)  #@NEW_LINE#@#  
Solo trials, where the subjects are not connected, are characterized by zero force Fi  0.  #@NEW_LINE#@#  
A subject using the motor command as described in Eq (6) to move their wrist according to Eq (5) to follow the target that moves according to Eq (4) is described by the full state equation  #@NEW_LINE#@#  
(8)  #@NEW_LINE#@#  
which is equivalent to the difference of Eq (5) minus Eq (4).  #@NEW_LINE#@#  

Interaction_strategies  #@NEW_LINE#@#  
Various interaction strategies are described from the sensory information exchange between the partners.  #@NEW_LINE#@#  First, we describe the behavior of one subject tracking the target ti alone using only visual feedback.  #@NEW_LINE#@#  To generate the motor command according to Eq (6), the state describing the difference between the target and the wrist is observed through  #@NEW_LINE#@#  
(9)  #@NEW_LINE#@#  
where the observation zi is corrupted by Gaussian visual sensory noise i with variance .  #@NEW_LINE#@#  This linear quadratic estimation is computed in discrete time using an iterative Kalman filter algorithm [29].  #@NEW_LINE#@#  Sensory delay in vision and proprioception is compensated by integrating Eq (8).  #@NEW_LINE#@#  
Now that we have described how to visually track a target, what motion planning model could be used to track the randomly moving target whilst being physically coupled to a partner?  #@NEW_LINE#@#  In the follow the leader model that subjects follow the partners wrist position  if it is nearer to the target, otherwise the targets position ti is tracked.  #@NEW_LINE#@#  We assume that the state of the partners wrist  is known to a subject from the interaction force in Eq (7).  #@NEW_LINE#@#  The observation is dependent on  #@NEW_LINE#@#  
(10)  #@NEW_LINE#@#  
The interpersonal goal integration model proposes that the partners target  is optimally combined with ones own visual estimate of the target ti, such that  #@NEW_LINE#@#  
(11)  #@NEW_LINE#@#  
The method to estimate the partners target  from the interaction force with the partner and own vision and proprioception is described in a previous paper [18].  #@NEW_LINE#@#  First, one considers the partners control law  #@NEW_LINE#@#  
(12)  #@NEW_LINE#@#  
similar to ones own control law Eq (6).  #@NEW_LINE#@#  To estimate the partners target, the partners control gain  must be identified.  #@NEW_LINE#@#  To do so, Eq (12) must be inverted; the state of the partners wrist  is estimated through the interaction force Fi, the partners motor command  is estimated through the changes in the state of the partners wrist, and the partners target is initially substituted with ones own target state ti.  #@NEW_LINE#@#  Thus, to identify the partners control gain, the following sensory information must be observable:  #@NEW_LINE#@#  
(13)  #@NEW_LINE#@#  
where ones own wrist position i is measured through proprioception, ones own target position ti is measured through vision and the interaction force Fi is measured through haptics.  #@NEW_LINE#@#  In discrete time, the representation of the partner to estimate their control policy can be described by the equations:  #@NEW_LINE#@#  

(14)  #@NEW_LINE#@#  

While identifying the partners control policy , one can infer the partners target by replacing ones own target t in Eq (14), which was initially substituted in the beginning, with the partners target , yielding  #@NEW_LINE#@#  
(15)  #@NEW_LINE#@#  
and with sensory information from only proprioception and haptics,  #@NEW_LINE#@#  
(16)  #@NEW_LINE#@#  
Eqs (13)(16) enable one to both estimate the partners control policy and infer the partners target.  #@NEW_LINE#@#  Note that the partners target can be estimated from knowledge of their control policy and from proprioceptive and haptic sensory information only; the substitution with ones own target is only necessary to identify the partners control policy.  #@NEW_LINE#@#  
The neuromechanical goal sharing model suggests that partners integrate vision and haptics as in Eq (11), but the haptic information is degraded by the coupling stiffness, which is modelled as additive sensory noise.  #@NEW_LINE#@#  What is the sensory noise in the haptic measurement of the partners target?  #@NEW_LINE#@#  We assumed that the haptic noise is equivalent to the partners visual noise in the tracking task  plus a noise due to the softness of the coupling dynamics .  #@NEW_LINE#@#  The value of  for each coupling stiffness was taken from the haptic tracking control experiment (see S1 Text for more information).  #@NEW_LINE#@#  

Sensitivity_analysis  #@NEW_LINE#@#  
For each proposed model, we conducted a sensitivity analysis to compare their predictive power over a parameter space.  #@NEW_LINE#@#  As the length of the trial is sufficiently long and the tracking task is continuous, we used an infinite-horizon optimal controller with quadratic cost.  #@NEW_LINE#@#  Two parameters of the model are adjustable; , a multiplier for the Gaussian noise i in the acceleration, and q  0, a multiplier for the state cost Q in the controller.  #@NEW_LINE#@#  L will minimize the cost functional  #@NEW_LINE#@#  
(17)  #@NEW_LINE#@#  
where xi is the combined state vector, ui is the motor command, the state cost qQ is positive semi-definite and control cost R  0.  #@NEW_LINE#@#  
 is a scaling factor of the process noise that determines the frequency content of the simulated trajectory, and q modulates the strength of the partners controllers.  #@NEW_LINE#@#  was bound within a range such that the trajectories were not jerky, and q was varied within a stable controllable range (see S1 Text).  #@NEW_LINE#@#  
The root mean squared error was used as a metric for predictive power.  #@NEW_LINE#@#  Over the whole parameter space, the neuromechanical goal sharing model had the most predictive power (S1 Fig in S1 Text).  #@NEW_LINE#@#  


Supporting_information  #@NEW_LINE#@#  
S1_Fig_Sensitivity_analysis_of_the_interaction_models_for_the_two_parameters_in_the_simulation  #@NEW_LINE#@#  
The log of the MAE between the fits from the data and the simulation as a function of q and .  #@NEW_LINE#@#  The MAE is relatively insensitive to changes in the strength q and .  #@NEW_LINE#@#  The neuromechanical goal sharing model has a lower RMSE than the follow the leader and interpersonal goal integration models for all parameter values.  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pcbi.1005971.s001  #@NEW_LINE#@#  
(TIF)  #@NEW_LINE#@#  

S2_Fig_Interpersonal_goal_integration_model_reproduces_the_medium_interaction__but_only_if_the_other_conditions_and_the_interaction_effort_are_ignored  #@NEW_LINE#@#  
In a previous study [18], we showed that the interpersonal goal integration model reproduced the medium interaction performance improvement.  #@NEW_LINE#@#  It can also reproduce the medium interaction data in this study, but only if the hard and soft interactions and the interaction effort, are ignored.  #@NEW_LINE#@#  Thus, the additional empirical data from this new study has refined our understanding of the goal sharing mechanism, resulting in the neuromechanical goal sharing model where the coupling dynamics influence the estimation of the partners goal.  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pcbi.1005971.s002  #@NEW_LINE#@#  
(TIF)  #@NEW_LINE#@#  

S1_Text_This_document_describes_the_sensitivity_analysis_used_to_find_the_simulation_parameters_for_the_best_fit_to_the_data_for_each_mechanism  #@NEW_LINE#@#  
We also demonstrate that the interpersonal goal sharing model from our previous study can explain the medium performance improvement, but only if the hard and soft interactions and the interaction effort are ignored.  #@NEW_LINE#@#  Thus, this model was sufficient for the previous study that only examined performance improvement during medium interaction, but cannot explain the interaction with different coupling dynamics.  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pcbi.1005971.s003  #@NEW_LINE#@#  
(DOCX)  #@NEW_LINE#@#  

S1_Data_Text_file_containing_data_from_all_14_dyads_in_the_human-human_interaction_experiments  #@NEW_LINE#@#  
Each row comes from a paired data point that compares a connected trial with the proceeding solo trial.  #@NEW_LINE#@#  Each column contains data in the following order where 1 denotes one partner and 2 the other: solo error (1), solo error (2), connected error (1), connected error (2), solo total effort (1), solo total effort (2), connected total effort (1), connected total effort (2), solo co-contraction (1), solo co-contraction (2), connected co-contraction (1), connected co-contraction (2), solo reciprocal activation (1), solo reciprocal activation (2), connected reciprocal activation (1), connected reciprocal activation (2), connection stiffness, dyad number, and order of connection blocks.  #@NEW_LINE#@#  Errors are in degrees, effort measures are all in N/m and stiffness in Nm/deg.  #@NEW_LINE#@#  The order of connection is 1 for medium, hard and soft and 0 for medium, soft and hard.  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pcbi.1005971.s004  #@NEW_LINE#@#  
(TXT)  #@NEW_LINE#@#  

S2_Data_Text_file_containing_data_from_all_8_subjects_in_the_haptic_tracking_experiment  #@NEW_LINE#@#  
The data is composed of 30 rows and 8 columns, where the first 15 rows are the tracking error in degrees and the last 15 rows denote the connection stiffness of the respective trial in Nm/deg.  #@NEW_LINE#@#  Each column is from a separate subject.  #@NEW_LINE#@#  
https://doi.org/10.1371/journal.pcbi.1005971.s005  #@NEW_LINE#@#  
(TXT)  #@NEW_LINE#@#  


References  #@NEW_LINE#@#  



