article id="http://dx.doi.org/10.1073/pnas.1522419113"  #@NEW_LINE#@#  
title  #@NEW_LINE#@#  
Integration of parallel mechanosensory and visual pathways resolved through sensory conflict  #@NEW_LINE#@#  

Significance  #@NEW_LINE#@#  
Animals rely on information drawn from a host of sensory systems to control their movement as they navigate in and interact with their environment.  #@NEW_LINE#@#  How the nervous system consolidates and processes these channels of information to govern locomotion is a challenging reverse engineering problem.  #@NEW_LINE#@#  To address this issue, we asked how a hawkmoth feeding from a moving flower combines visual and mechanical (force) cues to follow the flower motion.  #@NEW_LINE#@#  Using experimental and theoretical approaches, we discover that the brain performs a remarkably simple summation of information from visual and mechanosensory pathways.  #@NEW_LINE#@#  Moreover, we reveal that the moth could perform the behavior with either visual or mechanical information alone, and this redundancy provides a robust strategy for movement control.  #@NEW_LINE#@#  

Abstract  #@NEW_LINE#@#  
The acquisition of information from parallel sensory pathways is a hallmark of coordinated movement in animals.  #@NEW_LINE#@#  Insect flight, for example, relies on both mechanosensory and visual pathways.  #@NEW_LINE#@#  Our challenge is to disentangle the relative contribution of each modality to the control of behavior.  #@NEW_LINE#@#  Toward this end, we show an experimental and analytical framework leveraging sensory conflict, a means for independently exciting and modeling separate sensory pathways within a multisensory behavior.  #@NEW_LINE#@#  As a model, we examine the hovering flower-feeding behavior in the hawkmoth Manduca sexta.  #@NEW_LINE#@#  In the laboratory, moths feed from a robotically actuated two-part artificial flower that allows independent presentation of visual and mechanosensory cues.  #@NEW_LINE#@#  Freely flying moths track lateral flower motion stimuli in an assay spanning both coupled motion, in which visual and mechanosensory cues follow the same motion trajectory, and sensory conflict, in which the two sensory modalities encode different motion stimuli.  #@NEW_LINE#@#  Applying a frequency-domain system identification analysis, we find that the tracking behavior is, in fact, multisensory and arises from a linear summation of visual and mechanosensory pathways.  #@NEW_LINE#@#  The response dynamics are highly preserved across individuals, providing a model for predicting the response to novel multimodal stimuli.  #@NEW_LINE#@#  Surprisingly, we find that each pathway in and of itself is sufficient for driving tracking behavior.  #@NEW_LINE#@#  When multiple sensory pathways elicit strong behavioral responses, this parallel architecture furnishes robustness via redundancy.  #@NEW_LINE#@#  

Results  #@NEW_LINE#@#  
Lateral_Flower_Tracking_Is_a_Multisensory_Behavior  #@NEW_LINE#@#  
We first explore if moths attend to both visual and mechanosensory cues during flower tracking and whether incongruence between these stimuli affect behavior.  #@NEW_LINE#@#  In the laboratory, a robotically actuated two-part artificial flower allows independent presentation of visual and mechanosensory cues (Fig 1A and SI Materials and Methods) along prescribed and repeatable trajectories.  #@NEW_LINE#@#  We present freely flying moths with flower motion stimuli in an assay spanning both coupled motion, for which the facade and nectary motions are the same as would be expected in naturalistic conditions, and sensory conflict, in which the two sensory modalities encode different motion stimuli (either the facade or nectary moves, while the other remains stationary) (Movie S1).  #@NEW_LINE#@#  In both sensory conflict categories, one sensory modality indicates that the flower is moving, whereas the other encodes that the flower is stationary.  #@NEW_LINE#@#  Soon after the moth initiates feeding, one or both flower components are commanded to oscillate along a prescribed trajectory, a linear combination of sinusoids with frequencies spanning 0.220 Hz (as in ref.  #@NEW_LINE#@#  4) (so as to include and extend beyond the motion spectrum moths experience when feeding in nature, 01.7 Hz).  #@NEW_LINE#@#  
When flower facade and nectary move in unison (the coupled condition) (Fig 2A), moth trajectories (Fig 2A, green) follow the reference trajectory (Fig 2A, black) with high fidelity.  #@NEW_LINE#@#  In the frequency domain (Fig 2 A, ii), each peak corresponds to a constituent frequency of the sum of sines stimulus; the fact that the peaks of the moth trajectory are coincident with the peaks of the input stimulus is an indication that the observed behavior is, in fact, a response to the presented motion stimulus.  #@NEW_LINE#@#  
Moth trajectories are noticeably altered in both sensory conflict conditions (Fig 2B).  #@NEW_LINE#@#  When only the nectary is actuated (the M-only condition in blue in Fig 2B), moths maintain good tracking with only slight reduction in amplitude compared with the coupled condition.  #@NEW_LINE#@#  In response to only facade motion (the V-only condition in gold in Fig 2B), tracking performance is dramatically diminished, but the peaks of the frequency spectrum of moth motion are still coincident to the motion stimulus.  #@NEW_LINE#@#  Moths respond coherently to both visual and mechanosensory cues to actively control flight while feeding; the behavior is multisensory.  #@NEW_LINE#@#  However, the unexpectedly anemic response to the visual stimulus challenges the prior suggestion that this is an exclusively visual behavior (16).  #@NEW_LINE#@#  

Open-Loop_Sensorimotor_Gains_of_Visual_and_Mechanosensory_Pathways_Are_Consistent_Across_Sensory_Conflict_Conditions  #@NEW_LINE#@#  
Sensory systems measure exogenous motion with respect to the animals body frame coordinates, e(t)=r(t)y(t) (Fig 1), referred to as the sensory slip or sensory error.  #@NEW_LINE#@#  An animal that is tracking a moving reference does so by minimizing this sensory error.  #@NEW_LINE#@#  During flower feeding, the different sensory modalities typically encode the same motion stimulus, and as such, the same locomotor response simultaneously minimizes both error signals (em and ev in Fig 1B).  #@NEW_LINE#@#  
In a sensory conflict experiment paradigm, we present the animal with uncorrelated visual and mechanosensory stimuli such that there does not exist a motor output, which simultaneously minimizes both error signals.  #@NEW_LINE#@#  In the M-only paradigm, the mechanosensory error signal encodes the positional difference of the moth with respect to the moving nectary, em(t)=rm(t)y(t), whereas the visual slip represents the position of the moth with respect to the motionless flower facade, ev(t)=y(t).  #@NEW_LINE#@#  Conversely, in the V-only condition, ev(t)=rv(t)y(t), whereas em(t)=y(t).  #@NEW_LINE#@#  As such, we consider not only the tracking error to the motion stimulus but also the error with respect to the motionless stimulus.  #@NEW_LINE#@#  By putting the sensory pathways into conflict (a sensory tug of war), we reveal the relative gain assigned to each pathway (the open-loop transforms Gm and Gv in Eq.  #@NEW_LINE#@#  3) and show that these weights are unchanged as a function of the stimulus motion content.  #@NEW_LINE#@#  It is important to note that, unlike assays that test sensory weighting as a function of reliability, the agreement (or lack thereof) between the motion stimuli does not affect the signal-to-noise ratio of either sensory pathway.  #@NEW_LINE#@#  
Remarkably, the time courses of the error signals are quite similar in the M- and V-only conditions (Fig 2 D and E), despite the dramatic differences in moth flight trajectories in these experiments.  #@NEW_LINE#@#  For the coupled condition, nectary and flower face move coherently, giving a single error signal em(t)=ev(t) (Fig 2C).  #@NEW_LINE#@#  For the M- and V-only conditions (Fig 2 D and E, respectively), we compare the mechanosensory (blue in Fig 2 D and E) and visual errors (gold in Fig 2 D and E).  #@NEW_LINE#@#  In the M-only condition, the moths trajectories closely follow the mechanical stimulus (the moving nectary), resulting in a greater visual slip.  #@NEW_LINE#@#  In the V-only case, the trajectory of the moths lateral motion is substantially attenuated, again yielding close tracking of the now stationary nectary.  #@NEW_LINE#@#  The resulting error is nearly identical to that from the M-only condition, favoring lower mechanosensory error at the expense of increased visual slip.  #@NEW_LINE#@#  Comparing M- and V-only conditions in the frequency-domain representation of error (Fig 2 D, ii and E, ii), the behavior favors lower mechanosensory error at the expense of increased visual slip at the lower behaviorally relevant frequencies; at high frequencies, tracking performance attenuates (for all conditions), and as a result, the errors converge to a baseline, in which slip with respect to the moving stimulus nears unity and error with respect to the motionless stimulus approaches zero (Fig S1).  #@NEW_LINE#@#  
In sensory conflict, it is not the case that moths are worse at tracking the motion stimulus for lack of sensory information.  #@NEW_LINE#@#  Rather, the observed attenuation is the response to the motion stimulus mitigated by a response to the stationary stimulus.  #@NEW_LINE#@#  Surprisingly, the mechanosensory pathway is more heavily weighted than the visual.  #@NEW_LINE#@#  

Mechanosensory_and_Visual_Contributions_Sum_Linearly  #@NEW_LINE#@#  
The control strategy that underlies this behavior balances (with some unequal weighting) the perceived visual and mechanosensory slips, and this strategy is consistent across the conflict paradigms tested.  #@NEW_LINE#@#  How are these signals consolidated in the coupled condition?  #@NEW_LINE#@#  A simple hypothesisand one that has been proposed for the interaction of visual and antennal pathways (9, 10)is linear summation, and the sensory conflict paradigm is ideally suited for testing this hypothesis.  #@NEW_LINE#@#  
The frequency-domain approach leverages a convenient property of linear dynamical systems: when excited by a sinusoidal input, the output of a linear dynamical system is a sinusoid at the same frequency, consistently scaled in amplitude and shifted in time by frequency-dependent gain and phase, respectively (Fig 3).  #@NEW_LINE#@#  This frequency-preserving property is evinced by the alignment of peaks between the input and output frequency spectra (Fig 2 A and B).  #@NEW_LINE#@#  A linear dynamical system is described by its transfer function, represented graphically as a Bode plot of the frequency-dependent gains and phases.  #@NEW_LINE#@#  Behavioral transfer functions are estimated empirically as the ratio of the Fourier transforms of the sampled output (moth motion) and input signal (flower motion), H()=Y()/R(), where  is the frequency variable (Fig 3 and Fig S1).  #@NEW_LINE#@#  
Moths exhibit slight attenuation and phase lag in the M-only stimulus condition (Fig 3A, blue).  #@NEW_LINE#@#  In the V-only condition (Fig 3A, gold), the mean gain is severely attenuated, even at the lowest frequencies (between 0.23 and 0.43 in the range 0.21 Hz), and phase is leading in this band.  #@NEW_LINE#@#  When presented coherent visual and mechanosensory cues (Fig 3B, green), moths track with high fidelity at low frequencies characterized by near-unity gain and small phase lags.  #@NEW_LINE#@#  
The block diagram depicted in Fig 1B suggests a deconstruction of these transfer functions into constituent dynamical blocks.  #@NEW_LINE#@#  Coupled motion yields the following behavioral transform (we omit the frequency argument  for clarity):H=(Sm+Sv)CP1+(Sm+Sv)CPandY=HR.  #@NEW_LINE#@#  [1]  #@NEW_LINE#@#  
Also, for the sensory conflict paradigms, the transfer function for the M- and V-only responses isY=SmCP1+(Sm+Sv)CPHmRm+SvCP1+(Sm+Sv)CPHvRv.  #@NEW_LINE#@#  [2]  #@NEW_LINE#@#  
Note that, in conflict conditions, both sensory transforms, Sv and Sm, appear in the denominator; the denominator reflects the reafferent pathway, the negative feedback that represents ego motion with respect to both the moving and stationary features.  #@NEW_LINE#@#  These behavioral transforms reveal an interaction between sensory pathways in closed loop, and therefore, the M- and V-only responses do not transparently represent the open-loop dynamics of the underlying sensory processes.  #@NEW_LINE#@#  
Still, linear summation implies that the sum of M- and V-only responses predicts the coupled response, H=Hm+Hv (Eqs.  #@NEW_LINE#@#  1 and 2).  #@NEW_LINE#@#  The close agreement between the sum of the M- and V-only responses (Fig 3B, brown dashed line) and the response to coupled stimuli is consistent with a model in which mechanosensory and visual processing occurs on parallel and independent pathways that sum linearly.  #@NEW_LINE#@#  Moreover, the sensory weights are constant across our stimulus conditions.  #@NEW_LINE#@#  

Linear_Summation_Furnishes_a_Predictive_Model  #@NEW_LINE#@#  
If the linear summation hypothesis truly reflects the underlying computation, then these transfer functions should provide a predictive model, allowing us to forecast the response to novel combinations of visual and mechanosensory stimuli.  #@NEW_LINE#@#  
In a final set of experiments, we simultaneously actuate both the nectary and flower face with dramatically different and particularly crafted trajectories.  #@NEW_LINE#@#  We design two new sum of sines stimuli, rm(t) and rv(t), composed of five frequency components at 0.2, 0.7, 1.3, 1.9, and 2.9 Hz (Fig 4A).  #@NEW_LINE#@#  Using the empirical transfer functions Hv and Hm, we design the inputs (selecting appropriate amplitude and phase at each frequency from Tables S1 and S2), such that the predicted visual and mechanosensory contributions are identical in amplitude and perfectly antiphase (Fig 4B).  #@NEW_LINE#@#  The linear summation model predicts that the combined effect of these trajectories should elicit a zero motion response.  #@NEW_LINE#@#  However, it would then be impossible to differentiate between this cancellation of responses and no response at all (which might be reasonable to expect from an animal presented such a confounding set of sensory stimuli).  #@NEW_LINE#@#  Therefore, we select a single frequency (0.7 Hz) at which the outputs sum constructively.  #@NEW_LINE#@#  Hence, the moth receives largely antagonistic sum of sines stimuli and is predicted to respond with a pure sinusoidal trajectory at the prescribed frequency (Fig 4C).  #@NEW_LINE#@#  
The spectrum of the moth trajectory clearly shows a peak at the selected frequency and attenuation of all other responses (Fig 4D, Right).  #@NEW_LINE#@#  We repeat this experiment, designing the stimuli such that responses at 1.9 Hz sum constructively (Fig S2), and as predicted, we observe a significant peak at the desired frequency and attenuation at all others.  #@NEW_LINE#@#  Importantly, the stimuli used in these two iterations have identical power spectra; only the relative phases between visual and mechanosensory stimuli are changed.  #@NEW_LINE#@#  The annihilation of antagonistic stimuli further corroborates the hypothesis that sensory integration attenuates noise; if we presume that noise signals on different sensory pathways are independent, these components would not combine constructively, yielding reduced noise in the summed output.  #@NEW_LINE#@#  
The summation model allows us to predictably direct the moths trajectories.  #@NEW_LINE#@#  Perhaps most telling, the predictive models that we used to design these trajectories (the M- and V-only Bode plots depicted in Fig 3A) were each derived from different sets of animals.  #@NEW_LINE#@#  A third independent group was used to test the predictive model.  #@NEW_LINE#@#  The population responses predict the individual response, suggesting that the relative gains and phases of responses are highly preserved across individuals.  #@NEW_LINE#@#  

Mechanosensory_and_Visual_Pathways_Provide_Redundancy_for_Control  #@NEW_LINE#@#  
Sensory pathway refers to the aggregate transformation from error signal to motion output, the cascade of sensory, neural, and physical transforms SvCP and SmCP.  #@NEW_LINE#@#  From these inputoutput data, it is not possible to further parse the contributions of the constituent blocks.  #@NEW_LINE#@#  However, we may exploit the commonality between the transfer functions Hm and Hv to calculate the relative gain of the visual and mechanosensory systems, specifically |Sm|/|Sv|=|Hm|/|Hv|.  #@NEW_LINE#@#  
In the decade from 0.2 to 2 Hz, the gain of the mechanosensory pathway ranges from 3.9 to 1.6 times greater than that of the visual system (Tables S1 and S2).  #@NEW_LINE#@#  It seems logical that the mechanosensory pathway would carry such weight; the sensory cue is provided by the nectar spur, the actual location of the food source.  #@NEW_LINE#@#  However, under most natural conditions, the visual cues would be highly correlated to the flower motion as well.  #@NEW_LINE#@#  In fact, the visual response is not impoverished; rather, it only seems meager when pitted against the more sensitive mechanosensory response.  #@NEW_LINE#@#  
A statistically optimal sensory summation weights modalities commensurate to their reliability (19).  #@NEW_LINE#@#  In our experiments, the reliability of each sensory modality is unaffected across presentations, and accordingly, we observe consistent weighting in response to the coupled and conflicting motion stimuli.  #@NEW_LINE#@#  However, the seemingly feeble visual response raises an important question: for our experiment conditions (lighting, flower geometry, visual background, etc.  #@NEW_LINE#@#  ), are visual percepts deemed unreliable and as a result, attenuated as noise?  #@NEW_LINE#@#  If so, we should not expect the visual pathway to be sufficient to mediate the behavior on its own in the absence of mechanosensory cues.  #@NEW_LINE#@#  To the contrary, the visual pathway is independently sufficient.  #@NEW_LINE#@#  Although this isolation experiment is infeasible, we can estimate the responses of each modality given our existing empirical model.  #@NEW_LINE#@#  
From the formulations in Eqs.  #@NEW_LINE#@#  1 and 2, we could estimate the individual sensorimotor (open-loop) transforms for mechanosensory and visual pathways Gm and Gv:Gm=SmCP=Hm1HandGv=SvCP=Hv1H,whereY=SmCPGmEm+SvCPGvEv.  #@NEW_LINE#@#  [3]  #@NEW_LINE#@#  
Using the estimated sensorimotor transforms, we further construct hypothetical responses for a pair of sensory isolation experiments (Fig 3C), experiments that we could not perform.  #@NEW_LINE#@#  Let Hm be the transfer function describing the feeding response using only mechanosensory cues (e.g., were the moth to feed in complete darkness) (Fig 3C, blue dashed line).  #@NEW_LINE#@#  These transfer functions can be represented in terms of empirically measured responses asHm=SmCP1+SmCP=Gm1+Gm=Hm1H+Hm.  #@NEW_LINE#@#  [4]  #@NEW_LINE#@#  
Also, similarly, Hv would be the isolated visual response (e.g., were we to ablate or inhibit the sensilla on the proboscis) (Fig 3C, gold dashed line).  #@NEW_LINE#@#  
For comparison, we replot the mean empirical response from our coupled motion condition (Fig 3C, green).  #@NEW_LINE#@#  At low frequencies, the predicted responses are qualitatively similar to the coupled motion condition.  #@NEW_LINE#@#  Each sensory pathway in isolation seems sufficient to achieve good tracking performance; the pathways are redundant in the context of control.  #@NEW_LINE#@#  


Discussion  #@NEW_LINE#@#  
Behavioral_Context_Shapes_Sensory_Weighting  #@NEW_LINE#@#  
In this behavior, the proboscis plays a significant sensory role.  #@NEW_LINE#@#  However, for a similar task in which moths regulate distance from a looming flower, Farina et al.  #@NEW_LINE#@#  (16) concluded the opposite: that proboscis-mediated mechanosensory pathways contribute negligibly to the behavioral response.  #@NEW_LINE#@#  Moths tracking a fictive corolla moving longitudinally along a stationary nectary tube (analogous to our V-only condition) showed only slight attenuation in tracking performance compared with that for an intact flower (analogous to our naturalistic motion condition).  #@NEW_LINE#@#  It is likely that the lateral motions that we presented provide a more salient mechanical stimulus than the axial motions associated with looming movements, whereas looming visual motion elicits a strong optomotor response (20).  #@NEW_LINE#@#  Additionally, Farina et al.  #@NEW_LINE#@#  (16) conducted experiments on the diurnal moth, Macroglossum stellatarum, which may further impact the relative weighting of visual pathways compared with the crepuscular M. sexta.  #@NEW_LINE#@#  Analogously, in the interaction of vision and olfaction, nocturnal moths rely more heavily on olfactory cues, whereas diurnal moths favor visual cues (21).  #@NEW_LINE#@#  Hence, the weighting between modalities may well depend on the direction of stimulus motion as well as the ecological context to which the moth is adapted.  #@NEW_LINE#@#  

Sensory_Conflict_Reveals_Redundancy  #@NEW_LINE#@#  
Although we observe dramatically unequal weighting between visual and mechanosensory transforms, each pathway is in itself sufficient for mediating accurate tracking.  #@NEW_LINE#@#  Accurate trackinga behavioral transform H() near one (Fig S1)can be achieved by any sufficiently large sensorimotor transform, |G()|1 (again, we omit the argument ):H=G1+G.  #@NEW_LINE#@#  [5]  #@NEW_LINE#@#  
Moreover, as the gain of the sensorimotor transform increases, there are diminishing returns in terms of tracking performance, and this insensitivity endows robustness.  #@NEW_LINE#@#  A behavior arising from parallel sensorimotor transforms, G1() and G2(), and a pair of tunable weighting variables, 1 and 2, is described by the following:Y=1G1+2G21+1G1+2G2HR.  #@NEW_LINE#@#  [6]  #@NEW_LINE#@#  
The above equation represents the behavioral response when both sensory pathways encode the same motion stimulusthe coupled condition.  #@NEW_LINE#@#  In a sensory isolation paradigm, a single sensory modality is isolated by inhibiting other modalities by either manipulating the animal (e.g., surgical, genetic, or pharmacological) or altering the sensory milieu.  #@NEW_LINE#@#  In the mathematical representation in Eq.  #@NEW_LINE#@#  6, the isolation effectively modulates the weighting variables, 1 and 2.  #@NEW_LINE#@#  However, if both G1() and G2() are sufficiently large, the behavioral response is relatively insensitive to modulation of those weights.  #@NEW_LINE#@#  In nature, this redundancy can confer robustness to damage of a sensory organ or impoverished sensory information that the pathways mutually insure each other.  #@NEW_LINE#@#  In the laboratory, this robustness presents an experimental challenge in isolating the individual contributions of parallel pathways.  #@NEW_LINE#@#  
In contrast to isolation, sensory conflict effectively splits the behavioral transform into independently stimulated pathways:Y=1G11+1G1+2G2H1R1+2G21+1G1+2G2H2R2.  #@NEW_LINE#@#  [7]  #@NEW_LINE#@#  
Assuming H() near one, H1() and H2() are complementary; in conflict, either one or both must exhibit depreciation.  #@NEW_LINE#@#  For this investigation, we resort to sensory conflict out of necessity (to circumvent the requisite role of vision in insect flight), but the conflict paradigm furnishes a uniquely powerful tool for studying sensory integration.  #@NEW_LINE#@#  


Conclusion  #@NEW_LINE#@#  
Through sensory conflict, we show that the flower tracking behavior is mediated by a linear summation of parallel visual and mechanosensory pathways.  #@NEW_LINE#@#  We do not preclude adaptive sensory reweighting in response to changes in sensory salience or reliability (signal-to-noise ratio).  #@NEW_LINE#@#  This model provides a general description of the visualmechanosensory combination that is consistent with previous observations (2, 9, 10) and as such, may represent a more general topology for this sensory integration.  #@NEW_LINE#@#  More importantly, a single model explains the behavioral responses to both coupled and conflicting motion cues, even when the sensory inputs suggest antagonistic motor outputs.  #@NEW_LINE#@#  Visual and mechanosensory pathways are, as such, independent, and their summation gives rise to robustness via redundancy.  #@NEW_LINE#@#  

SI_Materials_and_Methods  #@NEW_LINE#@#  
We performed animal husbandry and prepared experimental lighting, temperature, flower scent, and food source following the protocols enumerated in ref.  #@NEW_LINE#@#  4.  #@NEW_LINE#@#  
Experimental_Apparatus  #@NEW_LINE#@#  
For coherent motion trials (Fig 2A), we used the same flower as in ref.  #@NEW_LINE#@#  4.  #@NEW_LINE#@#  For the sensory conflict experiments, we designed (Solidworks; Dassault Systèmes S.A.) and fabricated (UPrint SE; Stratasys) a two-part fictive flower.  #@NEW_LINE#@#  The nectary consisted of an elbow-shaped tube 7.5 mm in diameter, to which we attached a centrifuge tube containing 0.75 mL 20% (wt/vol) sucrose solution.  #@NEW_LINE#@#  The nectary was painted black to minimize visual salience.  #@NEW_LINE#@#  The nectary is accessible through a 2-mm-wide arced slot in the flower facade.  #@NEW_LINE#@#  In the M- and V-only conflict conditions (Fig 2B), we actuated one flower component using a servo motor harvested from a chart recorder (Model 156327-57; Gould Inc.), the same as was used in ref.  #@NEW_LINE#@#  4; the unactuated flower component was rigidly attached to the support scaffold.  #@NEW_LINE#@#  For the destructiveconstructive conflict experiments (Fig 4), facade and nectary were each actuated by a stepper motor and stepper controller (1067_0 PhidgetStepper Bipolar HC; Phidgets Inc.).  #@NEW_LINE#@#  

Dissociating_Visual_and_Mechanosensory_Cues  #@NEW_LINE#@#  
The two-part flower design aims at separating visual and mechanosensory cues.  #@NEW_LINE#@#  Here, we consider possible confounds of this design.  #@NEW_LINE#@#  
If the moth can see its proboscis at the point of insertion, the proboscis would provide a visual cue correlated to the nectary motion.  #@NEW_LINE#@#  The interommatidial angle for the Manduca eye is 0.94° (22).  #@NEW_LINE#@#  However, the crepuscular Manduca have superposition eyes, a spatial integration over several adjacent ommatidia trading off improved brightness for reduced resolution.  #@NEW_LINE#@#  At the insertion point into the flower, the proboscis would subtend an angle of less than 2.8° (assuming a proboscis diameter of 1 mm and insertion distance of 2 cm), which is on the order of a single pixel in moth vision.  #@NEW_LINE#@#  We do not believe that this would provide a strong visual cue compared with the contrasting silhouette of the flower facade.  #@NEW_LINE#@#  
Conversely, at the point of insertion, the proboscis might detect the motion of the facade, providing a mechanosensory cue correlated to what we consider to be solely a visual input.  #@NEW_LINE#@#  There are mechanosensory sensilla along the entire length of the proboscis: sensilla trichodea throughout and most densely at the proboscis elbow, sensilla styloconica at the proboscis tip, and sensilla of pilifer at the base (5).  #@NEW_LINE#@#  The sensilla of pilifer are thought to detect the flexion of the proboscis with respect to the head (similar to the Johnston organ at the base of the antenna and the campaniform sensilla at the base of fly halteres, each sensitive to strain caused by the deflection of its respective structure).  #@NEW_LINE#@#  Although we suspect that the mechanosensory control signal arises largely from these basal sensilla of pilifer, it is unclear what role the other sensilla types might play in the behavior; we are not aware of any neurophysiological support for input from proboscis mechanosensory cells.  #@NEW_LINE#@#  That said, only a small fraction of the mechanosensory sensilla could be in contact with flower facade.  #@NEW_LINE#@#  Furthermore, the width of the facade slot is twice the width of the proboscis diameter, and therefore, it is unlikely that the slit deflects the proboscis.  #@NEW_LINE#@#  The rubbing of the facade against the proboscis would suggest a phase-leading derivative (velocity) response, where as we observe, low phase lags consistent with a proportional (positional) response.  #@NEW_LINE#@#  
If the moth draws visual cues from the sight of its proboscis, it would suggest that some of the mechanosensory response should be attributed to the visual pathway and vice versa if the proboscis is perturbed by facade motion.  #@NEW_LINE#@#  We have made design choicespainting the nectary black and allowing ample clearance for the proboscis in the facade slotto mitigate these confounds as much as possible.  #@NEW_LINE#@#  

Experiment_Design  #@NEW_LINE#@#  
A common trajectory was used for the coherent motion and M- and V-only trials: a sum of sinusoids comprising 20 frequency components selected as prime multiples of 0.1 Hz (to avoid harmonic coincidence) logarithmically spaced and spanning a band from 0.2 to 19.9 Hz (Figs.  #@NEW_LINE#@#  2 and 3).  #@NEW_LINE#@#  At each frequency, the constituent signals were designed to have equal velocity amplitudes.  #@NEW_LINE#@#  Trials were 20 s in length, from which we extract 10 s from the middle.  #@NEW_LINE#@#  
For constructivedestructive trials, we design independent trajectories for the flower facade and the nectary, such that the predicted locomotor contributions at each frequency are equal in magnitude and antiphase; at one frequency, the predicted locomotor contributions from each pathway sum constructively, with equal magnitude and in phase:rm(t)=i=15Ai|Hm(i)|cos(2it+iHm(i))rv(t)=i=15ijAi|Hv(i)|cos(2it+iHv(i))whereij={1forij1fori=j,where i, =2{0.2,0.7,1.3,1.9,2.9}s1, and ij determines the constructively summing frequency (the frequency j selected from the set ).  #@NEW_LINE#@#  A and  are free parameters.  #@NEW_LINE#@#  The linear summation model thus predicts the moth positional output asy(t)=2Ajcos(2jt+j).These experiments were conducted for j, the constructive frequency, at 0.7 (Fig 4) and 1.9 Hz (Fig S2).  #@NEW_LINE#@#  Trials were 30 s in duration, and we analyzed the tracking bout from 5 to 25 s, video recorded at 100 frames s1, and digitized using DLTdataviewer (23).  #@NEW_LINE#@#  To compensate for the different heights of nectary and facade markers, the measured lateral displacement of the facade is scaled (by similar triangles) to provide the equivalent displacement at the z height of the nectary.  #@NEW_LINE#@#  

Frequency-Domain_Analysis  #@NEW_LINE#@#  
At each frequency, a transfer function, H, assumes a complex value:H=a+jb,[S1]where j=1.  #@NEW_LINE#@#  Equivalently, in polar coordinates, the transfer function can be represented asH=gexp(j),where g=a2+b2 is the gain, and =arctan(b/a) is the phase.  #@NEW_LINE#@#  Taking the logarithm of the above, we getlnH=lng+j.  #@NEW_LINE#@#  [S2]In this log-space representation, the real and imaginary arguments are the log gain and phase, respectively, and these quantities are depicted in Bode plots.  #@NEW_LINE#@#  For the Bode plots in Fig 3, we have demarcated the y axis with the values for gain (as opposed to log gain in decibels, which is typical) but maintained logarithmic spacing.  #@NEW_LINE#@#  
Statistics for gain in the behavioral transform are calculated on the log gain and exponentiated back to gain:|H()|logmean=1Nk=1Nln|Hk()||H()|logstd=1N1k=1N(ln|Hk()||H()|)2.Subsequently,|H()|mean=exp(|H()|logmean)|H()|±std=exp(|H()|logmean±|H()|logstd).Statistics for phase are calculated as the circular mean and SD:H()mean=1Nk=1NexpHk()jH()std=2lnR,where R is the vector strengthR=|1Nk=1Nexp(Hk()j)|.For predicted values (the summation prediction and the isolation predictions in Figs.  #@NEW_LINE#@#  3 B and C, respectively), confidence intervals are estimated using a propagation of uncertainty analysis.  #@NEW_LINE#@#  As an example, we consider the summation prediction, mapping empirical measurements of Hm and Hv to their predicted sum.  #@NEW_LINE#@#  We define a vector of log-gain and phase parameters for the M- and V-only responses:x=[gm,m,gv,v].Accordingly, the sample means and SDs are denoted byx¯=[g¯m,¯m,g¯v,¯v]=(g,m,mg,v,v).A prediction is described by two mapping functions: Fg, which maps measurements of log gain and phase to the predicted log gain; and F, which maps those same empirical quantities to the predicted phase.  #@NEW_LINE#@#  These mappings require first an exponentiation from the log space (Eq.  #@NEW_LINE#@#  S2) to the Cartesian representation (Eq.  #@NEW_LINE#@#  S1), then the prescribed arithmetic manipulation (in this case, a summation), and finally, a transformation back into the log space.  #@NEW_LINE#@#  The predicted mean response is calculated at each frequency asg^=Fg(x¯)^=F(x¯).Also, for each frequency, the SDs are predicted by^g=Jg2JgT^=J2JT,where Jg, is the Jacobian for each mapping:Jg,=dFg,dx|x¯.  #@NEW_LINE#@#  


Acknowledgments  #@NEW_LINE#@#  
We thank Eric Warrant and Jeff Riffell for insightful comments on the manuscript.  #@NEW_LINE#@#  Support was provided by Air Force Research Lab Grant FA8651-13-1-0004; Air Force Office of Scientific Research Grants FA9550-14-1-0398 and FA9550-11-1-0155; The Washington Research Foundation; and the Joan and Richard Komen Endowed Chair (T.L.D.  #@NEW_LINE#@#  ).  #@NEW_LINE#@#  

Footnotes  #@NEW_LINE#@#  


