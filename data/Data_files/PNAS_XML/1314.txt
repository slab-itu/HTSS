article id="http://dx.doi.org/10.1073/pnas.1718648115"  #@NEW_LINE#@#  
title  #@NEW_LINE#@#  
Data-driven bodymachine interface for the accurate control of drones  #@NEW_LINE#@#  

Significance  #@NEW_LINE#@#  
The teleoperation of nonhumanoid robots is often a demanding task, as most current control interfaces rely on mappings between the operators and the robots actions, which are determined by the design and characteristics of the interface, and may therefore be challenging to master.  #@NEW_LINE#@#  Here, we describe a structured methodology to identify common patterns in spontaneous interaction behaviors, to implement embodied user interfaces, and to select the appropriate sensor type and positioning.  #@NEW_LINE#@#  Using this method, we developed an intuitive, gesture-based control interface for real and simulated drones, which outperformed a standard joystick in terms of learning time and steering abilities.  #@NEW_LINE#@#  Implementing this procedure to identify body-machine patterns for specific applications could support the development of more intuitive and effective interfaces.  #@NEW_LINE#@#  

Abstract  #@NEW_LINE#@#  
The accurate teleoperation of robotic devices requires simple, yet intuitive and reliable control interfaces.  #@NEW_LINE#@#  However, current humanmachine interfaces (HMIs) often fail to fulfill these characteristics, leading to systems requiring an intensive practice to reach a sufficient operation expertise.  #@NEW_LINE#@#  Here, we present a systematic methodology to identify the spontaneous gesture-based interaction strategies of naive individuals with a distant device, and to exploit this information to develop a data-driven bodymachine interface (BoMI) to efficiently control this device.  #@NEW_LINE#@#  We applied this approach to the specific case of drone steering and derived a simple control method relying on upper-body motion.  #@NEW_LINE#@#  The identified BoMI allowed participants with no prior experience to rapidly master the control of both simulated and real drones, outperforming joystick users, and comparing with the control ability reached by participants using the bird-like flight simulator Birdly.  #@NEW_LINE#@#  

Results  #@NEW_LINE#@#  
Experiment_1__Identification_of_Preferred_Human_Flight_Strategies  #@NEW_LINE#@#  
The participants wore an HMD through which they were shown simulated flight sequences in FPV and were asked to follow the actions of the aircraft executing five distinct behaviors (constant forward motion, right-banked turn, left-banked turn, upward pitch, and downward pitch; SI Appendix) with self-selected, flight-like movements.  #@NEW_LINE#@#  Upper-body kinematics and electromyographic (EMG) activities of the subjects were recorded during the execution of the task (Fig 1A and SI Appendix, Fig S2) as these are often used as sources of information for BoMIs.  #@NEW_LINE#@#  

Experiment_2__BoMI_Control_of_a_Simulated_Drone  #@NEW_LINE#@#  
The subjects were shown a virtual environment displaying a series of waypoints to follow (Fig 1B) through a HMD.  #@NEW_LINE#@#  The first 9 min of virtual flight were considered as a training period.  #@NEW_LINE#@#  The final performance was evaluated at the end of the training, on an additional series of waypoints (Movie S4; see also SI Appendix).  #@NEW_LINE#@#  We compared the outcomes of the gesture-based control to a previous study in which the participants used a standard joystick or Birdly, an immersive platform simulating a birds flight (52).  #@NEW_LINE#@#  Additionally, we compared the evolution of the steering performance between the gesture-based controls and the joystick over three training sessions on consecutive days on a subset of those subjects.  #@NEW_LINE#@#  

Experiment_3__BoMI_Control_of_a_Real_Drone  #@NEW_LINE#@#  
We evaluated the transferability of the skills acquired during the virtual reality (VR) training to the control of an actual drone using the Torso strategy, as this approach proved to be superior for the control of a virtual aircraft (SI Appendix, Fig S1).  #@NEW_LINE#@#  The participants began with a 9-min VR training as described previously.  #@NEW_LINE#@#  Afterward, they were given the control of a real quadcopter with FPV video feedback, which they could freely fly for 2 min to get used to its dynamics.  #@NEW_LINE#@#  Eventually, they were asked to steer the drone through six gates arranged along an eight-shaped trajectory (Fig 1C; see also SI Appendix).  #@NEW_LINE#@#  
After completing the VR training and the free flight, the participants were able to steer the quadcopter along the defined path with an average percentage of validly crossed gates (PVC, 19) of 87.67 ± 9.88% (Movie S5).  #@NEW_LINE#@#  This result suggests a transfer of the control skills acquired in simulation and confirms the usability of the Torso strategy for the steering of a real drone.  #@NEW_LINE#@#  


Discussion  #@NEW_LINE#@#  
We proposed a systematic selection process to identify effective body movement patterns in nonhomologous HMIs and to reduce the sensor coverage necessary for the acquisition of the discriminant information.  #@NEW_LINE#@#  We applied the described method to the specific case of flight and derived a simple BoMI interface for drone control.  #@NEW_LINE#@#  We found that, despite the noninnate nature of flying, two common motives emerged during the spontaneous selection of congruent movements during a virtual imitation task.  #@NEW_LINE#@#  These two major patterns proved to be valid command inputs for the control of a virtual drone, with the simpler strategy involving only movements of the torso leading to higher performances than the strategy employing both the torso and the arms.  #@NEW_LINE#@#  Eventually, we demonstrated that a real quadcopter could be controlled with the first, simpler strategy.  #@NEW_LINE#@#  
When using only their torso to steer the trajectory of the simulated drone in the virtual environment, inexperienced participants needed less than 7 min of practice to reach a performance of 84.58% (Fig 6A).  #@NEW_LINE#@#  By comparison, users performing the same task with a joystick typically used for piloting drones only reached an average score of 59.42% (Fig 6A).  #@NEW_LINE#@#  Furthermore, the performance level obtained using the identified BoMI is comparable to the performance of subjects using the bird-flight simulator Birdly to steer the virtual drone (52) (Fig 5).  #@NEW_LINE#@#  However, the participants using this platform displayed higher initial performance and a steeper improvement.  #@NEW_LINE#@#  But the Birdly platform provides haptic and vestibular feedbacks in addition to the visual information used in this study, factors known to improve the execution of teleoperated tasks (51).  #@NEW_LINE#@#  The lying position imposed by Birdly may also have affected the rapid proficiency, since this platform allows the entire body to move as a whole, and this posture may be more closely associated with the idea of flying.  #@NEW_LINE#@#  Nonetheless, the comparable final steering performance suggests that the identification of intuitive BoMIs can compensate to a certain extent the absence of additional sources of feedback, while requiring only minimal recording apparatus.  #@NEW_LINE#@#  Moreover, the Torso control method led to 87.7% of gates crossed without collisions during the steering of a real drone along a complex trajectory following a 9-min training in simulation.  #@NEW_LINE#@#  
In a single session, the two implemented gestural strategies led to significantly different performance levels, with the participants using the Torso strategy outperforming those using the Torso and Arms approach (Fig 6A).  #@NEW_LINE#@#  This difference was expected, since the Torso and Arms strategy was derived from the movement patterns displayed by 5 out of 15 participants of Experiment 1, being therefore less representative of the population.  #@NEW_LINE#@#  Additionally, while the Torso strategy mapped three body DOFs (torso rotations) to two drone DOFs, the participants using their torso and arms had to correctly coordinate 13 DOFs to control the two rotations of the aircraft.  #@NEW_LINE#@#  Such an approach may however be of interest in the perspective of an extension of this work including additional commands or behaviors.  #@NEW_LINE#@#  
All of the subjects who trained for three consecutive days improved their performance, confirming the importance of practice.  #@NEW_LINE#@#  However, the intragroup variability significantly differed across the control methods after the third training session, as the steering ability displayed by some participants using either the joystick or the Torso and Arms strategy remained low (Fig 6B).  #@NEW_LINE#@#  Instead, all of the subjects using the Torso strategy displayed a final performance above 77% and the overall performance variability significantly decreased over time.  #@NEW_LINE#@#  Therefore, the Torso strategy was the only approach which all participants managed to master following the 3-d training, suggesting that this method may be suited to a broader range of users.  #@NEW_LINE#@#  
Surveying the spontaneous interaction strategies selected by nontrained users is a concept that has already been applied for the development of intuitive controllers for UAVs, either by means of interviews (43) or through Wizard-of-Oz experimentations (37, 39).  #@NEW_LINE#@#  However, these systems focus on the identification of discrete commands and have the user interact with the drone from an external perspective.  #@NEW_LINE#@#  Conversely, our work presents a case of a data-driven, gesture-based interface for the continuous and immersive control of drones using an immersive visual feedback.  #@NEW_LINE#@#  Our present approach could easily be translated into a wearable implementation using an inertial measurement unit to acquire the three-dimensional torso angles.  #@NEW_LINE#@#  This would provide a substantial benefit over HMIs using video-based motion tracking, which imposes constraints on lighting conditions in the operating environment and on the users freedom of displacement, and thus limit the applicability of such a controller in natural environments.  #@NEW_LINE#@#  
A possible limitation of this study could be found in the mapping (scaling and offset constants) used to translate upper-body movements into commands of the simulated and real drones.  #@NEW_LINE#@#  The chosen mapping has shown to be sufficiently sensitive to steer the drone along the relatively smooth waypoint paths used in the experiments described here.  #@NEW_LINE#@#  However, we cannot exclude that sinuous trajectories involving sharp changes of directions may require different or even adaptive mapping values.  #@NEW_LINE#@#  Indeed, it is known that humans make directional errors when relying only on proprioception to estimate the spatial location of their limbs, and that these errors are proportional to the distance to the body centerline (53, 54).  #@NEW_LINE#@#  Building on this knowledge, previous studies showed that nonlinear transformations of the users arm movements led to faster and more precise control of a robotic arm than a simple scaling (14, 55).  #@NEW_LINE#@#  Further studies will be needed to understand the role of more complex mappings to extend the results of this work.  #@NEW_LINE#@#  
Another limitation comes from the small diversity of our study population, which consisted mainly of young, male university students.  #@NEW_LINE#@#  It is unknown to which extent experience and observation shape the human representation of noninnate behaviors such as flight.  #@NEW_LINE#@#  We can therefore not exclude that factors such as age, gender, physical condition, or familiarity with technology could lead to the identification of different body motion patterns.  #@NEW_LINE#@#  However, such discrepancies may highlight interesting causes in motor learning and representation rather than invalidating the proposed identification method.  #@NEW_LINE#@#  

Conclusion  #@NEW_LINE#@#  
The results of this study have a significant importance for the field of teleoperation and more generally HMIs.  #@NEW_LINE#@#  Often, control strategies are predefined and selected to comply with existing interfaces rather than derived from spontaneous representations of the interaction.  #@NEW_LINE#@#  The implementation of a methodology to identify bodymachine patterns for specific applications could lead to the development of more intuitive and effective interfaces, which could in turn reduce the training time required to reach proficiency, limit the workload associated with the operation of the system, and eventually improve the reliability of teleoperated missions.  #@NEW_LINE#@#  Moreover, the method described in this article could be extended to different populations, machines, and operations, including individuals with limited or impaired body functions.  #@NEW_LINE#@#  

Methods  #@NEW_LINE#@#  
Seventeen subjects participated in Experiment 1, in which they were asked to produce self-selected upper-body movements corresponding to predefined drone commands.  #@NEW_LINE#@#  For Experiment 2, 44 new participants were asked to steer a virtual drone using the Torso or the Torso and Arms strategy during a single session.  #@NEW_LINE#@#  Sixteen randomly selected participants repeated this task on two additional, consecutive days.  #@NEW_LINE#@#  Ten new participants were recruited for Experiment 3.  #@NEW_LINE#@#  They were first asked to control a virtual drone using the Torso strategy and afterward to steer a real drone through circular gates (see SI Appendix for details).  #@NEW_LINE#@#  The experiments were approved by the École Polytechnique Fédérale de Lausanne Brain Mind Institute Ethics Committee for Human Behavioral Research and the Ethics Committee Geneva.  #@NEW_LINE#@#  

Acknowledgments  #@NEW_LINE#@#  
This research was supported by the National Competence Center in Research in Robotics, funded by the Swiss National Science Foundation, and the Bertarelli Foundation.  #@NEW_LINE#@#  

Footnotes  #@NEW_LINE#@#  

This open access article is distributed under Creative Commons Attribution-NonCommercial-NoDerivatives License 4.0 (CC BY-NC-ND).  #@NEW_LINE#@#  

