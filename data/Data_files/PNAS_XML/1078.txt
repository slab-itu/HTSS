article id="http://dx.doi.org/10.1073/pnas.1712673115"  #@NEW_LINE#@#  
title  #@NEW_LINE#@#  
Bayesian selection of misspecified models is overconfident and may cause spurious posterior probabilities for phylogenetic trees  #@NEW_LINE#@#  

Significance  #@NEW_LINE#@#  
The Bayesian method is widely used to estimate species phylogenies using molecular sequence data.  #@NEW_LINE#@#  While it has long been noted to produce spuriously high posterior probabilities for trees or clades, the precise reasons for this overconfidence are unknown.  #@NEW_LINE#@#  Here we characterize the behavior of Bayesian model selection when the compared models are misspecified and demonstrate that when the models are nearly equally wrong, the method exhibits unpleasant polarized behaviors, supporting one model with high confidence while rejecting others.  #@NEW_LINE#@#  This provides an explanation for the empirical observation of spuriously high posterior probabilities in molecular phylogenetics.  #@NEW_LINE#@#  

Abstract  #@NEW_LINE#@#  
The Bayesian method is noted to produce spuriously high posterior probabilities for phylogenetic trees in analysis of large datasets, but the precise reasons for this overconfidence are unknown.  #@NEW_LINE#@#  In general, the performance of Bayesian selection of misspecified models is poorly understood, even though this is of great scientific interest since models are never true in real data analysis.  #@NEW_LINE#@#  Here we characterize the asymptotic behavior of Bayesian model selection and show that when the competing models are equally wrong, Bayesian model selection exhibits surprising and polarized behaviors in large datasets, supporting one model with full force while rejecting the others.  #@NEW_LINE#@#  If one model is slightly less wrong than the other, the less wrong model will eventually win when the amount of data increases, but the method may become overconfident before it becomes reliable.  #@NEW_LINE#@#  We suggest that this extreme behavior may be a major factor for the spuriously high posterior probabilities for evolutionary trees.  #@NEW_LINE#@#  The philosophical implications of our results to the application of Bayesian model selection to evaluate opposing scientific hypotheses are yet to be explored, as are the behaviors of non-Bayesian methods in similar situations.  #@NEW_LINE#@#  

(A) The three binary rooted trees for three species T1,T2, and T3 and the star tree T0.  #@NEW_LINE#@#  (B) The three binary unrooted trees for four species T1,T2, and T3 and the star tree T0.  #@NEW_LINE#@#  The branch length parameters are shown next to the branches, measured by the expected number of nucleotide changes per site.  #@NEW_LINE#@#  In the star-tree simulations, the star tree is used to generate data, which are analyzed to calculate the posterior probabilities for the three binary trees, with the star tree excluded.  #@NEW_LINE#@#  
Results  #@NEW_LINE#@#  
Problem_Description  #@NEW_LINE#@#  
We consider independent and identically distributed (i.i.d.)  #@NEW_LINE#@#  models only.  #@NEW_LINE#@#  The data x={x1,,xn} are an i.i.d.  #@NEW_LINE#@#  sample from the true model g().  #@NEW_LINE#@#  We consider two models as the case for more models is obvious.  #@NEW_LINE#@#  Model Hk has density fk(x|k), with dk free parameters (k), k=1,2.  #@NEW_LINE#@#  We are in particular interested in models of the same dimension, with d1=d2=d.  #@NEW_LINE#@#  In the Bayesian analysis, we assign a uniform prior for the two models (1=2=12) and also a prior for the parameters within each model Hk: fk(k).  #@NEW_LINE#@#  The posterior model probabilities, Pk=(Hk|x), are then proportional to the marginal likelihoods: Mk=fk(x)=fk(k)fk(x|k)dk; that is, P1/P2=(1M1)/(2M2)=M1/M2.  #@NEW_LINE#@#  We are interested in the asymptotic behavior of P1 in large datasets (as n).  #@NEW_LINE#@#  
The dynamics depend on how well the models fit the data.  #@NEW_LINE#@#  Let k^ be the maximum-likelihood estimate (MLE) of k under model Hk from dataset x.  #@NEW_LINE#@#  Let k be the limiting value of k^ when the data size n. In other words k minimizes the KullbackLeibler (K-L) divergence from model Hk to the true model,Dk=DKL(g,fk)=g(x)logg(x)dxg(x)logfk(x|k)dx,[1]and is known as the best-fitting or pseudotrue parameter value under the model (18).  #@NEW_LINE#@#  Dk (calculated at k) measures the distance from Hk to the true model, with Dk0.  #@NEW_LINE#@#  We say a model is right if it encompasses the true model, with D=0, and wrong if D greater than 0.  #@NEW_LINE#@#  Model 1 is less wrong than model 2 if D1less_thanD2.  #@NEW_LINE#@#  Both models are equally right if D1=D2=0 and equally wrong if D1=D2 greater than 0.  #@NEW_LINE#@#  

Characterization_of_Bayesian_Model_Selection  #@NEW_LINE#@#  
The asymptotic behavior of P1=(H1|x) when n is analyzed in SI Text and summarized in Fig 2.  #@NEW_LINE#@#  We identify three types of asymptotic behaviors: type 1 (balanced), type 2 (volatile), and type 3 (polarized), as defined below.  #@NEW_LINE#@#  We also refer to three types of inference problems that give rise to those behaviors.  #@NEW_LINE#@#  
Type 1 (balanced) is for the posterior model probability P1 to converge (as n) to a single reasonable value that is different from 0 to 1, such as 12.  #@NEW_LINE#@#  In other words, in essentially every large dataset, P112.  #@NEW_LINE#@#  This behavior occurs when the two models are essentially identical.  #@NEW_LINE#@#  Examples include comparison of two identical models with no parameters, such as H1:p=0.5 and H2:p=0.5 irrespective of the true p in a coin-tossing experiment (Fig 2, cases A1 and A2), and overlapping models where the best-fitting parameter values lie in the region of overlap (Fig 2, A3 and A4).  #@NEW_LINE#@#  Whether the two models are both right (A1 and A3) or both wrong (A2 and A4) does not affect the dynamics.  #@NEW_LINE#@#  The case of overlapping models is interesting.  #@NEW_LINE#@#  If the truth is p=12 while the two compared models are H1:0.4less_thanpless_than0.6 and H2:0less_thanpless_than1, and if we assign a uniform prior on p in each model, then as n, P111+0.2=56, which appears more reasonable than 12 as it favors the more-informative model H1.  #@NEW_LINE#@#  At any rate, the comparison of identical or overlapping models is unusual for testing scientific hypotheses.  #@NEW_LINE#@#  This type of problem is not considered further.  #@NEW_LINE#@#  
Type 2 (volatile) is for P1 to converge to a nondegenerate statistical distribution, such as U(0,1).  #@NEW_LINE#@#  In other words, if we analyze different large datasets, all generated from the same true model, to compare two equally right or equally wrong models, P1 varies among datasets according to a nondegenerate distribution.  #@NEW_LINE#@#  This behavior occurs when the two compared models become unidentifiable as the data size n. There are two scenarios.  #@NEW_LINE#@#  In the first one, both models are right, with D1=D2=0 (Fig 2, B1 and B2).  #@NEW_LINE#@#  In the second one both models are equally wrong (with D1=D2 greater than 0) but indistinct (Fig 2, B3 and B4).  #@NEW_LINE#@#  We say that two models are indistinct if and only if they, each at the best-fitting parameter values, are unidentifiable, with f1(x|1)=f2(x|2) for essentially all x.  #@NEW_LINE#@#  In other words, in infinite data, the two models make essentially the same predictions about the data and are unidentifiable.  #@NEW_LINE#@#  In both scenarios of equally right and equally wrong models, P1 varies among datasets according to a nondegenerate distribution.  #@NEW_LINE#@#  
Type 3 (polarized) is for P1 to have a degenerate two-point distribution, at values 0 and 1.  #@NEW_LINE#@#  If we analyze large datasets to compare two models, we favor model 1 with total confidence in some datasets and model 2 with total confidence in others.  #@NEW_LINE#@#  This behavior is observed when the two models are equally wrong and also distinct.  #@NEW_LINE#@#  
It is remarkable that the asymptotic behavior is determined by whether or not the compared models are distinct and not by whether they are both right or both wrong or by whether the compared models have unknown parameters.  #@NEW_LINE#@#  For example, cases B1 (two right models) and B3 (two equally wrong models) in Fig 2 show the same volatile behavior, while cases C1 (no free parameters) and C2 (with free parameters) show the same polarized behavior.  #@NEW_LINE#@#  

Problem_1_Fair-Coin_Paradox_(Equally_Wrong_Models_with_No_Free_Parameter)  #@NEW_LINE#@#  
Consider a coin-tossing experiment in which the coin is fair with the probability of heads p=12.  #@NEW_LINE#@#  We use the data of x heads in n tosses to compare two models: H1:p=0.4 (tail bias) and H2:p=0.6 (head bias).  #@NEW_LINE#@#  The two models are equally wrong.  #@NEW_LINE#@#  We assign a uniform prior for the two models (12 each) and calculate the posterior model probability P1=(H1|x).  #@NEW_LINE#@#  This is a type-3 problem (Fig 2, C1).  #@NEW_LINE#@#  
As the models involve no free parameters, the likelihood (L) and marginal likelihood (M) are the same, given by the binomial probability for data x.  #@NEW_LINE#@#  The posterior odds are the likelihood-ratioP11P1=M1M2=0.4x0.6nx0.6x0.4nx=(0.40.6)2xn.  #@NEW_LINE#@#  [2]When n is large, P1 tends to be extreme (close to 0 or 1).  #@NEW_LINE#@#  Indeed, less_thanP1less_than1 if and only if |2xn|less_thanB=log{/(1)}log{0.4/0.6}.  #@NEW_LINE#@#  If n is large, 2xn is (0,n), so that{|2xn|less_thanB}12(Bn)2B2n,[3]where  is the cumulative distribution function (CDF) for (0,1).  #@NEW_LINE#@#  If =1%, we have B = 11.33296, so that only 11 data outcomes will give P1 in the range (0.01, 0.99), with xn2 being 5,4,,5.  #@NEW_LINE#@#  For n=103,104,105,106, we have {0.01less_thanP1less_than0.99} = 0.280, 0.090, 0.0286, and 0.0090 using the normal approximation of Eq.  #@NEW_LINE#@#  3 or 0.272, 0.0876, 0.0277, and 0.0088 exactly by the binomial distribution.  #@NEW_LINE#@#  Thus, in large datasets, moderate posterior probabilities will be rare, and either H1 or H2 will be favored with posterior  greater than 0.99.  #@NEW_LINE#@#  When n, P1 has a degenerate two-point distribution, taking the values 0 and 1, each half of the times.  #@NEW_LINE#@#  This is the type-3 polarized behavior.  #@NEW_LINE#@#  Note that there is no information either for or against either model in the data.  #@NEW_LINE#@#  Fig 3 A, i shows the distribution of P1 for n=103.  #@NEW_LINE#@#  
Fig 3 A, ii shows the comparison of H1:p=0.42 against H2:p=0.6 when the truth is p=0.5.  #@NEW_LINE#@#  Here H1 is less wrong and will eventually dominate.  #@NEW_LINE#@#  However, in large and finite datasets, the more wrong model H2 can often receive high support.  #@NEW_LINE#@#  For example, for n=103, nonextreme posterior probabilities in the range 0.01less_thanP1less_than0.99 occur for only 13 data outcomes, with x being 504516, and in 14.8% of datasets, x is greater than those values so that P2 greater than 0.99.  #@NEW_LINE#@#  Indeed over the whole range 36n11,611, the more wrong model H2 is strongly favored too often, with (P2 greater than 0.99) greater than 0.01.  #@NEW_LINE#@#  The method becomes overconfident before it becomes reliable.  #@NEW_LINE#@#  It may be noted that such strong support for the more wrong model occurs only when the two models are opposing each other.  #@NEW_LINE#@#  It does not occur if both models are wrong in the same direction: In the comparison of H1:p=0.4 and H2:p=0.42 when the truth is p=0.5, the less wrong model H2 dominates in the posterior.  #@NEW_LINE#@#  

Problem_2_Fair-Balance_Paradox_(Equally_Right_Models_or_Equally_Wrong_and_Indistinct_Models)  #@NEW_LINE#@#  
The true model is (0,1), and we compare two models H1:(,1/), less_than0 and H2:(,1/), greater than 0, with  given.  #@NEW_LINE#@#  The data may represent measurement errors observed on a fair balance while the models claim that the balance has an unknown negative or positive bias.  #@NEW_LINE#@#  The best-fitting parameter value (the MLE when the data size n) is =0 in each model, when the two models become identical (indistinct).  #@NEW_LINE#@#  Thus, the two models are equally right if =1 (Fig 2, B2), and are equally wrong if =1/9 or 9 (Fig 2, B4).  #@NEW_LINE#@#  
We assign a uniform prior on the two models (12 each), and (0,1/) with  fixed, truncated to the appropriate range under each model.  #@NEW_LINE#@#  The data (x), an i.i.d.  #@NEW_LINE#@#  sample from (0,1), can be summarized as the sample mean x¯.  #@NEW_LINE#@#  It can be shown that the posterior model probability P1={H1|x} varies among datasets according to the densityf(P1)=+/nexp{[1(P1)]22[11n2]},[4]where 1 is the inverse CDF for (0,1) (Analysis of Problem 2 (Two Equally Right Models or Equally Wrong but Indistinct Models)).  #@NEW_LINE#@#  
Fig 3B shows the density of P1 for different values of precision (), with n=103.  #@NEW_LINE#@#  If =1, the two models are equally right, and f(P1)1 when n so that P1 behaves like a (0,1) random number (11, 12).  #@NEW_LINE#@#  If less_than1, the assumed variance (1/) is larger than the true variance, so that the distribution has a mode at 12.  #@NEW_LINE#@#  If  greater than 1, the assumed variance is too small, and P1 has a U-shaped distribution.  #@NEW_LINE#@#  If one overstates the precision of the experiment, one tends to overinterpret the data and generate extreme posterior model probabilities.  #@NEW_LINE#@#  In all three cases (less_than1,=1, greater than 1), P1 has a nondegenerate distribution.  #@NEW_LINE#@#  

Problem_3_Fair-Balance_Paradox_(Equally_Wrong_and_Distinct_Models)  #@NEW_LINE#@#  
The true model is (0,1), and the two compared models are H1:(,1/1) and H2:(,1/2), with 1less_than1less_than2 given, while  is a free parameter in each model.  #@NEW_LINE#@#  The best-fitting parameter value is =0 in each model, irrespective of the value of  assumed.  #@NEW_LINE#@#  Both models are wrong because of the misspecified variance: H1 is overdispersed while H2 is underdispersed.  #@NEW_LINE#@#  They are equally wrong, in the sense that D1=D2 in Eq.  #@NEW_LINE#@#  1, iflog12=12[5](Analysis of Problem 3 (Two Equally Wrong and Distinct Models, Gaussian with Incorrect Variances)).  #@NEW_LINE#@#  This is a type-3 problem (Fig 2, C2).  #@NEW_LINE#@#  We assign a uniform prior over the models (12 each), and (0,1/), with  given, within each model.  #@NEW_LINE#@#  The dataset, an i.i.d.  #@NEW_LINE#@#  sample of size n from (0,1), can be summarized as the sample mean x¯ and sample variance s2=1ni(xix¯)2.  #@NEW_LINE#@#  The posterior odds are given in Eq.  #@NEW_LINE#@#  S15 in Analysis of Problem 3 (Two Equally Wrong and Distinct Models, Gaussian with Incorrect Variances).  #@NEW_LINE#@#  
We use 1=0.25 and 2=2.58666, so that Eq.  #@NEW_LINE#@#  5 holds and the two models are equally wrong, to generate independent variables x¯(0,1/n) and ns2n22 and to calculate P1.  #@NEW_LINE#@#  Fig 3 C, i shows the estimated density of P1 for n=100, with =1.  #@NEW_LINE#@#  When n, P1 degenerates into a two-point distribution at 0 and 1, each with probability 12.  #@NEW_LINE#@#  These are the same dynamics as in problem 1 (Fig 3 A, i), even though in problem 1 the models do not involve any unknown parameters while here they do.  #@NEW_LINE#@#  
Fig 3 C, ii shows the density of P1 when 1=0.3 (which is closer to the true =1 than is 0.25), so that H1 is less wrong than H2 (with D1less_thanD2).  #@NEW_LINE#@#  In this case when n, P11.  #@NEW_LINE#@#  However, in large but finite datasets, P2 for the more wrong model H2 can be large in too many datasets: For example, with n=100, {P2 greater than 0.99}=0.0504: in 5.04% of datasets, the more wrong model H2 has posterior higher than 99%.  #@NEW_LINE#@#  

Star-Tree_Paradox_and_Bayesian_Phylogenetics  #@NEW_LINE#@#  
In Bayesian phylogenetics (1, 2), each model has two components: the phylogenetic tree describing the relationships among the species and the evolutionary model describing sequence evolution along the branches on the tree (19).  #@NEW_LINE#@#  Each tree Tk has a set of time or branch-length parameters (tk), which measure the amount of evolutionary changes along the branches.  #@NEW_LINE#@#  The evolutionary model may also involve unknown parameters ().  #@NEW_LINE#@#  The tree and the evolutionary model together specify the likelihood (20), with ={t,} being the unknown parameters.  #@NEW_LINE#@#  One of the trees is true, and all other trees are wrong, while the evolutionary model may be misspecified.  #@NEW_LINE#@#  The main objective is to infer the true tree.  #@NEW_LINE#@#  The data consist of an alignment of sequences from the modern species and have a multinomial distribution in which the categories correspond to the possible site patterns (configurations of nucleotides observed in the modern species) while the data size is the number of sites or alignment columns (21).  #@NEW_LINE#@#  
Here we consider three simple cases involving three or four species (Fig 1).  #@NEW_LINE#@#  We use the general theory described above to predict the asymptotic behavior of posterior probabilities for trees and use computer simulation to verify the predictions.  #@NEW_LINE#@#  
Case A (Fig 4 A and A´) involves equally right models.  #@NEW_LINE#@#  We use the rooted star tree T0 for three species with t=0.2 (Fig 1A) to generate datasets to compare the three binary trees.  #@NEW_LINE#@#  The JukesCantor (JC) substitution model (22) is used both to generate and to analyze the data, which assumes that the rate of change between any two nucleotides is the same.  #@NEW_LINE#@#  The molecular clock (rate constancy over time) is assumed as well, so that the parameters in each binary tree are the two ages of nodes (t0,t1), measured by the expected number of nucleotide changes per site.  #@NEW_LINE#@#  
The best-fitting parameter values are t0=0 and t1=0.2 for each of the three binary trees, in which case each binary tree converges to the true star tree.  #@NEW_LINE#@#  We assign uniform prior probabilities for the binary trees (13 each) and an exponential prior on branch lengths on each tree.  #@NEW_LINE#@#  According to our characterization, this is a type-2 problem of comparing equally right models (Fig 2, B2), so the posterior probabilities should have a nondegenerate distribution.  #@NEW_LINE#@#  This case was considered in previous studies (12, 14, 15), which generated numerically the limiting distribution of the posterior probabilities for the binary trees (P1,P2,P3) when n and pointed out that they do not converge to (13,13,13) (1113).  #@NEW_LINE#@#  
Case B (Fig 4 B and B´) involves equally wrong models that are indistinct.  #@NEW_LINE#@#  This is similar to case A except that the JC+ model (22, 23) is used to generate data, with different sites in the sequence evolving at variable rates according to the gamma distribution with shape parameter =1.  #@NEW_LINE#@#  The data are then analyzed using JC (equivalently to JC+ with =).  #@NEW_LINE#@#  The best-fitting parameter values (i.e., the MLEs of branch lengths in infinite data) are t0=0 and t1=0.16441 under each of the three binary trees.  #@NEW_LINE#@#  The binary trees thus represent equally wrong models (with D1=D2=D3 greater than 0 in Eq.  #@NEW_LINE#@#  1) that are indistinct.  #@NEW_LINE#@#  The posterior tree probabilities have a nondegenerate distribution.  #@NEW_LINE#@#  This is the type-2 volatile behavior for equally wrong and indistinct models (Fig 2, B4).  #@NEW_LINE#@#  
Case C (Fig 4 C and C´) involves equally wrong and distinct models.  #@NEW_LINE#@#  Like case B, the simulation model is JC+ with =1, and the analysis model is JC.  #@NEW_LINE#@#  However, we do not assume the molecular clock and consider unrooted trees for four species (Fig 1B).  #@NEW_LINE#@#  The true tree is the unrooted star tree T0 of Fig 1B, with t1=t2=t3=t4=0.2.  #@NEW_LINE#@#  The best-fitting parameter values (the MLEs of branch lengths in infinite data) are t0=0.01037,ti=0.16409,i=1,2,3,4, for each of the three binary trees (Fig 1B).  #@NEW_LINE#@#  As t0 greater than 0, the three binary trees are different from the star tree and represent equally wrong and distinct models (with D1=D2=D3 greater than 0 in Eq.  #@NEW_LINE#@#  1).  #@NEW_LINE#@#  As this is a type-3 problem (Fig 2, C4), our theory predicts that as n, the posterior probabilities for the three binary trees should degenerate into a three-point distribution, with probability 13 each, for (1, 0, 0), (0, 1, 0), and (0, 0, 1).  #@NEW_LINE#@#  In other words, one of the binary trees will have posterior 100% while the other two will have 0.  #@NEW_LINE#@#  This is confirmed by simulation (Table S1).  #@NEW_LINE#@#  
We note that most phylogenetic analyses involve unrooted trees as the clock assumption is violated except for closely related species.  #@NEW_LINE#@#  Furthermore, because of the violation of the evolutionary model, all trees (or the joint tree-process models) represent wrong statistical models.  #@NEW_LINE#@#  Thus, among the three cases considered in Fig 4, case C is the most relevant to analysis of real data, when Bayesian model selection exhibits type-3 polarized behavior.  #@NEW_LINE#@#  Previous analyses of the star-tree paradox (12, 14, 15) have deplored the volatile behavior of the Bayesian phylogenetic method, but those studies examined case A only, so the real situation is worse than previously realized.  #@NEW_LINE#@#  
A practically important scenario is where all binary trees are wrong because of violation of the evolutionary model but the true tree is less wrong than the other trees.  #@NEW_LINE#@#  We present such a case in Table S2, in which the data are simulated under JC+ (with =1) using a binary tree with a short internal branch (t0=0.002) and then analyzed under JC.  #@NEW_LINE#@#  When the amount of data approaches infinity, the true tree will eventually win, but there exists a twilight zone in which high posterior probabilities for wrong trees occur too frequently; according to Table S2, this zone is wider than 103less_thannless_than105.  #@NEW_LINE#@#  For example, at sequence length n=104 and at the 1% nominal level, the error rate of rejecting the true tree is 25.0% and the error rate of accepting a wrong tree is 16.6% (Table S2).  #@NEW_LINE#@#  


Discussion  #@NEW_LINE#@#  
High_Posterior_Probabilities_for_Phylogenetic_Trees  #@NEW_LINE#@#  
This work has been motivated by the phylogeny problem and in particular by the empirical observation of spuriously high posterior probabilities for phylogenetic trees (914).  #@NEW_LINE#@#  We note that certain biological processes such as deep coalescence (24, 25), gene duplication followed by gene loss (26), and horizontal gene transfer (24, 26) may cause different genes or genomic regions to have different histories.  #@NEW_LINE#@#  However, as discussed in the Introduction, posterior probabilities for many trees or clades observed in real data analyses are decidedly spurious even if the true tree is unknown.  #@NEW_LINE#@#  
One explanation for the spuriously high posterior probabilities for phylogenetic trees is the failure of current evolutionary models to accommodate interdependence among sites in the sequence, leading to an exaggeration of the amount of information in the data.  #@NEW_LINE#@#  Interacting sites may carry much less information than independent sites.  #@NEW_LINE#@#  This explanation predicts the problem to be more serious in coding genes than in noncoding regions of the genome as noncoding sites may be evolving largely independently due to lack of functional constraints.  #@NEW_LINE#@#  However, empirical evidence points to the opposite, with noncoding regions having higher substitution rates and higher information content (if they are not saturated with substitutions), generating more extreme posteriors for trees.  #@NEW_LINE#@#  
Our results suggest that the problem may lie deeper and may be a consequence of the polarized nature of Bayesian model selection when all models under comparison are misspecified.  #@NEW_LINE#@#  As the assumptions about the process of sequence evolution are unrealistic, the likelihood model is wrong whatever the tree, although the true tree may be expected to be less wrong than the other trees.  #@NEW_LINE#@#  As the different trees constitute opposing models that are nearly equally wrong, the inference problem is one of type 3 (Fig 2, C4).  #@NEW_LINE#@#  Bayesian tree estimation may then be expected to produce extreme posterior probabilities in large datasets.  #@NEW_LINE#@#  

Bayesian_Selection_of_Opposing_Misspecified_Models  #@NEW_LINE#@#  
We have provided a characterization of model selection problems according to the asymptotic behavior of the Bayesian method as the data size n [Fig 2 and General Theory for Equally Wrong Models with No Free Parameters (d=0) and General Theory for Equally Right or Equally Wrong Models with Free Parameters (d greater than 0)].  #@NEW_LINE#@#  While all of the problems considered here involve comparison of two equally right or equally wrong models, three different asymptotic behaviors are identified, which we label as type 1, type 2, and type 3.  #@NEW_LINE#@#  The type-1 behavior is for the posterior model probability P1 to converge to a sensible point value, such as 12.  #@NEW_LINE#@#  We consider this to be a good balanced behavior, following phylogeneticists (1012).  #@NEW_LINE#@#  The rationale is that one would like a sure answer given an infinite amount of data and the only reasonable sure answer should be 12 for each model, since the data contain no information for or against either model.  #@NEW_LINE#@#  This behavior occurs only when the two models are identical or overlapping, a situation that does not appear relevant to scientific inference.  #@NEW_LINE#@#  With type-2 behavior, P1 fluctuates among datasets (each of infinite size) like a random number, so that strong support may be attached to a particular model in some datasets.  #@NEW_LINE#@#  Biologists were surprised at this erratic behavior (1012), which we label as volatile.  #@NEW_LINE#@#  This occurs when the models are equally right or equally wrong but indistinct.  #@NEW_LINE#@#  In theory, type-2 behavior may not pose a serious problem, because the parameter posteriors under the models, if examined carefully, should make it clear that the competing models essentially gave the same interpretation of the data and should lead to the same scientific conclusion.  #@NEW_LINE#@#  In data simulated in ref.  #@NEW_LINE#@#  12 or in Fig 4 A and A´, the estimates of t0 should be very close to 0, and all binary trees are similar to the same star tree.  #@NEW_LINE#@#  Nevertheless this escaped our attention at the time.  #@NEW_LINE#@#  
With type-3 behavior, P1 is 0 in half of the datasets and 1 in the other half.  #@NEW_LINE#@#  We describe this behavior as polarized.  #@NEW_LINE#@#  This occurs when the two models are equally wrong and distinct.  #@NEW_LINE#@#  Type-3 problems may be the most relevant to practical data analysis given that all models are simplified representations of reality and are thus wrong.  #@NEW_LINE#@#  A variation to type-3 problems is when one model is only slightly less wrong than another (Fig 3 A, ii and C, ii and Table S2).  #@NEW_LINE#@#  While the less wrong model eventually wins in the limit of infinite data, Bayesian model selection is overconfident in large but finite datasets, supporting the more wrong model with high posterior too often.  #@NEW_LINE#@#  
Note that the question of how the posterior model probability should behave when large datasets are used to compare two equally wrong models is somewhat philosophical and may not have a simple answer.  #@NEW_LINE#@#  One position is to accept whatever behavior the Bayesian method exhibits.  #@NEW_LINE#@#  This may be legitimate given that Bayesian theory is the correct probability framework for summarizing evidence in the prior and likelihood.  #@NEW_LINE#@#  The polarized behavior in type-3 problems may then be seen as a consequence of user error (for not including the true model in the comparison), exacerbated by the large data size.  #@NEW_LINE#@#  In this regard we note that the posterior predictive distribution (27, 28) can be used to assess the general adequacy of any model or the compatibility between the prior and the likelihood, and indeed this has been widely used to assess the goodness of fit of models in phylogenetics (29, 30).  #@NEW_LINE#@#  Nevertheless, a number of sophisticated and parameter-rich models have been developed for Bayesian phylogenetic analysis, due to three decades of active research (31), and furthermore extreme sensitivity to the assumed model is not a desirable property of an inference method.  #@NEW_LINE#@#  Seven decades ago, Egon S. Pearson (ref.  #@NEW_LINE#@#  32, p.142) wrote that Hitherto the user has been accustomed to accept the function of probability theory laid down by the mathematicians; but it would be good if he could take a larger share in formulating himself what are the practical requirements that the theory should satisfy in application.  #@NEW_LINE#@#  This stipulation may be relevant even today.  #@NEW_LINE#@#  
Two heuristic approaches have been suggested to remedy the high posterior model probabilities in the context of phylogenies.  #@NEW_LINE#@#  The first one is to assign nonzero probabilities to multifurcating trees (such as the star tree of Fig 1) in the prior (11).  #@NEW_LINE#@#  This is equivalent to assigning some prior probability to the model p=0.5 in the fair-coin example of problem 1.  #@NEW_LINE#@#  While this resolves the star-tree paradox, it suffers from the conceptual difficulty that the multifurcating trees may not be plausible biologically.  #@NEW_LINE#@#  The second approach is to let the internal branch lengths in the binary trees become increasingly smaller in the prior when the data size increases (12, 14).  #@NEW_LINE#@#  This is non-Bayesian in that the prior depends on the size of the data.  #@NEW_LINE#@#  With both approaches, the posterior is extremely sensitive to the prior (9).  #@NEW_LINE#@#  

Non-Bayesian_Methods  #@NEW_LINE#@#  
The phylogeny problem was described by Jerzy Neyman (ref.  #@NEW_LINE#@#  33, p. 1) as a source of novel statistical problems.  #@NEW_LINE#@#  In the frequentist framework, the test of phylogeny, or test of nonnested models in general, offers challenging inference problems.  #@NEW_LINE#@#  Note that in many model selection problems, the model itself is not the focus of interest.  #@NEW_LINE#@#  For example, when an experiment is conducted to evaluate the effect of a new fertilizer, the sensitivity of the inference to the assumed normal distribution with homogeneous variance may be of concern, but the focus is not on the normal distribution itself.  #@NEW_LINE#@#  In phylogenetics, the phylogeny (which is a model) is of primary interest, far more important than the branch lengths (which are parameters in the model).  #@NEW_LINE#@#  The test of phylogeny is thus more akin to significance/hypothesis testing than to model selection.  #@NEW_LINE#@#  Model-selection criteria such as Akaike information criteria (34) or Bayesian information criteria (35) simply rank the trees by their likelihood (maximized over branch lengths) and will not be useful for attaching a measure of significance or confidence in the estimated tree.  #@NEW_LINE#@#  The phylogeny problem (or the problem of comparing nonnested models in general) falls outside the FisherNeymanPearson framework of hypothesis testing, which involves two nested models, one of which is true (36, 37).  #@NEW_LINE#@#  
In principle Coxs likelihood-ratio test (38), which conducts multiple tests with each model used as the null, can be used to compare nonnested models.  #@NEW_LINE#@#  For type-3 problems (Fig 2, C1C4), this test should lead to rejection of all models.  #@NEW_LINE#@#  Coxs test has not been used widely in phylogenetics, apparently because of the existence of a great many possible trees and the heavy computation needed to generate the null distribution by simulation.  #@NEW_LINE#@#  
The most commonly used method for attaching a measure of confidence in the maximum-likelihood tree is the bootstrap (39), which samples sites (alignment columns) to generate bootstrap pseudodatasets and calculates the bootstrap support value for a clade (a node on the species tree) as the proportion of the pseudodatasets in which that node is found in the inferred ML tree.  #@NEW_LINE#@#  This application of bootstrap for model comparison appears to have important differences from the conventional bootstrap for calculating the standard errors and confidence intervals for a parameter estimate (40); a straightforward interpretation of the bootstrap support values for trees remains elusive (31, 4143).  #@NEW_LINE#@#  At any rate, the asymptotic behavior of bootstrap support values under the different scenarios of Fig 2 merits further research.  #@NEW_LINE#@#  For the fair-coin example of problem 1 (Fig 2, C1), the bootstrap support converges to U(0,1), different from the posterior probability, although other cases are yet to be explored.  #@NEW_LINE#@#  


Materials_and_Methods  #@NEW_LINE#@#  
Star-Tree_Simulations  #@NEW_LINE#@#  
For Fig 4 A, A´, B, and B´, the true tree is T0 of Fig 1A.  #@NEW_LINE#@#  The data of counts of five site patterns (xxx, xxy, yxx, xyx, and xyz) were simulated by multinomial sampling (21) and analyzed using a C program, which calculates the 2D integrals in the marginal likelihood by Gaussian-Legendre quadrature with 128 points (14).  #@NEW_LINE#@#  For Fig 4 C and C´, the true tree is T0 of Fig 1B.  #@NEW_LINE#@#  Sequence alignments were simulated using EVOLVER and analyzed using MrBayes (4).  #@NEW_LINE#@#  


Acknowledgments  #@NEW_LINE#@#  
We thank Philip Dawid and Wally Gilks for stimulating discussions and Jeff Thorne and an anonymous reviewer for constructive comments.  #@NEW_LINE#@#  Z.Y.  #@NEW_LINE#@#  was supported by a Biotechnological and Biological Sciences Research Council grant (BB/P006493/1) and in part by the Radcliffe Institute for Advanced Study at Harvard University.  #@NEW_LINE#@#  T.Z.  #@NEW_LINE#@#  was supported by Natural Science Foundation of China grants (31671370, 31301093, 11201224, and 11301294) and a grant from the Youth Innovation Promotion Association of the Chinese Academy of Sciences (2015080).  #@NEW_LINE#@#  

Footnotes  #@NEW_LINE#@#  

Published under the PNAS license.  #@NEW_LINE#@#  

