article id="http://dx.doi.org/10.1073/pnas.1717075115"  #@NEW_LINE#@#  
title  #@NEW_LINE#@#  
Gradual progression from sensory to task-related processing in cerebral cortex  #@NEW_LINE#@#  

Significance  #@NEW_LINE#@#  
The earliest stages of processing in cerebral cortex reflect a relatively faithful copy of sensory inputs, but intelligent behavior requires abstracting behaviorally relevant concepts and categories.  #@NEW_LINE#@#  We examined how this transformation progresses through multiple levels of the cortical hierarchy by comparing neural representations in six cortical areas in monkeys categorizing across three visual domains.  #@NEW_LINE#@#  We found that categorical abstraction occurred in a gradual fashion across the cortical hierarchy and reached an apex in prefrontal cortex.  #@NEW_LINE#@#  Categorical coding did not respect classical models of large-scale cortical organization.  #@NEW_LINE#@#  The dimensionality of neural population activity was reduced in parallel with these representational changes.  #@NEW_LINE#@#  Our results shed light on how raw sensory inputs are transformed into behaviorally relevant abstractions.  #@NEW_LINE#@#  

Abstract  #@NEW_LINE#@#  
Somewhere along the cortical hierarchy, behaviorally relevant information is distilled from raw sensory inputs.  #@NEW_LINE#@#  We examined how this transformation progresses along multiple levels of the hierarchy by comparing neural representations in visual, temporal, parietal, and frontal cortices in monkeys categorizing across three visual domains (shape, motion direction, and color).  #@NEW_LINE#@#  Representations in visual areas middle temporal (MT) and V4 were tightly linked to external sensory inputs.  #@NEW_LINE#@#  In contrast, lateral prefrontal cortex (PFC) largely represented the abstracted behavioral relevance of stimuli (task rule, motion category, and color category).  #@NEW_LINE#@#  Intermediate-level areas, including posterior inferotemporal (PIT), lateral intraparietal (LIP), and frontal eye fields (FEF), exhibited mixed representations.  #@NEW_LINE#@#  While the distribution of sensory information across areas aligned well with classical functional divisions (MT carried stronger motion information, and V4 and PIT carried stronger color and shape information), categorical abstraction did not, suggesting these areas may participate in different networks for stimulus-driven and cognitive functions.  #@NEW_LINE#@#  Paralleling these representational differences, the dimensionality of neural population activity decreased progressively from sensory to intermediate to frontal cortex.  #@NEW_LINE#@#  This shows how raw sensory representations are transformed into behaviorally relevant abstractions and suggests that the dimensionality of neural activity in higher cortical regions may be specific to their current task.  #@NEW_LINE#@#  

Experimental design.  #@NEW_LINE#@#  (A) Trial sequence for the multidimensional visual categorization task.  #@NEW_LINE#@#  On each trial, the monkeys categorized either the motion direction or color of a random-dot stimulus.  #@NEW_LINE#@#  This stimulus was immediately preceded by a symbolic visual shape cue that instructed which feature (motion or color) to categorize for that trial.  #@NEW_LINE#@#  The monkey responded with a leftward or rightward saccade during the 3-s stimulus.  #@NEW_LINE#@#  (B) Either of two different cue shapes was used to instruct each task rule so as to dissociate cue- and task-rulerelated activity.  #@NEW_LINE#@#  (C) Stimuli systematically sampled motion direction (upward to downward) and color (green to red).  #@NEW_LINE#@#  Each color category comprised two distinct colors, and each motion category comprised two distinct motion directions (additional ambiguous stimuli on the category boundaries were not analyzed here due to our focus on categoricality).  #@NEW_LINE#@#  Dashed lines indicate category boundaries.  #@NEW_LINE#@#  For each task rule, the two categories had a fixed mapping to a leftward (L) or rightward (R) saccadic response.  #@NEW_LINE#@#  (D) Illustration of sampled brain regions: lateral PFC, FEF, LIP, PIT, V4, and MT.  #@NEW_LINE#@#  
Results  #@NEW_LINE#@#  
Our main interest was to track the transformation of visual inputs from more sensory (bottom-up) representations to task-related (top-down) representations.  #@NEW_LINE#@#  On each trial of our multidimensional categorization task (Fig 1A), a visual shape cue instructed the monkey whether to categorize a subsequently presented colored, moving random-dot stimulus based on its color (greenish vs. reddish) or direction of motion (upward vs. downward), and report the cued category with a leftward or rightward saccade.  #@NEW_LINE#@#  Therefore, it probed three different types of sensory inputs: shape, motion, and color.  #@NEW_LINE#@#  Two of the shapes (arbitrarily chosen) cued motion categorization, while the other two cued color categorization (Fig 1 B and C).  #@NEW_LINE#@#  Thus, four different shapes were arbitrarily grouped into pairs by virtue of them cueing the same task rule, and four continuously varying colors and directions of motion were arbitrarily divided by a sharp boundary (Fig 1C) [additional colors/motions on category boundaries (11) were excluded from the present analyses, which require an unambiguous category assignment].  #@NEW_LINE#@#  
We exploited the mapping in each domain from two stimulus items (cue shapes, directions, or colors) to each categorical grouping (task rule, motion category, or color category) to dissociate stimulus-related (sensory) and task-related (categorical) effects.  #@NEW_LINE#@#  Purely categorical neural activity would differentiate between categories (i.e., have preferred responses for both items in the same category) but show no differences between items within each category.  #@NEW_LINE#@#  Purely sensory activity would, instead, differentiate between stimulus items without regard to the learned categorical divisions.  #@NEW_LINE#@#  
We quantified this by fitting each neurons spike rate, at each time point, with a linear model that partitioned across-trial rate variance into between-category and within-category effects (details are provided in SI Appendix, SI Methods).  #@NEW_LINE#@#  The model included three orthogonal contrast terms for each task domain (Fig 2A).  #@NEW_LINE#@#  One contrast (blue) reflected the actual task-relevant grouping of stimulus items (cue shapes, directions, or colors) into categories, and thus captured between-category variance.  #@NEW_LINE#@#  The other contrasts (gray) reflected the two other possible nontask-relevant paired groupings of items and captured all within-category variance.  #@NEW_LINE#@#  Together, these three terms capture all data variance in the given task domain.  #@NEW_LINE#@#  We wished to measure how much of that variance, for each domain and studied brain region, was attributable to categorical coding: its categoricality.  #@NEW_LINE#@#  Note that simply measuring the between-category variance would result in a biased estimate of categoricality; it is nonzero even for neural populations with sensory tuning for single stimulus items or for arbitrary subsets of items (SI Appendix, Fig S1 E and F).  #@NEW_LINE#@#  
Instead, we estimated where the between-category variance of each neural population fell between the predictions of purely sensory and purely categorical coding.  #@NEW_LINE#@#  Note that the sum of variances for all three model terms bounds the between-category variance; they can be equal only for a perfectly categorical population with zero within-category variance (Fig 2B, Top).  #@NEW_LINE#@#  A purely sensory-driven population would, instead, have equal variance for all three contrasts; thus, between-category variance would equal the average of all three terms (Fig 2B, Bottom).  #@NEW_LINE#@#  To measure where neural populations fall between these extremes, we computed a categoricality index equal to the area between the between-category and sensory (lower-bound) time series, expressed as a fraction of the full area between the total (upper-bound) and sensory (lower-bound) time series (Fig 2C).  #@NEW_LINE#@#  It can be shown this is also equivalent to the between-category variance minus the average of within-category variance terms [the statistic used in our prior publication (11)], normalized by the total domain variance (details are provided in SI Appendix, SI Methods).  #@NEW_LINE#@#  This index is a specific measure of how categorical a neural population is, and ranges from 1 for a perfectly categorical population to 0 for a purely sensory population.  #@NEW_LINE#@#  [Negative values are possible if within-category variance is greater than between-category variance (i.e., for populations that specifically reflect within-category differences).]  #@NEW_LINE#@#  
Within the context of each task rule, motion and color categories were, by design, inextricably linked with the monkeys behavioral choice (e.g., under the color rule, greenish and reddish colors always mandated leftward and rightward saccades, respectively).  #@NEW_LINE#@#  Although this identity relationship is broken when both task rules are considered together, there remains a partial correlation between these task variables.  #@NEW_LINE#@#  To partition out choice effects from the category effects of interest, we also included in the fitted models a term reflecting behavioral choice.  #@NEW_LINE#@#  Category effects are thus measured in terms of their additional variance explained once choice effects are already accounted for (12).  #@NEW_LINE#@#  
To validate our analysis, we first assayed its properties on synthesized neural activity with known ground truth (details are provided in SI Appendix, SI Methods and SI Results).  #@NEW_LINE#@#  We show that our categoricality index reliably reports the relative weights of simulated sensory and categorical signals (SI Appendix, Fig S1A), that it is relatively insensitive to coupled changes in both sensory and categorical signals in concert (SI Appendix, Fig S1 B and C), and that it is relatively insensitive to simulated choice effects (SI Appendix, Fig S1D).  #@NEW_LINE#@#  
Shape_Information  #@NEW_LINE#@#  
We first examined representations of the four cue shapes instructing the task rule in effect on each trial.  #@NEW_LINE#@#  All sampled cortical areas (MT, V4, PIT, LIP, FEF, and PFC) conveyed significant information about the rule cues, as measured by the total spike rate variance explained by cues (Fig 3 A and B; P less_than 0.01, one-sample bootstrap test).  #@NEW_LINE#@#  The strongest cue shape information was in areas PIT and V4 (Fig 3C; P less_than 0.01 for all comparisons with other areas, two-sample bootstrap test), consistent with their well-established role in shape processing (13).  #@NEW_LINE#@#  
To measure task-related (top-down) information about the task rule instructed by the cues, we partitioned out spike rate variance due to effects between task rules (between-category variance) and between cues instructing the same rule (within-category variance).  #@NEW_LINE#@#  Areas MT, V4, and PIT all exhibited between-category variances (Fig 3D, colored curves) that hewed closely to values expected from a pure bottom-up sensory representation of shape (Fig 3D, lower gray curves).  #@NEW_LINE#@#  We summarized these results with a categoricality index that measures how categorical the information conveyed by each neural population is, ranging continuously from purely sensory (0) to purely categorical (1).  #@NEW_LINE#@#  Task-rule categoricality indices for each of these visual areas (Fig 3E) did not differ significantly from zero (P  0.01).  #@NEW_LINE#@#  This was true for both V4 and PIT, areas where we found strong overall cue information, as well as for MT, where there was weaker cue information.  #@NEW_LINE#@#  Thus, visual areas MT, V4, and PIT contained a primarily bottom-up sensory representation of the shape cues.  #@NEW_LINE#@#  Note that this result differs from the strong V4 and PIT task-rule signals in our prior publication on this dataset (11).  #@NEW_LINE#@#  This is primarily due to differences in the specific questions addressed by each study, and can be reconciled by the fact that V4 and PIT do contain some task-rule signals, but these signals constitute a very small fraction of the total cue variance in these areas (details are provided in SI Appendix, SI Results).  #@NEW_LINE#@#  
By contrast, PFC, FEF, and LIP all conveyed task-rule information (Fig 3D, colored curves) well above that predicted from bottom-up sensory signals (Fig 3D, lower gray curves), and had task-rule categoricality indices significantly greater than zero (Fig 3E; P  1 × 105 for all three areas).  #@NEW_LINE#@#  PFC exhibited the most categorical task cue representation, significantly greater than all other areas (Fig 3F; P less_than 0.01) except FEF (P = 0.05).  #@NEW_LINE#@#  FEF and LIP had intermediate values between PFC and the group of sensory areas (MT, V4, and PIT).  #@NEW_LINE#@#  All areas, including PFC, still conveyed less task-rule information than expected from a purely categorical representation (Fig 3D, upper gray curves) and had categoricality indices significantly less than 1 (P  1 × 105).  #@NEW_LINE#@#  This suggests that, unlike the visual areas, areas LIP, FEF, and particularly PFC represented the top-down meaning of the rule cues, although also retaining some sensory information about them as well.  #@NEW_LINE#@#  Unlike the case with sensory information, where results were predictable from traditional areal divisions (shape-coding ventral stream areas PIT and V4 showed the strongest information), top-down task-rule coding was observed in traditionally nonshape-coding dorsal stream areas LIP and FEF, but not in V4 or PIT.  #@NEW_LINE#@#  
It seems likely that some trace of the current task rule would have to persist into the stimulus period to influence how the random-dot stimulus was assigned to categories.  #@NEW_LINE#@#  This can be seen in the rightmost portion of Fig 3D, and we focus in on it in SI Appendix, Fig S2.  #@NEW_LINE#@#  The results indicate that cue signals in V4 and PIT decrease sharply after cue offset (SI Appendix, Fig S2A) and remain sensory in nature (SI Appendix, Fig S2 D and E).  #@NEW_LINE#@#  In contrast, cue signals in PFC, FEF, and LIP persist relatively unabated through the stimulus period (SI Appendix, Fig S2D) and are generally even more categorical than during the cue period (SI Appendix, Fig S2 E and F).  #@NEW_LINE#@#  These results indicate that task-rule signals in frontoparietal regions (PFC, FEF, and LIP) may be involved in guiding categorical decisions about the random-dot stimuli.  #@NEW_LINE#@#  

Motion_Direction_Information  #@NEW_LINE#@#  
Next, we turned to the random-dot stimuli that the animals had to categorize according to their direction of motion or their color.  #@NEW_LINE#@#  Both motion direction and color varied along a continuum, but the animals had to group them into upward/downward or greenish/reddish.  #@NEW_LINE#@#  Much as with the rule cues (as discussed above), we would expect bottom-up sensory signals to reflect the actual direction or color, whereas task-related signals should divide them into their relevant categories.  #@NEW_LINE#@#  To discriminate signals related to stimulus category and behavioral choice, we combined data across both task rules (as discussed above; details are provided in SI Appendix, SI Methods).  #@NEW_LINE#@#  
First, we began with motion.  #@NEW_LINE#@#  Analogous to the rule cues, there were four distinct motion directions, grouped into two categories: upward (90° and 30°) and downward (30° and 90°) categories, with rightward motion (0°) serving as the category boundary (Fig 1C).  #@NEW_LINE#@#  All areas conveyed significant information about motion direction, as measured by the total spike rate variance explained by motion (Fig 4 A and B; P less_than 0.01).  #@NEW_LINE#@#  The strongest motion information was found in area MT (Fig 4 A and B), which was significantly greater than in all other areas (Fig 4C; P less_than 0.01) except PIT (P = 0.05), consistent with its classical role in motion processing (14).  #@NEW_LINE#@#  
When we partitioned total motion variance into between- and within-category effects, between-category variance in MT (Fig 4D, orange curve) closely approximated its sensory prediction (Fig 4D, lower gray curve), and its motion categoricality index was not significantly different from zero (Fig 4E; P = 0.44).  #@NEW_LINE#@#  The same was true of more weakly direction-selective areas V4 (P  1), PIT (P  1), and FEF (P = 0.03).  #@NEW_LINE#@#  Thus, the motion information carried by MT, V4, PIT, and FEF was largely sensory in nature.  #@NEW_LINE#@#  
In contrast, PFC and LIP both exhibited between-category variances (Fig 4D, colored curves) considerably greater than their sensory predictions (Fig 4D, lower gray curves) and motion categoricality indices significantly greater than zero (Fig 4E; PFC: P = 0.004, LIP: P  1 × 105).  #@NEW_LINE#@#  As with the task instruction cues, PFC showed the most categorical motion signals (Fig 4F; significantly greater than MT, V4, and PIT: all P less_than 0.01; nonsignificant for FEF: P = 0.06 and LIP: P = 0.38).  #@NEW_LINE#@#  All areas, including PFC, remained significantly below the predictions of a purely categorical representation (Fig 3D, upper gray curves; P  1 × 105).  #@NEW_LINE#@#  Thus, areas PFC and LIP conveyed top-down motion categories but retained some sensory direction information as well.  #@NEW_LINE#@#  Once again, while the sensory results were consistent with traditional areal divisions (MT predictably had the strongest direction information), significant motion category information was observed in one higher level dorsal stream area (LIP), but not in another one (FEF).  #@NEW_LINE#@#  

Color_Information  #@NEW_LINE#@#  
Next, we examined neural information about the colors of the random-dot stimuli.  #@NEW_LINE#@#  As with motion, there were four distinct color hues grouped into two categories, greenish (90° and 30° hue angles) and reddish (30° and 90°), with the category boundary at yellow (0°; Fig 1C).  #@NEW_LINE#@#  Once again, significant color information (total color variance) could be found in all studied areas (Fig 5 A and B; P less_than 0.01).  #@NEW_LINE#@#  Area V4 showed the strongest color information (Fig 5 A and B), which was significantly greater than in all other studied areas (Fig 5C; P less_than 0.01), consistent with its established role in color processing (15).  #@NEW_LINE#@#  Although PIT showed the second strongest stimulus color information, it was not significantly greater than in other areas (Fig 5C; P  0.01), possibly due to insufficient sampling of the relatively sparsely distributed color patches in and around this area (16).  #@NEW_LINE#@#  
Cortical representations of color were overall much more categorical than those for motion direction and rule cues, possibly due to alignment of the category structure with the red-green opponent signals arising in retinal ganglion cells and prevalent at many levels of the visual system (15).  #@NEW_LINE#@#  All areas except MT showed significant color categoricality indices (Fig 5 D and E; P less_than 0.01 for all areas).  #@NEW_LINE#@#  PIT, FEF, and PFC all had nearly purely categorical color representations.  #@NEW_LINE#@#  For each of them, categorical information nearly equaled its upper bound (Fig 5D).  #@NEW_LINE#@#  Their categoricality indices were significantly greater than those of LIP and V4 (Fig 5F; P less_than 0.01), and those of PIT and FEF were not significantly different from a purely categorical representation (PIT: P = 0.1; FEF: P = 0.04).  #@NEW_LINE#@#  By comparison, strongly color-selective area V4, as well as weakly color-selective areas MT and LIP, was much less categorical.  #@NEW_LINE#@#  Thus, areas MT, V4, and LIP have a relatively bottom-up representation of color, while areas PIT, FEF, and PFC have largely categorized them into binary greenish and reddish categories.  #@NEW_LINE#@#  Note that while bottom-up biases toward red-green opponent coding might have boosted the overall apparent color categoricality, it is not obvious why such signals would be inherently stronger in higher level areas than in V4.  #@NEW_LINE#@#  We also found that, once again, overall color information was fairly consistent with traditional areal divisions (V4 predictably had the strongest color information), while color categoricality exhibited a mixed correlation with them: As expected, PIT was strongly categorical for color, but so was traditional dorsal stream area FEF.  #@NEW_LINE#@#  

Changes_in_Dimensionality_Across_Cortex  #@NEW_LINE#@#  
As a complementary assay of cortical coding properties, we examined the dimensionality of neural population activity using a noise-thresholded principal components analysis method (17) (details are provided in SI Appendix, SI Methods).  #@NEW_LINE#@#  This analysis was previously used to measure PFC dimensionality in an object sequence memory task (18).  #@NEW_LINE#@#  In that context, it was found that PFC neurons contained a high-dimensional representation of task components due to their conjunctive coding of multiple task variables (18).  #@NEW_LINE#@#  We asked whether high dimensionality is an invariant property of PFC population activity or whether it might be specific to task context.  #@NEW_LINE#@#  We concatenated all neurons from each studied area into a pseudo-population and extrapolated to larger population sizes via a condition relabeling procedure.  #@NEW_LINE#@#  For each area and population size, we computed the mean spike rate for each of 64 task conditions (four rule cues × four motion directions × four colors) within the random-dot stimulus epoch when all conditions were differentiated.  #@NEW_LINE#@#  The dimensionality of the space spanned by each resulting set of 64 neural population activity vectors was quantified as the number of principal components (eigenvalues) significantly greater than those estimated to be due solely to noise.  #@NEW_LINE#@#  
As expected, estimated dimensionality grew with the size of the neural population examined but generally approximated an asymptotic value (Fig 6A) that can be taken as an estimate of the dimensionality of the underlying (much larger) neural population.  #@NEW_LINE#@#  Clear differences in the estimated dimensionality were observed across areas, as summarized in Fig 6B.  #@NEW_LINE#@#  The highest dimensionality was observed in visual areas V4, PIT, and MT, presumably reflecting a large diversity of sensory tuning curves in these visual areas.  #@NEW_LINE#@#  These areas were followed by intermediate-level visual areas LIP and FEF.  #@NEW_LINE#@#  The lowest dimensionality was observed in PFC.  #@NEW_LINE#@#  The observed high dimensionality of area PIT was likely due, in part, to the inclusion of two task variables that it carried relatively strong information about: rule cues (shape) and color.  #@NEW_LINE#@#  When the same analysis was performed in 16D space consisting only of four directions × four colors (Fig 6 C and D), PIT dimensionality was greatly reduced and was similar to that of LIP.  #@NEW_LINE#@#  
Thus, the dimensionality of population activity decreased progressively up the cortical hierarchy in parallel with the gradual shift from sensory to categorical representations.  #@NEW_LINE#@#  Further, the estimated PFC dimensionality is close to the value that would be expected of a purely categorical representation with binary responses for each task variable (3 for the three-variable analysis, Fig 6B; 2 for the two-variable analysis, Fig 6D).  #@NEW_LINE#@#  These results suggest that high dimensionality is not an invariant property of PFC activity but may be specific to current behavioral demands, to reduce high-dimensional sensory stimuli to binary categories in this case.  #@NEW_LINE#@#  


Discussion  #@NEW_LINE#@#  
Abstraction_of_Sensory_Inputs_Occurs_Progressively_Through_the_Cortical_Hierarchy  #@NEW_LINE#@#  
Our results, summarized in Fig 7, demonstrate a gradual progression from bottom-up sensory inputs to abstracted, top-down behaviorally relevant signals as the cortical hierarchy is ascended.  #@NEW_LINE#@#  Across three visual domains (shape, motion direction, and color), lower level visual areas MT and V4 conveyed strong information about sensory stimuli within their preferred domains (Fig 7A) but showed little evidence for any abstraction beyond the raw sensory inputs (Fig 7B).  #@NEW_LINE#@#  In contrast, higher level area PFC, despite containing relatively weak information overall (Fig 7A), showed strongly abstracted, task-relevant coding across all domains (Fig 7B).  #@NEW_LINE#@#  In between, intermediate-level visual areas PIT, LIP, and FEF showed mixed representations with partially categorical coding in some domains but not others.  #@NEW_LINE#@#  These results support models of cortical processing where representational transformations happen gradually across multiple cortical processing steps (19, 20), rather than in a discrete, all-or-nothing fashion.  #@NEW_LINE#@#  
In all but a few cases (PIT and FEF for color), cortical representations, even in high-level areas, remained significantly less categorical than predicted for a purely categorical neural population.  #@NEW_LINE#@#  The distribution of categoricality index values across neurons in the studied populations (SI Appendix, Fig S3) suggests two reasons for this.  #@NEW_LINE#@#  First, even mostly categorical populations contained some residual sensory-coding neurons (index values  0).  #@NEW_LINE#@#  Second, all studied populations contained some individual neurons whose activity differentiates both between categories and between items within each category (0  index  1).  #@NEW_LINE#@#  Thus, the intermediate categorical coding we observed in most areas reflected a mixture of sensory and categorical effects at the level of both single neurons and the neural population.  #@NEW_LINE#@#  Purely categorical signals might exist in other brain regions, such as the medial temporal lobe (10).  #@NEW_LINE#@#  However, some multiplexing of categorical and residual sensory signals could also have a functional role, such as permitting behavior to be driven flexibly by multiple levels of abstraction.  #@NEW_LINE#@#  
Note that the exact values of categoricality indices may be influenced by the particular stimuli used, and are thus, to some degree, specific to this task.  #@NEW_LINE#@#  For example, the apparent strong categoricality of color representations may have been due to alignment of the category structure with the red-green opponent signals arising in retinal ganglion cells (15).  #@NEW_LINE#@#  However, it is not obvious why any such bottom-up stimulus biases would be inherently stronger in higher level areas, without being driven by a learned category structure.  #@NEW_LINE#@#  Thus, while we do not put strong interpretational value on the exact index values for each area and task variable, we believe their relative values accurately portray a progression from sensory-dominated to categorical coding through the cortical hierarchy.  #@NEW_LINE#@#  

Comparison_with_Our_Previous_Results  #@NEW_LINE#@#  
One result may appear to be somewhat at odds with our prior publication on this dataset (11).  #@NEW_LINE#@#  We previously claimed that V4 and PIT had strong task-rule information (figure 2C in ref.  #@NEW_LINE#@#  11).  #@NEW_LINE#@#  Here, we claim task-rule categoricality is weak and nonsignificant in these areas (Fig 3 D and E).  #@NEW_LINE#@#  This difference lies primarily in the specific questions addressed by each study.  #@NEW_LINE#@#  Our previous study addressed the overall task-rule information conveyed by each neural population.  #@NEW_LINE#@#  It therefore used a statistic that measured a debiased version of between-category variance for task cues.  #@NEW_LINE#@#  This measure could be high for populations conveying strong information about a domain, such as the representations of rule cue shapes in V4 and PIT, even if only a very small fraction of that information is categorical (simulations in SI Appendix, Fig S1H).  #@NEW_LINE#@#  Here, we instead addressed how categorical neural representations are.  #@NEW_LINE#@#  We used a statistic that normalizes out overall information to measure categoricality per se (SI Appendix, Fig S1 B and C).  #@NEW_LINE#@#  Thus, we can reconcile results from the two studies by concluding that V4 and PIT contain strong information about task cues but only a small fraction of that information is categorical.  #@NEW_LINE#@#  In contrast, despite the weaker overall task cue information in PFC and FEF, a substantial fraction of that information reflects the learned task-rule categories.  #@NEW_LINE#@#  This definition accords well with both intuitive notions of categoricality and those previously proposed (3, 10).  #@NEW_LINE#@#  As elaborated below, it is further supported by its tight correspondence to the anatomically defined cortical hierarchy.  #@NEW_LINE#@#  

Graded_Cortical_Functional_Specialization  #@NEW_LINE#@#  
There is a long-standing debate about the degree to which the functions of different cortical regions are specialized or overlapping.  #@NEW_LINE#@#  The cortexs broad interconnections and remarkable resistance to localized damage argue for more distributed, overlapping representations (21), while many studies find evidence for seemingly circumscribed functions in at least some cortical regions (22, 23).  #@NEW_LINE#@#  We find evidence supporting both points of view.  #@NEW_LINE#@#  Information about task variables was not distributed homogeneously across cortical regions.  #@NEW_LINE#@#  For each variable, one or two areas clearly conveyed much stronger information (Fig 7A) than others.  #@NEW_LINE#@#  These results were largely predictable from the classical functions of visual cortical areas.  #@NEW_LINE#@#  Area MT was dominant for motion direction, consistent with its well-established role in motion processing (14).  #@NEW_LINE#@#  V4 was dominant for color, consistent with many reports of its robust color selectivity (15).  #@NEW_LINE#@#  PIT and V4 both showed strong sensory information about rule cue shapes consistent with their well-established role in shape processing (13).  #@NEW_LINE#@#  Thus, these results support the idea of specialized cortical representations and reconfirm some of the classical functional divisions between ventral stream and dorsal stream areas using an experimental paradigm where multiple areas from both streams were tested simultaneously across multiple stimulus domains.  #@NEW_LINE#@#  
On the other hand, significant information about all examined experimental variables was found in all sampled areas, supporting the idea of broadly distributed cortical representations.  #@NEW_LINE#@#  The fact that color and shape information can be found in dorsal stream areas MT, LIP, and FEF and motion information can be found in ventral stream areas V4 and PIT argues against any absolute functional dichotomies between cortical processing streams, consistent with previous reports (2426).  #@NEW_LINE#@#  We believe this body of results supports cortical models with graded functional specialization, where cortical areas have clear innate or learned biases to represent certain attributes but retain coarse, distributed information about nonspecialized attributes (27, 28).  #@NEW_LINE#@#  
While the overall strength of task-related information accorded well with classical divisions, the degree of top-down categorical abstraction painted a somewhat different picture.  #@NEW_LINE#@#  Dorsal stream area FEF exhibited a strongly categorical representation of color and task rule (derived from cue shape) but a noncategorical, sensory representation of motion direction.  #@NEW_LINE#@#  LIP was predictably categorical for motion but also showed a moderately categorical representation for task rule (shape) and color.  #@NEW_LINE#@#  While areas V4 and PIT were somewhat more predictable (they were relatively categorical for color but not at all for motion direction), they unexpectedly exhibited little to no categorical coding for the cue shape-derived task rule.  #@NEW_LINE#@#  
We quantified these observations by explaining the summary data in Fig 7 with two predictors related to large-scale cortical organization: (i) the anatomically derived hierarchical level of each area (29) and (ii) the expected functional congruence of each combination of task variable and area, positive for those consistent with classical dorsal/ventral processing stream divisions (e.g., MT and motion, V4 and color) and negative for inconsistent combinations (e.g., MT and color, V4 and motion) (details are provided in SI Appendix, SI Methods).  #@NEW_LINE#@#  We found that both the decrease in sensory information and the increase in categorical coding across cortical areas were well explained by their anatomical hierarchical level (P  1 × 105 for both), with only a marginally significant difference between them (P = 0.04).  #@NEW_LINE#@#  In contrast, only sensory information was also significantly explained by classical processing stream divisions (P  1 × 105), while categoricality index values were not (P = 0.11), with a significant difference between them (P = 0.003).  #@NEW_LINE#@#  Thus, while our sensory information results confirm classical areal divisions, the degree of categorical coding is not well explained by them.  #@NEW_LINE#@#  These results suggest cortical regions may form different functional networks for bottom-up vs. top-down functions, putatively reflecting primarily feedforward and feedback/recurrent circuits, respectively.  #@NEW_LINE#@#  

Categorization_Reached_Its_Apex_in_PFC  #@NEW_LINE#@#  
Many studies have now reported neural correlates of categories in PFC (3, 57), as well as in area LIP and related areas of posterior parietal cortex (6, 7, 9).  #@NEW_LINE#@#  A recent study suggested that LIP might contain a stronger representation of categories that could drive categorical processing in PFC (6).  #@NEW_LINE#@#  For all examined domains, we found that PFC exhibited a degree of categorical abstraction either greater than all other studied areas (task rule and motion) or not significantly different from the other most categorical area (color).  #@NEW_LINE#@#  For all domains, the prefrontal representation was more categorical than LIP, although this difference was significant only for task rule and color, and not for motion direction.  #@NEW_LINE#@#  On the other hand, despite being less categorical than PFC, LIP did also exhibit a significantly categorical representation for all tested domains, which was not the case for any other studied area besides PFC.  #@NEW_LINE#@#  We interpret these results to mean that PFC does play an important, and perhaps the most important, role in categorization (also ref.  #@NEW_LINE#@#  7).  #@NEW_LINE#@#  However, LIP clearly also plays a central role, and categorization likely involves reciprocal interactions between these areas as well as others (30, 31).  #@NEW_LINE#@#  

Cortical_Dimensionality_May_Be_Task-Specific  #@NEW_LINE#@#  
We found a progression from high-dimensional population activity in the visual areas (V4 and MT) to low-dimensional populations in the frontal areas (PFC and FEF), paralleling the change in categoricality.  #@NEW_LINE#@#  We interpret this to reflect a shift from a large diversity of sensory tuning curves in visual cortex to nearly binary categorical responses in PFC.  #@NEW_LINE#@#  
At first glance, however, these results might seem at odds with a recent report showing prefrontal population activity is high dimensional (18).  #@NEW_LINE#@#  That study found that PFC neurons tend to exhibit nonlinear mixed selectivity for specific conjunctions of task variables, and, consequently, PFC population activity had a dimensionality near the theoretical maximum (24 dimensions) for the studied task.  #@NEW_LINE#@#  However, that study employed a task involving encoding and maintenance in working memory of a sequence of visual objects and responding via either a recollection or recall probe (32).  #@NEW_LINE#@#  Thus, correct performance required remembering which of 12 different sequences was shown and which of two modes of behavioral output was mandated.  #@NEW_LINE#@#  By contrast, the task used here emphasized dimensionality reduction.  #@NEW_LINE#@#  First, four visual cues were grouped into either of two task instructions.  #@NEW_LINE#@#  Next, 16 random-dot stimuli (four colors × four directions) were mapped onto binary color or motion categories, depending on the currently instructed task rule.  #@NEW_LINE#@#  Finally, the deduced category was translated into a binary response.  #@NEW_LINE#@#  Thus, this task, unlike the previous one, emphasized reduction of high-dimensional sensory inputs to lower dimensional abstractions.  #@NEW_LINE#@#  Our results therefore suggest the possibility that prefrontal dimensionality may flexibly reflect current cognitive demands (33).  #@NEW_LINE#@#  Inputs may be expanded to higher dimensions when decisions depend on multiple variables but reduced to lower dimensionality when categorical abstraction is required.  #@NEW_LINE#@#  Thus, PFC dimensionality, like other PFC coding properties (34), appears to flexibly adapt to behavioral needs.  #@NEW_LINE#@#  


Methods  #@NEW_LINE#@#  
Experimental methods are briefly reviewed here, but further details can be found in SI Appendix, SI Methods, as well as in our prior publication from this dataset (11).  #@NEW_LINE#@#  All procedures followed the guidelines of the Massachusetts Institute of Technology Committee on Animal Care and the NIH.  #@NEW_LINE#@#  
Electrophysiological_Data_Collection  #@NEW_LINE#@#  
In each of 47 experimental sessions, neuronal activity was recorded simultaneously from up to 108 electrodes acutely inserted daily into up to six cortical regions (Fig 1D): MT, V4, PIT, LIP, FEF, and lateral PFC.  #@NEW_LINE#@#  All analyses were based on 2,414 well-isolated single neurons (MT: 60, V4: 121, PIT: 36, LIP: 516, FEF: 612, and PFC: 1,069).  #@NEW_LINE#@#  The basic analysis was also repeated using multiunit signals (pooling together all threshold-crossing spikes on each electrode), with very similar results (SI Appendix, Fig S4).  #@NEW_LINE#@#  To minimize any sampling bias of neural activity, we did not prescreen neurons for responsiveness or selectivity.  #@NEW_LINE#@#  Details are provided in SI Appendix, SI Methods.  #@NEW_LINE#@#  

Behavioral_Paradigm  #@NEW_LINE#@#  
Two adult rhesus macaques (Macaca mulatta) were trained to perform a multidimensional categorization task.  #@NEW_LINE#@#  On each trial (Fig 1A), a visual cue instructed the monkey to perform one of two tasks: color categorization (greenish vs. reddish) or motion categorization (upward vs. downward) of a subsequently presented colored, moving random-dot stimulus.  #@NEW_LINE#@#  The monkey responded via a saccade toward a target to the left (greenish/upward) or right (reddish/downward).  #@NEW_LINE#@#  Details are provided in SI Appendix, SI Methods.  #@NEW_LINE#@#  

General_Data_Analysis  #@NEW_LINE#@#  
For most analyses, spike trains were converted into smoothed rates (spike densities).  #@NEW_LINE#@#  To summarize results, we pooled rates or other derived statistics within empirically defined epochs of interest for each task variable and area (details are provided in SI Appendix, SI Methods).  #@NEW_LINE#@#  Only correctly performed trials were included in the analyses.  #@NEW_LINE#@#  All hypothesis tests used distribution-free bootstrap methods unless otherwise noted.  #@NEW_LINE#@#  

Categoricality_Analysis  #@NEW_LINE#@#  
Our primary interest was to characterize each cortical regions categoricality, the degree to which it reflected the raw sensory stimuli or their abstracted meaning (task rule or motion/color category).  #@NEW_LINE#@#  We quantified this by fitting each neurons spike rate, at each time point, with a linear model that partitioned across-trial rate variance within each task domain into between-category and within-category effects (Fig 2A).  #@NEW_LINE#@#  We then computed a categoricality index reflecting where the observed between-category variance for each population fell between the predictions of purely sensory and categorical coding (Fig 2B).  #@NEW_LINE#@#  Because overall variance within each task domain is effectively normalized out of this index, it reflects a pure measure of the categorical quality of a neural representation, similar to previous measures of category selectivity (3), but taking the reliability of neural coding into account, as it is based on explained variance rather than raw spike rates.  #@NEW_LINE#@#  Details are provided in SI Appendix, SI Methods.  #@NEW_LINE#@#  Our analysis methods were validated with extensive simulations (SI Appendix, Fig S1) and supported by a separate analysis comparing predictions of category and choice coding (SI Appendix, Fig S5).  #@NEW_LINE#@#  Details are provided in SI Appendix, SI Methods and SI Results.  #@NEW_LINE#@#  
We also measured categoricality by comparing mean spike rates for preferred categories and stimulus items within categories.  #@NEW_LINE#@#  The relative difference in spike rates between and within categories was generally consistent with our presented results (SI Appendix, Fig S6).  #@NEW_LINE#@#  Details are provided in SI Appendix, SI Methods and SI Results.  #@NEW_LINE#@#  

Population_Dimensionality_Analysis  #@NEW_LINE#@#  
To measure the dimensionality of population activity, we estimated the number of principal components required to describe the space spanned by condition-mean neural population activity vectors (17, 18).  #@NEW_LINE#@#  Epoch spike rates were computed for each trial and neuron, averaged across all trials of each condition, and concatenated across all neurons and sessions into a set of neural pseudo-population vectors for each studied area.  #@NEW_LINE#@#  Dimensionality was computed as the number of principal components (eigenvalues) of each resulting matrix significantly greater than the estimated distribution of principal components due to noise.  #@NEW_LINE#@#  Details are provided in SI Appendix, SI Methods.  #@NEW_LINE#@#  

Cortical_Organization_Analysis  #@NEW_LINE#@#  
To relate our results to classical models of cortical organization, we fit the data in each of the population summary matrices of Fig 7 with a two-predictor linear model: (i) the Felleman and Van Essen (29) hierarchical level of each area and (ii) the expected functional congruence of each combination of task variable and area based on classical functional divisions, positive for consistent combinations (e.g., MT and motion) and negative for inconsistent ones (e.g., MT and color).  #@NEW_LINE#@#  Details are provided in SI Appendix, SI Methods.  #@NEW_LINE#@#  


Acknowledgments  #@NEW_LINE#@#  
We thank Andre Bastos, Mikael Lundqvist, Morteza Moazami, Jefferson Roy, Jason Sherfey, and Andreas Wutz for helpful discussions, and Mattia Rigotti for providing code and advice on the dimensionality analysis.  #@NEW_LINE#@#  This work was supported by National Institute of Mental Health Grant 5R37MH087027 (to E.K.M.  #@NEW_LINE#@#  ), European Research Council Grant StG335880 (to M.S.  #@NEW_LINE#@#  ), Deutsche Forschungsgemeinschaft Grant DFG SI1332-3/1 (to M.S.  #@NEW_LINE#@#  ), and the Centre for Integrative Neuroscience (Deutsche Forschungsgemeinschaft Grant EXC 307 to M.S.  #@NEW_LINE#@#  ).  #@NEW_LINE#@#  

Footnotes  #@NEW_LINE#@#  

This open access article is distributed under Creative Commons Attribution-NonCommercial-NoDerivatives License 4.0 (CC BY-NC-ND).  #@NEW_LINE#@#  

