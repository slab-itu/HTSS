article id="http://dx.doi.org/10.1073/pnas.1617540114"  #@NEW_LINE#@#  
title  #@NEW_LINE#@#  
Assessing significance in a Markov chain without mixing  #@NEW_LINE#@#  

Significance  #@NEW_LINE#@#  
Markov chains are simple mathematical objects that can be used to generate random samples from a probability space by taking a random walk on elements of the space.  #@NEW_LINE#@#  Unfortunately, in applications, it is often unknown how long a chain must be run to generate good samples, and in practice, the time required is often simply too long.  #@NEW_LINE#@#  This difficulty can preclude the possibility of using Markov chains to make rigorous statistical claims in many cases.  #@NEW_LINE#@#  We develop a rigorous statistical test for Markov chains which can avoid this problem, and apply it to the problem of detecting bias in Congressional districting.  #@NEW_LINE#@#  

Abstract  #@NEW_LINE#@#  
We present a statistical test to detect that a presented state of a reversible Markov chain was not chosen from a stationary distribution.  #@NEW_LINE#@#  In particular, given a value function for the states of the Markov chain, we would like to show rigorously that the presented state is an outlier with respect to the values, by establishing a p value under the null hypothesis that it was chosen from a stationary distribution of the chain.  #@NEW_LINE#@#  A simple heuristic used in practice is to sample ranks of states from long random trajectories on the Markov chain and compare these with the rank of the presented state; if the presented state is a 0.1% outlier compared with the sampled ranks (its rank is in the bottom 0.1% of sampled ranks), then this observation should correspond to a p value of 0.001.  #@NEW_LINE#@#  This significance is not rigorous, however, without good bounds on the mixing time of the Markov chain.  #@NEW_LINE#@#  Our test is the following: Given the presented state in the Markov chain, take a random walk from the presented state for any number of steps.  #@NEW_LINE#@#  We prove that observing that the presented state is an -outlier on the walk is significant at p=2 under the null hypothesis that the state was chosen from a stationary distribution.  #@NEW_LINE#@#  We assume nothing about the Markov chain beyond reversibility and show that significance at p is best possible in general.  #@NEW_LINE#@#  We illustrate the use of our test with a potential application to the rigorous detection of gerrymandering in Congressional districting.  #@NEW_LINE#@#  

This schematic illustrates a region of a potentially much larger Markov chain with a very simple structure; from each state seen here, a jump is made with equal probability to each of four neighboring states.  #@NEW_LINE#@#  Colors from green to pink represent labels from small to large, respectively.  #@NEW_LINE#@#  It is impossible to know from this local region alone whether the highlighted green state has unusually small label in this chain overall.  #@NEW_LINE#@#  However, to an unusual degree, this state is a local outlier.  #@NEW_LINE#@#  The  test is based on the fact that no reversible Markov chain can have too many local outliers.  #@NEW_LINE#@#  
SI_Text  #@NEW_LINE#@#  
S1_Precinct_Data  #@NEW_LINE#@#  
Precinct-level voting data and associated shape files were obtained from the Harvard Election Data Archive (projects.iq.harvard.edu/eda/home) (20).  #@NEW_LINE#@#  The data for Pennsylvania contain 9,256 precincts.  #@NEW_LINE#@#  The data were altered in two ways: 258 precincts that were contained within another precinct were merged and 79 precincts that were not contiguous were split into continuous areas, with voting and population data distributed proportional to the area.  #@NEW_LINE#@#  The result was a set of 9,060 precincts.  #@NEW_LINE#@#  All geometry calculations and manipulations were accomplished in R with maptools, rgeos, and BARD R packages.  #@NEW_LINE#@#  The final input to the Markov chain is a set of precincts with corresponding areas, neighbor precincts, the length of the perimeter shared with each neighbor, voting data from 2012, and the current Congressional district to which the precinct belongs.  #@NEW_LINE#@#  

S2_Valid_Districting  #@NEW_LINE#@#  
We restrict our attention to districtings satisfying four restrictions, each of which we describe here.  #@NEW_LINE#@#  

S3_The_Markov_Chain  #@NEW_LINE#@#  
The Markov chain M that we use has as its state space , the space of all valid districtings (with 18 districts) of Pennsylvania.  #@NEW_LINE#@#  Note that there is no simple way to enumerate these, and there is an enormous number of them.  #@NEW_LINE#@#  
A simple way to define a Markov chain on this state space is to transition as follows.  #@NEW_LINE#@#  
Let the Markov chain with these transition rules be denoted by M0.  #@NEW_LINE#@#  This chain is a perfectly fine reversible Markov chain to which our theorem applies, but the uniform distribution on valid districtings is not stationary for M0; therefore, we cannot use M0 to make comparisons between a presented districting and a uniformly random valid districting.  #@NEW_LINE#@#  
A simple way to make the uniform distribution stationary is to regularize the chain (that is, to modify the chain so that the number of legal steps from any state is equal).  #@NEW_LINE#@#  (M0 is not already regular, because the number of precincts on the boundaries of districts will vary from districting to districting.)  #@NEW_LINE#@#  We do this by adding loops to each possible state.  #@NEW_LINE#@#  In particular, using a theoretical maximum Nmax on the possible size of NS for any district, we modify the transition rules as follows.  #@NEW_LINE#@#  
In particular, with this modification, each state has exactly Nmax possible transitions, which are each equally likely; many of these transitions are loops back to the same state.  #@NEW_LINE#@#  (Some of these loops arise from step ii, but some also arise when the if condition in step iv fails.)  #@NEW_LINE#@#  

S4_The_Label_Function  #@NEW_LINE#@#  
In principle, any label function  could be used in the application of the  test; note that Theorem 1.1 places no restrictions on .  #@NEW_LINE#@#  Thus, when we choose which label function to use, we are making a choice based on what is likely to achieve good significance rather than what is valid statistical reasoning (subject to the caveat discussed below).  #@NEW_LINE#@#  To choose a label function that was likely to allow good statistical power, we want to have a function that is  #@NEW_LINE#@#  
Although the role of the first condition in achieving outlier status is immediately obvious, the second property is also crucial to detecting significance with our test, which makes use of trajectories that may be quite small compared with the mixing time of the chain.  #@NEW_LINE#@#  For the  test to succeed at showing significance, it is not enough for the presented state 0 to actually be an outlier against  with respect to ; this outlier status must also be detectable on trajectories of the fixed length k, which may well be too small to mix the chain.  #@NEW_LINE#@#  This second property discourages the use of coarse-grained label functions, such as the number of seats of 18 that the Democrats would hold with the districting in question, because many swaps would be needed to shift a representative from one party to another.  #@NEW_LINE#@#  
We considered two label functions for our experiments (each selected with the above desired properties in mind) to show the robustness of our framework.  #@NEW_LINE#@#  The first label function var that we used is simply the negative of the variance in the proportions of Democrat voters among the districts.  #@NEW_LINE#@#  Thus, given a districting , var() is calculated asvar()=(12+22++18218(1+2++1818)2),where for each i=1,,18, i is the fraction of voters in that district that voted for the Democrat presidential candidate in 2012.  #@NEW_LINE#@#  We suspect that the variance is a good label function from the standpoint of the first characteristic listed above but a great label function from the standpoint of the second characteristic.  #@NEW_LINE#@#  Recall that, in practice, gerrymandering is accomplished by packing the voters of one party into a few districts, in which they make up an overwhelming majority.  #@NEW_LINE#@#  This technique, naturally, results in a high-variance vector of party proportions in the districts.  #@NEW_LINE#@#  However, high-variance districtings can exist that do not favor either party (note, for example, that the variance is symmetric with respect to Democrats and Republicans, ignoring third-party affiliations).  #@NEW_LINE#@#  Thus, for a districting that is biased against  because of a partisan gerrymander to stand out as an outlier, it must have especially high variance.  #@NEW_LINE#@#  In particular, statistical significance will be weaker than it might be for a label function that is more strongly correlated with partisan gerrymandering.  #@NEW_LINE#@#  However, var can detect very small changes in the districting, because essentially, every swap will either increase or decrease the variance.  #@NEW_LINE#@#  Indeed, for the run of the chain corresponding to the L constraint (SI Text, Runs of the Chain), var(X0) was strictly greater than var(Xi) for the entire trajectory (1i240).  #@NEW_LINE#@#  That is, for the L constraint, the current districting of Pennsylvania was the absolute worst districting seen according to var among the more than 1 trillion districtings on the trajectory.  #@NEW_LINE#@#  
The second label function that we considered is calculated simply as the difference between the median and the mean of the ratios 1,,18.  #@NEW_LINE#@#  This simple metric, called the Symmetry Vote Bias by McDonald and Best (13) and denoted as MM by us, is closely tied to the goal of partisan gerrymandering.  #@NEW_LINE#@#  As a simple illustration of the connection, we consider the case where the median of the ratios 1,,18 is close to 12.  #@NEW_LINE#@#  In this case, the mean of the i tracks the fraction of votes that the reference party wins to win one-half of the seats.  #@NEW_LINE#@#  Thus, a positive Symmetry Vote Bias corresponds to an advantage for the reference party, whereas a negative Symmetry Vote Bias corresponds to a disadvantage.  #@NEW_LINE#@#  The use of the Symmetry Vote Bias in evaluating districtings dates at least to the 19th century work of Edgeworth (21).  #@NEW_LINE#@#  These features make it an excellent candidate from the standpoint of our first criterion: gerrymandering is very likely to be reflected in outlier values of MM.  #@NEW_LINE#@#  
However, MM is a rather slow-changing function compared with var.  #@NEW_LINE#@#  Indeed, observe that, in the calculationSymmetry Vote Bias=medianmean,the mean is essentially fixed, so that changes in MM depend on changes in the median.  #@NEW_LINE#@#  In initial changes to the districting, only changes to the 2 districtings giving rise to the median (2 because 18 is even) can have a significant impact on MM.  #@NEW_LINE#@#  (However, changes to any district directly affect var.)  #@NEW_LINE#@#  
It is likely possible to make better choices for the label function  to achieve better significance.  #@NEW_LINE#@#  For example, the metric BG described by Nagle (12) seems likely to be excellent from the standpoints of conditions i and ii simultaneously.  #@NEW_LINE#@#  However, we have restricted ourselves to the simple choices of var and MM to clearly show our method and make it obvious that we have not tried many labeling functions before finding some that worked (in which case, a multiple hypothesis test would be required).  #@NEW_LINE#@#  
One point to keep in mind is that, often when applying the  testincluding in this application to gerrymanderingwe will wish to apply the test and thus, need to define a label function after the presented state 0 is already known.  #@NEW_LINE#@#  In these cases, care must be taken to choose a canonical label function , so that there is no concern that  was carefully crafted in response to 0 (in this case, a multiple hypothesis correction would be required for the various possible  values that could have been crafted depending on 0); var and MM are excellent choices from this perspective: the variance is a common and natural function on vectors, and the Symmetry Vote Bias has an established history in the evaluation of gerrymandering (and in particular, a history that predates the present districting of Pennsylvania).  #@NEW_LINE#@#  

S5_Runs_of_the_Chain  #@NEW_LINE#@#  
In Table S1, we give the results of eight runs of the chain under various conditions.  #@NEW_LINE#@#  Each run was for k=240 steps.  #@NEW_LINE#@#  Code and input data for our Markov chain are available at the website of W.P.  #@NEW_LINE#@#  (math.cmu.edu/wes).  #@NEW_LINE#@#  
Generally, after an initial burn-in period, we expect the chain to (almost) never again see states as unusual as the current districting of Pennsylvania, which means that we expect the test to show significance proportional to the inverse of the square root of the number of steps (i.e., the p value at 242 steps should be one-half the p value at 240 steps).  #@NEW_LINE#@#  In particular, for the L1, L2, and L constraints, these runs never revisited states as bad as the initial state after 221 steps for the MM label and after 26 steps for the var label.  #@NEW_LINE#@#  Note that this agrees with our guess that var had the potential to change more quickly than MM.  #@NEW_LINE#@#  The perimeter constraint did revisit enough states as bad as the given state with respect to the var label to adversely affect its p value with respect to the var label.  #@NEW_LINE#@#  This observation may reflect our guess that the var label is worse than the MM label in terms of how easily it can distinguish gerrymandered districtings from random ones.  #@NEW_LINE#@#  
The parameters for the first row were used for Fig 2.  #@NEW_LINE#@#  
One quick point is that, although we have experimented here with different compactness measures, there is no problem of multiple hypothesis correction to worry about, because every run that we encountered produces strong significance for the bias of the initial districting.  #@NEW_LINE#@#  The point of experimenting with the notion of compactness is to show that this is a robust framework and that the finding is unlikely to be sensitive to minor disagreements over the proper definition of the set of valid districtings.  #@NEW_LINE#@#  

S6_An_Example_Where__Is_Best_Possible  #@NEW_LINE#@#  
It might be natural to suspect that observing -outlier status for  on a random trajectory from  is significant at something like p instead of the significance p established by Theorem 1.1.  #@NEW_LINE#@#  However, because Theorem 1.1 places no demand on the mixing rate of M, it should instead seem remarkable that any significance can be shown in general, and indeed, we show by example in this section that significance at p is essentially best possible.  #@NEW_LINE#@#  
Let N be some large integer.  #@NEW_LINE#@#  We let M be the Markov chain where X0 is distributed uniformly in [0,1,2,,N1], and for any i1, Xi is equal to Xi1+i computed modulo N, where i is 1 or 1 with probability 1/2.  #@NEW_LINE#@#  Note that the chain is stationary and reversible.  #@NEW_LINE#@#  
If N is chosen large relative to k, then with probability arbitrarily close to one the value of X0 is at distance greater than k from zero (in both directions).  #@NEW_LINE#@#  Conditioning on this event, we have that X0 is minimum among X0,,Xk if and only if all of the partial sums i=1ji are positive.  #@NEW_LINE#@#  The probability of this event is just the probability that a k-step 1D random walk from the origin takes a first step to the right and does not return to the origin.  #@NEW_LINE#@#  The calculation of this probability is a classical problem in random walks, which can be solved using the reflection principle.  #@NEW_LINE#@#  
In particular, for k even, the probability is given by12k+1(kk/2)12k.  #@NEW_LINE#@#  
Because being the minimum of X0,,Xk corresponds to being an -outlier for =1/k+1, this example shows that the probability of being an -outlier can be as high as /2.  #@NEW_LINE#@#  
The best possible value of the constant in the  test seems to be an interesting problem for future work.  #@NEW_LINE#@#  

S7_Notes_on_Statistical_Power  #@NEW_LINE#@#  
The effectiveness of the  test depends on the availability of a good choice for  and the ability to run the test for long enough (in other words, choose k large enough) to detect that the presented state is a local outlier.  #@NEW_LINE#@#  
It is possible, however, to make a general statement about the power of the test when k is chosen large relative to the actual mixing time of the chain.  #@NEW_LINE#@#  Recall that one potential application of the test is in situations where the mixing time of the chain is actually accessible through reasonable computational resources, although this fact cannot be proved rigorously, because theoretical bounds on the mixing time are not available.  #@NEW_LINE#@#  In particular, we do know that the test is very likely to succeed when k is sufficiently large and (0) is atypical.  #@NEW_LINE#@#  
Theorem S1.  #@NEW_LINE#@#  Let M be a reversible Markov chain on , and let : be arbitrary.  #@NEW_LINE#@#  Given 0, suppose that, for a random state , (()(0)).  #@NEW_LINE#@#  Then, with probability at least1(1+k102)1minexp(2k202),  #@NEW_LINE#@#  
() is an 2-outlier among (0),(1),,(k), where 0,1, is a random trajectory starting from 0.  #@NEW_LINE#@#  
Here, 2 is the relaxation time for M defined as 1/(12), where 2 is the second eigenvalue of M. 2 is thus the inverse of the spectral gap for M and intimately related to the mixing time of M (2224).  #@NEW_LINE#@#  The probability  in Theorem S1 converges exponentially quickly to 1 and moreover, is very close to one after k is large relative to 2.  #@NEW_LINE#@#  In particular, Theorem S1 shows that the  test will work when the test is run for long enough.  #@NEW_LINE#@#  Of course, one strength of the  test is that it can sometimes show bias, even when k is far too small to mix the chain, which is almost certainly the case for our application to gerrymandering.  #@NEW_LINE#@#  When these short-k runs are successful at detecting bias is, of course, dependent on the relationship of the presented state 0 and its local neighborhood in the chain.  #@NEW_LINE#@#  
Theorem S1 is an application of the following theorem of Gillman.  #@NEW_LINE#@#  
Theorem S2.  #@NEW_LINE#@#  Let M=X0,X1, be a reversible Markov chain on , let A, and let Nk(A) denote the number of visits to A among X0,,Xk.  #@NEW_LINE#@#  Then, for any  greater than 0,(Nk(A)/n(A) greater than )(1+n102)(X0=)2()Ã—exp(2n202).Proof of Theorem S1.  #@NEW_LINE#@#  We apply Theorem S2, with A as the set of states , such that ()(0), X0=0, and =.  #@NEW_LINE#@#  By assumption, (A), and Theorem S2 gives that(Nk(A)/k greater than 2)(1+k102)1minexp(2k202).  #@NEW_LINE#@#  


S8_A_Result_for_Small_Variation_Distance  #@NEW_LINE#@#  
In this section, we give a corollary of Theorem 1.1 that applies to the setting where X0 is not distributed as a stationary distribution  but instead, is distributed with small total variation distance to .  #@NEW_LINE#@#  
The total variation distance ||12||TV between probability distributions 1,2 on a probability space  is defined to be||12||TV:=supE|1(E)2(E)|.  #@NEW_LINE#@#  [S1]  #@NEW_LINE#@#  
Corollary S1.  #@NEW_LINE#@#  Let M=X0,X1, be a reversible Markov chain with a stationary distribution , and suppose that the states of M have real-valued labels.  #@NEW_LINE#@#  If ||X0||TV1, then for any fixed k, the probability that the label of X0 is an -outlier from among the list of labels observed in the trajectory X0,X1,X2,,Xk is, at most, 2+1.  #@NEW_LINE#@#  
The theorem is intuitively clear; we provide a formal proof below for completeness.  #@NEW_LINE#@#  


Definitions  #@NEW_LINE#@#  
We remind the reader that a Markov chain is a discrete time random process; at each step, the chain jumps to a new state, which only depends on the previous state.  #@NEW_LINE#@#  Formally, a Markov chain M on a state space  is a sequence M=X0,X1,X2, of random variables taking values in  (which correspond to states that may be occupied at each step), such that, for any ,0,,n1,(Xn=|X0=0,X1=1,,Xn1=n1)=(X1=|X0=n1).Note that a Markov chain is completely described by the distribution of X0 and the transition probabilities (X1=1|X0=0) for all pairs 0,1.  #@NEW_LINE#@#  Terminology is often abused, so that the Markov chain refers only to the ensemble of transition probabilities, regardless of the choice of distribution for X0.  #@NEW_LINE#@#  
With this abuse of terminology, a stationary distribution for the Markov chain is a distribution , such that X0 implies that X1 and therefore, that Xi for all i.  #@NEW_LINE#@#  When the distribution of X0 is a stationary distribution, the Markov chain X0,X1, is said to be stationary.  #@NEW_LINE#@#  A stationary chain is said to be reversible if, for all i,k, the sequence of random variables (Xi,Xi+1,,Xi+k) is identical in distribution to the sequence (Xi+k,Xi+k1,,Xi).  #@NEW_LINE#@#  Finally, a chain is reducible if there is a pair of states 0,1, such that 1 is inaccessible from 0 via legal transitions and irreducible otherwise.  #@NEW_LINE#@#  
A simple example of a Markov chain is a random walk on a directed graph beginning from an initial vertex X0 chosen from some distribution.  #@NEW_LINE#@#  Here,  is the vertex set of the directed graph.  #@NEW_LINE#@#  If we are allowed to label the directed edges with positive reals and if the probability of traveling along an arc is proportional to the label of the arc (among those leaving the present vertex), then any Markov chain has such a representation, because the transition probability (X1=1|X0=0) can be taken as the label of the arc from 0 to 1.  #@NEW_LINE#@#  Finally, if the graph is undirected, the corresponding Markov chain is reversible.  #@NEW_LINE#@#  

Detecting_Bias_in_Political_Districting  #@NEW_LINE#@#  
A central feature of American democracy is the selection of Congressional districts in which local elections are held to directly elect national representatives.  #@NEW_LINE#@#  Because a separate election is held in each district, the proportions of party affiliations of the slate of representatives elected in a state do not always match the proportions of statewide votes cast for each party.  #@NEW_LINE#@#  In practice, large deviations from this seemingly desirable target do occur.  #@NEW_LINE#@#  
Various tests have been proposed to detect gerrymandering of districting, in which a district is drawn in such a way as to bias the resulting slate of representatives toward one party, which can be accomplished by concentrating voters of the unfavored party in a few districts.  #@NEW_LINE#@#  One class of methods to detect gerrymandering concerns heuristic smell tests, which judge whether districting seems generally reasonable in its statistical properties (11, 12).  #@NEW_LINE#@#  For example, such tests may frown on districting in which difference between the mean and median votes on district by district basis is unusually large (13).  #@NEW_LINE#@#  
The simplest statistical smell test, of course, is whether the party affiliation of the elected slate of representatives is close in proportion to the party affiliations of votes for representatives.  #@NEW_LINE#@#  Many states have failed this simple test spectacularly, such as in Pennsylvania; in 2012, 48.77% of votes were cast for Republican representatives and 50.20% of votes were cast for Democrat representatives in an election that resulted in a slate of 13 Republican representatives and 5 Democrat representatives.  #@NEW_LINE#@#  
Heuristic statistical tests such as these all suffer from lack of rigor, however, because of the fact that the statistical properties of typical districting are not rigorously characterized.  #@NEW_LINE#@#  For example, it has been shown (14) that Democrats may be at a natural disadvantage when drawing electoral maps, even when no bias is at play, because Democrat voters are often highly geographically concentrated in urban areas.  #@NEW_LINE#@#  Particularly problematic is that the degree of geographic clustering of partisans is highly variable from state to state: what looks like gerrymandered districting in one state may be a natural consequence of geography in another.  #@NEW_LINE#@#  
Some work has been done in which the properties of valid districting are defined (which may be required to have roughly equal populations among districts, districts with reasonable boundaries, etc.  #@NEW_LINE#@#  ), so that the characteristics of a given districting can be compared with what would be typical for valid districting of the state in question, by using computers to generate random districting (15, 16); there is discussion of this in ref.  #@NEW_LINE#@#  13.  #@NEW_LINE#@#  However, much of this work has relied on heuristic sampling procedures, which do not have the property of selecting districting with equal probability (and more generally, distributions that are not well-characterized), undermining rigorous statistical claims about the properties of typical districts.  #@NEW_LINE#@#  
In an attempt to establish a rigorous framework for this kind of approach, several groups (1719) have used Markov chains to sample random valid districting for the purpose of such comparisons.  #@NEW_LINE#@#  Like many other applications of real-world Markov chains, however, these methods suffer from the completely unknown mixing time of the chains in question.  #@NEW_LINE#@#  Indeed, no work has even established that the Markov chains are irreducible (in the case of districting, irreducibility means that any valid districting can be reached from any other by a legal sequence of steps), even if valid districting was only required to consist of contiguous districts of roughly equal populations.  #@NEW_LINE#@#  Additionally, indeed, for very restrictive notions of what constitutes valid districting, irreducibility certainly fails.  #@NEW_LINE#@#  
As a straightforward application of the  test, we can achieve rigorous p values in Markov models of political districting, despite the lack of bounds on mixing times of the chains.  #@NEW_LINE#@#  In particular, for all choices of the constraints on valid districting that we tested, the  test showed that the current Congressional districting of Pennsylvania is an outlier at significance thresholds ranging from p2.5104 to p8.1107.  #@NEW_LINE#@#  Detailed results of these runs are in SI Text.  #@NEW_LINE#@#  
A key advantage of the Markov chain approach to gerrymandering is that it rests on a rigorous framework, namely comparing the actual districting of a state with typical (i.e., random) districting from a well-defined set of valid districting.  #@NEW_LINE#@#  The rigor of the approach thus depends on the availability of a precise definition of what constitutes valid districting; in principle and in practice, the best choice of definition is a legal question.  #@NEW_LINE#@#  Although some work on Markov chains for redistricting (in particular, ref.  #@NEW_LINE#@#  19) has aimed to account for complex constraints on valid districting, our main goal in this manuscript is to illustrate the application of the  test.  #@NEW_LINE#@#  In particular, we have erred on the side of using relatively simple sets of constraints on valid districting in our Markov chains, while checking that our significance results are not highly sensitive to the parameters that we use.  #@NEW_LINE#@#  However, our test immediately gives a way of putting the work, such as that in ref.  #@NEW_LINE#@#  19, on a rigorous statistical footing.  #@NEW_LINE#@#  
The full description of the Markov chain that we use in this work is given in SI Text, but its basic structure is as follows: Pennsylvania is divided into roughly 9,000 census blocks.  #@NEW_LINE#@#  (These blocks can be seen on close inspection of Fig 2.)  #@NEW_LINE#@#  We define a division of these blocks into 18 districts to be a valid districting of Pennsylvania if districts differ in population by less than 2%, are contiguous, are simply connected (districts do not contain holes), and are compact in ways that we discuss in SI Text; roughly, this final condition prohibits districts with extremely contorted structure.  #@NEW_LINE#@#  The state space of the Markov chain is the set of valid districting of the state, and one step of the Markov chain consists of randomly swapping a precinct on the boundary of a district to a neighboring district if the result is still a valid districting.  #@NEW_LINE#@#  As we discuss in SI Text, the chain is adjusted slightly to ensure that the uniform distribution on valid districting is indeed a stationary distribution for the chain.  #@NEW_LINE#@#  Observe that this Markov chain has a potentially huge state space; if the only constraint on valid districting was that the districts have roughly equal population, there would be 1010000 or so valid districtings.  #@NEW_LINE#@#  Although contiguity and especially, compactness are severe restrictions that will decrease this number substantially, it seems difficult to compute effective upper bounds on the number of resulting valid districtings, and certainly, it is still enormous.  #@NEW_LINE#@#  Impressively, these considerations are all immaterial to our very general method.  #@NEW_LINE#@#  
Applying the  test involves the choice of a label function (), which assigns a real number to each districting.  #@NEW_LINE#@#  We have conducted runs using two label functions: var is the (negative) variance of the proportion of Democrats in each district of the districting (as measured by 2012 presidential votes), and MM is the difference between the median and mean of the proportions of Democrats in each district; MM is motivated by the fact that this metric has a long history of use in gerrymandering and is directly tied to the goals of gerrymandering, whereas the use of the variance is motivated by the fact that it can change quickly with small changes in districtings.  #@NEW_LINE#@#  These two choices are discussed further in SI Text, but an important point is that our use of these label functions is not based on an assumption that small values of var or MM directly imply gerrymandering.  #@NEW_LINE#@#  Instead, because Theorem 1.1 is valid for any fixed label function, these labels are tools used to show significance, which are chosen because they are simple and natural functions on vectors that can be quickly computed, seem likely to be different for typical versus gerrymandered districtings, and have the potential to change relatively quickly with small changes in districtings.  #@NEW_LINE#@#  For the various notions of valid districtings that we considered, the  test showed significance at p values in the range from 104 to 105 for the MM label function and the range from 104 to 107 for the var label function (see Fig S1 and Table S1).  #@NEW_LINE#@#  
As noted earlier, the  test can easily be used with more complicated Markov chains that capture more intricate definitions of the set of valid districtings.  #@NEW_LINE#@#  For example, the current districting of Pennsylvania splits fewer rural counties than the districting in Fig 2, Right, and the number of county splits is one of many metrics for valid districtings considered by the Markov chains developed in ref.  #@NEW_LINE#@#  19.  #@NEW_LINE#@#  Indeed, our test will be of particular value in cases where complex notions of what constitute valid districting slow the chain to make the heuristic mixing assumption particularly questionable.  #@NEW_LINE#@#  Regarding mixing time, even our chain with relatively weak constraints on the districtings (and very fast running time in implementation) seems to mix too slowly to sample , even heuristically; in Fig 2, we see that several districts still seem to have not left their general position from the initial districting, even after 240 steps.  #@NEW_LINE#@#  
On the same note, it should also be kept in mind that, although our result gives a method to rigorously disprove that a given districting is unbiasede.g., to show that the districting is unusual among districtings X0 distributed according to the stationary distribution it does so without giving a method to sample from the stationary distribution.  #@NEW_LINE#@#  In particular, our method cannot answer the question of how many seats Republicans and Democrats should have in a typical districting of Pennsylvania, because we are still not mixing the chain.  #@NEW_LINE#@#  Instead, Theorem 1.1 has given us a way to disprove X0 without sampling .  #@NEW_LINE#@#  

Proof_of_Theorem_11  #@NEW_LINE#@#  
We let  denote any stationary distribution for M and suppose that the initial state X0 is distributed as X0, so that in fact, Xi for all i.  #@NEW_LINE#@#  We say j is -small among 0,,k if there are, at most,  indices ij among 0,,k, such that the label of i is, at most, the label of j.  #@NEW_LINE#@#  In particular, j is 0-small among 0,1,,k when its label is the unique minimum label, and we encourage readers to focus on this =0 case in their first reading of the proof.  #@NEW_LINE#@#  
For 0jk, we definej,k:=(Xjis-small amongX0,,Xk)j,k():=(Xjis-small amongX0,,XkXj=).  #@NEW_LINE#@#  
Observe that, because Xs for all s, we also have thatj,k()=(Xs+jis-small amongXs,,Xs+kXs+j=).  #@NEW_LINE#@#  [1]  #@NEW_LINE#@#  
We begin by noting two easy facts.  #@NEW_LINE#@#  
Observation_41  #@NEW_LINE#@#  
Proof.  #@NEW_LINE#@#  Because M=X0,X1, is stationary and reversible, the probability that (X0,,Xk)=(0,,k) is equal to the probability that (X0,,Xk)=(k,,0) for any fixed sequence (0,,k).  #@NEW_LINE#@#  Thus, any sequence (0,,k) for which j= and j is a -small corresponds to an equiprobable sequence (k,,0), for which kj= and kj is -small.  #@NEW_LINE#@#  

Observation_42  #@NEW_LINE#@#  
Proof.  #@NEW_LINE#@#  Consider the events that Xj is an -small among X0,,Xj and among Xj,,Xk.  #@NEW_LINE#@#  These events are conditionally independent when conditioning on the value of Xj=, and j,j() gives the probability of the first of these events, whereas applying Eq.  #@NEW_LINE#@#  1 with s=j gives that 0,kj() gives the probability of the second event.  #@NEW_LINE#@#  
Finally, when both of these events happen, we have that Xj is 2-small among X0,,Xk.  #@NEW_LINE#@#  
We can now deduce thatj,2k()j,j()0,kj()=0,j()0,kj()(0,k())2.  #@NEW_LINE#@#  [2]Indeed, the first inequality follows from Observation 4.2, the equality follows from Observation 4.1, and the final inequality follows from the fact that j,k() is monotone nonincreasing in k for fixed j,,.  #@NEW_LINE#@#  
Observe now that j,k=j,k(Xj), where the expectation is taken over the random choice of Xj.  #@NEW_LINE#@#  
Thus, taking expectations in Eq.  #@NEW_LINE#@#  2, we find thatj,2k=j,2k()((0,k())2)(0,k())2=(0,k)2,[3]where the second of the two inequalities is the CauchySchwartz inequality.  #@NEW_LINE#@#  
For the final step in the proof, we sum the left- and right-hand sides of Eq.  #@NEW_LINE#@#  3 to obtainj=0kj,2k(k+1)(0,k)2.If we let j (0ik) be the indicator variable that is one whenever Xj is 2-small among X0,,Xk, then j=0kj is the number of 2-small terms, which is always, at most, 2+1.  #@NEW_LINE#@#  Therefore, linearity of expectation gives that2+1(k+1)(0,k)2,[4]giving that0,k2+1k+1.  #@NEW_LINE#@#  [5]Theorem 1.1 follows, because if Xi is an -outlier among X0,,Xk, then Xi is necessarily -small among X0,,Xk for =(k+1)1(k+1)1, and then, we have 2+12(k+1)12(k+1).  #@NEW_LINE#@#  


Acknowledgments  #@NEW_LINE#@#  
We thank John Nagle, Danny Sleator, and Dan Zuckerman for helpful conversations.  #@NEW_LINE#@#  M.C.  #@NEW_LINE#@#  was supported, in part, by NIH Grants 1R03MH10900901A1 and U545U54HG00854003.  #@NEW_LINE#@#  A.F.  #@NEW_LINE#@#  was supported, in part, by National Science Foundation (NSF) Grants DMS1362785 and CCF1522984 and Simons Foundation Grant 333329.  #@NEW_LINE#@#  W.P.  #@NEW_LINE#@#  was supported, in part, by NSF Grant DMS-1363136 and the Sloan Foundation.  #@NEW_LINE#@#  

Footnotes  #@NEW_LINE#@#  


