article id="http://dx.doi.org/10.1073/pnas.1621239114"  #@NEW_LINE#@#  
title  #@NEW_LINE#@#  
Memory-n strategies of direct reciprocity  #@NEW_LINE#@#  

Significance  #@NEW_LINE#@#  
Direct reciprocity is one of the fundamental mechanisms for cooperation.  #@NEW_LINE#@#  It is based on the idea that individuals are more likely to cooperate if they can expect their beneficiaries to remember and to return their cooperative acts in future.  #@NEW_LINE#@#  Previous computational models, however, often had to restrict the number of past rounds subjects can memorize.  #@NEW_LINE#@#  Herein we suggest an alternative approach.  #@NEW_LINE#@#  We propose general properties that robust cooperative strategies ought to have.  #@NEW_LINE#@#  Then we characterize all memory-n strategies that meet these properties, and we show that such strategies naturally emerge across different evolutionary scenarios.  #@NEW_LINE#@#  Our results are applicable to general social dilemmas of arbitrary size.  #@NEW_LINE#@#  For some dilemmas, longer memory is all it takes for cooperation to evolve.  #@NEW_LINE#@#  

Abstract  #@NEW_LINE#@#  
Humans routinely use conditionally cooperative strategies when interacting in repeated social dilemmas.  #@NEW_LINE#@#  They are more likely to cooperate if others cooperated before, and are ready to retaliate if others defected.  #@NEW_LINE#@#  To capture the emergence of reciprocity, most previous models consider subjects who can only choose from a restricted set of representative strategies, or who react to the outcome of the very last round only.  #@NEW_LINE#@#  As players memorize more rounds, the dimension of the strategy space increases exponentially.  #@NEW_LINE#@#  This increasing computational complexity renders simulations for individuals with higher cognitive abilities infeasible, especially if multiplayer interactions are taken into account.  #@NEW_LINE#@#  Here, we take an axiomatic approach instead.  #@NEW_LINE#@#  We propose several properties that a robust cooperative strategy for a repeated multiplayer dilemma should have.  #@NEW_LINE#@#  These properties naturally lead to a unique class of cooperative strategies, which contains the classical WinStay LoseShift rule as a special case.  #@NEW_LINE#@#  A comprehensive numerical analysis for the prisoners dilemma and for the public goods game suggests that strategies of this class readily evolve across various memory-n spaces.  #@NEW_LINE#@#  Our results reveal that successful strategies depend not only on how cooperative others were in the past but also on the respective context of cooperation.  #@NEW_LINE#@#  

Results  #@NEW_LINE#@#  
Repeated_Dilemmas_with_Memory-n_Strategies  #@NEW_LINE#@#  
We consider a repeated game in a group of m players.  #@NEW_LINE#@#  In each round, players can either cooperate (C) or defect (D).  #@NEW_LINE#@#  If there are j cooperators among the other group members, the payoff of a cooperator is Aj and the payoff of a defector is Bj.  #@NEW_LINE#@#  Herein, we focus on social dilemmas, such that payoffs are assumed to satisfy the following three properties (30, 31): (i) Players prefer their coplayers to cooperate, Aj+1Aj and Bj+1Bj for all j.  #@NEW_LINE#@#  (ii) A defectors payoff always exceeds the payoff of a cooperator, BjAj1 for all j.  #@NEW_LINE#@#  (iii) For the whole group, mutual cooperation is beneficial, Am1B0.  #@NEW_LINE#@#  Most of the well-known examples in the literature satisfy these criteria.  #@NEW_LINE#@#  For example, in a prisoners dilemma, m=2 and payoffs are A1=R (the reward for mutual cooperation), A0=S (the suckers payoff), B1=T (the temptation to defect), and B0=P (the punishment for mutual defection), such that TRPS.  #@NEW_LINE#@#  Herein, we will often use a specific parametrization of the prisoners dilemma, where cooperation means paying a cost c0 for the coplayer to derive a benefit bc.  #@NEW_LINE#@#  As a result, the payoffs become R=bc, S=c, T=b, and P=0.  #@NEW_LINE#@#  In SI Appendix, we show that our results are robust with respect to other payoff specifications (SI Appendix, Fig S7).  #@NEW_LINE#@#  Further examples of social dilemmas include the snowdrift game (32), the stag hunt game (33), and the public goods game (13, 34).  #@NEW_LINE#@#  
For a given group member i, we refer to the players past n actions as the players n-history, and we write hni=(a1i,,ani).  #@NEW_LINE#@#  The elements ati{C,D} represent the players action t rounds ago.  #@NEW_LINE#@#  For example, for a player who always cooperated except for the last round, the respective n-history is given by (D,C,,C).  #@NEW_LINE#@#  A games n-history is the tuple n=(hn1,,hnm) that contains the individual histories of all players.  #@NEW_LINE#@#  For m-player interactions, the set of all possible n-histories Hn contains |Hn|=2mn different n-histories.  #@NEW_LINE#@#  
In repeated games, a players decision to cooperate in one round may depend on the entire history of the game so far.  #@NEW_LINE#@#  Herein, we assume that players base their decision on the previous n rounds.  #@NEW_LINE#@#  A memory-n strategy is a vector =(p)Hn.  #@NEW_LINE#@#  The entries p[0,1] give the players probability of cooperating in the next round if the current n-history is Hn.  #@NEW_LINE#@#  For n=1 and m=2, this definition of memory-n strategies recovers the typical format of memory-1 strategies for the prisoners dilemma (22), =(pCC,pCD,pDC,pDD).  #@NEW_LINE#@#  We say that a memory-n strategy =(p) is pure if all its entries are either 0 or 1.  #@NEW_LINE#@#  In contrast, the strategy is stochastic if there is at least one entry p for which 0less_thanpless_than1.  #@NEW_LINE#@#  We assume that the players actions in any round can be subject to implementation errors [i.e., players have a trembling hand (35)].  #@NEW_LINE#@#  Specifically, when a player intends to cooperate (defect) in a given round, there is a probability 0 that an error leads the player to defect (cooperate) instead.  #@NEW_LINE#@#  In the main text, we entirely focus on infinitely repeated games without discounting of the future.  #@NEW_LINE#@#  In such games, the assumption of occasional errors allows us to ignore the players actions in the first n rounds (when no complete n-history is yet available).  #@NEW_LINE#@#  The payoffs of the players can be calculated independent of the initial history of play (for details, see SI Appendix).  #@NEW_LINE#@#  
In the limit of rare errors, a player with some given strategy may never experience certain n-histories.  #@NEW_LINE#@#  For example, in a prisoners dilemma where player 1 uses , the 2-history =(h1;h2)=(CC;CD) cannot arise: It would require that the -player cooperated in the last round although the coplayer defected the round before.  #@NEW_LINE#@#  Motivated by this observation, we say that an n-history  is consistent with respect to the focal player 1s strategy  if there are strategies j for the remaining group members such that, in a game without errors, the history  is revisited with positive probability if it was reached once (for formal definitions, see SI Appendix).  #@NEW_LINE#@#  We refer to the set of all consistent n-histories with respect to  as n()Hn.  #@NEW_LINE#@#  The consistent n-histories of a strategy  are those histories that a -player will generically experience.  #@NEW_LINE#@#  We say two memory-n strategies =(p) and =(q) are equivalent, and write , if both strategies have the same consistent n-histories n()=n(), and if they prescribe the same action for all those consistent n-histories, p=q for all n().  #@NEW_LINE#@#  As the error rate approaches zero, equivalent strategies  become more and more indistinguishable.  #@NEW_LINE#@#  No matter which strategies the remaining group members use, the expected response of a -player will (almost) always coincide with the expected response of a -player.  #@NEW_LINE#@#  

Desirable_Properties_of_Memory-n_Strategies  #@NEW_LINE#@#  
Within the set of memory-1 strategies for the prisoners dilemma, evolutionary processes often lead to a particular cooperative strategy, WSLS (15, 16).  #@NEW_LINE#@#  A  player only cooperates if both players chose the same action before, (pCC,pCD,pDC,pDD)=(1,0,0,1).  #@NEW_LINE#@#  has several qualities (22, 23).  #@NEW_LINE#@#  It is fully cooperative against a player with the same strategy; it is robust with respect to occasional errors; it is immune to invasion by unconditional altruists; and, if the benefit-to-cost ratio satisfies b/c2,  is also stable against defectors.  #@NEW_LINE#@#  Herein we suggest that the same qualities may also prove useful for memory-n strategies in arbitrary m-player games.  #@NEW_LINE#@#  In the following, we thus formalize and generalize a few of the properties of  (see Fig 1A for a visual description, and see SI Appendix for formal definitions).  #@NEW_LINE#@#  We will start with the property of mutual cooperativeness.  #@NEW_LINE#@#  

Stability_of_Pure_Memory-2_Strategies_with_Errors  #@NEW_LINE#@#  
As an application of our previous results, let us consider memory-2 strategies for the repeated prisoners dilemma.  #@NEW_LINE#@#  Depending on the players own two moves in the previous two rounds, and depending on the two moves of the coplayer, there are 24=16 possible 2-histories .  #@NEW_LINE#@#  A player with a memory-2 strategy needs to determine whether to cooperate or defect for each possible 2-history, and thus there are 216=65,536 pure memory-2 strategies.  #@NEW_LINE#@#  However, there are only two all-or-none strategies: AON2 punishes unilateral defection for two rounds, and reverts to cooperation thereafter.  #@NEW_LINE#@#  AON1 punishes defectors only once (and hence coincides with the memory-1 strategy ).  #@NEW_LINE#@#  In addition, one may also consider a delayed version of AON1, which waits for one round until it punishes unilateral defection.  #@NEW_LINE#@#  AON2 is predicted to be stable for b/c1.5, whereas the other two strategies require b/c2.  #@NEW_LINE#@#  
We performed an exhaustive numerical analysis to identify all strict Nash equilibria if players are restricted to pure memory-2 strategies.  #@NEW_LINE#@#  To this end, we considered a small error rate of =0.01, and we computed, for each of these strategies, whether any other pure strategy can yield at least the same payoff (see SI Appendix for a detailed description of the method).  #@NEW_LINE#@#  This analysis shows that, for typical benefit-to-cost ratios (with 1less_thanb/cless_than10), there are 11 Nash equilibria that yield the mutual cooperation payoff against themselves; four of those are equivalent to AON2, four others are equivalent to AON1, and the remaining three are delayed versions of AON1 (Table 1).  #@NEW_LINE#@#  In particular, all 11 strategies are mutually cooperative, revert to mutual cooperation after at most two rounds, and punish defectors for at least one round (possibly with one round delay).  #@NEW_LINE#@#  
This numerical approach is not restricted to cooperative strategies; we also used this method to record all other stable memory-2 strategies for the repeated prisoners dilemma.  #@NEW_LINE#@#  We find that, besides the class of cooperative strategies, one can distinguish three additional classes of stable behaviors.  #@NEW_LINE#@#  First, there are Nash equilibria that lead to mutual defection, containing 15 elements, including  and  (SI Appendix, Table S2).  #@NEW_LINE#@#  Second, we also identified a class of stable self-alternating strategies, containing eight strategies in total (SI Appendix, Table S3).  #@NEW_LINE#@#  When applied by both players, these self-alternating strategies lead to a deterministic switch between rounds of mutual cooperation and rounds of mutual defection.  #@NEW_LINE#@#  Finally, the last class of Nash equilibria consists of strategies that have two absorbing states, for example, mutual cooperation and mutual defection (SI Appendix, Table S4).  #@NEW_LINE#@#  When two such players interact, they defect for a large number of rounds; however, after a specific sequence of erroneous moves, players begin to cooperate until cooperation again breaks down due to errors.  #@NEW_LINE#@#  Thus, the set of memory-2 strategies allows for multiple equilibria that differ in their prospects for cooperation.  #@NEW_LINE#@#  Which of these equilibria is most relevant may thus depend on how likely they are to emerge in natural evolutionary processes.  #@NEW_LINE#@#  

Evolutionary_Dynamics_Among_Memory-n_Players  #@NEW_LINE#@#  
Based on the previous equilibrium analysis, we may predict the following: (i) For intermediate b/c ratios, cooperation should more readily evolve among memory-2 strategies than among memory-1 strategies.  #@NEW_LINE#@#  (ii) If cooperation evolves, it is due to strategies with an all-or-none character (i.e., strategies that are particularly likely to cooperate if players chose the same actions during the previous rounds).  #@NEW_LINE#@#  In the following, we test these predictions by simulating a simple imitation process based on the dynamics of Imhof and Nowak (17) for stochastic memory-1 and memory-2 strategies (the setup of these simulations is outlined in Materials and Methods).  #@NEW_LINE#@#  
Our simulation results support both predictions.  #@NEW_LINE#@#  When players are allowed to use memory-2 strategies, the evolving cooperation rates sharply increase once b/c1.5 [i.e., when AON2 becomes stable (Fig 2A); as the evolving cooperation rate is a continuous function of the b/c ratio, we do not expect full cooperation when b/c is only slightly above 1.5].  #@NEW_LINE#@#  In contrast, when players are restricted to memory-1 strategies, cooperation increases more gradually, and substantial cooperation rates are only achieved when b/c2.  #@NEW_LINE#@#  To gain some insights on which strategies are particularly successful, we recorded the most abundant strategy for several independent simulation runs (that is, for each simulation run, we recorded which memory-1 or memory-2 strategy was adopted by the population for the longest time).  #@NEW_LINE#@#  The most abundant strategies resemble the predicted AON strategies reasonably well (Fig 2 B and C).  #@NEW_LINE#@#  When both players cooperated in all remembered rounds, players are almost certain to cooperate in the next round.  #@NEW_LINE#@#  Moreover, players are most likely to cooperate if the players actions in the last rounds coincided, consistent with all-or-none behavior.  #@NEW_LINE#@#  
Among memory-2 players, AON2-like strategies seem to be preferred over strategies that resemble AON1.  #@NEW_LINE#@#  In particular, although memory-2 players could make use of the classical  strategy, the most abundant strategy does not resemble  (in Fig 2C, this would require that the first four bars are close to 1, because a  player always cooperates if both players cooperated in the previous round).  #@NEW_LINE#@#  These findings suggest that memory-2 players consider the full 2-history of play when deciding whether to cooperate in the next round.  #@NEW_LINE#@#  
Fig 2 B and C also suggests that the evolving memory-1 strategies yield somewhat better approximations to AON behavior than the evolving memory-2 strategies.  #@NEW_LINE#@#  This may be partly due to the differential selection pressure on each of the p values.  #@NEW_LINE#@#  All 1-histories  are consistent with respect to AON1, and hence an AON1 player will frequently be challenged to give an optimal response to each possible 1-history.  #@NEW_LINE#@#  This selection pressure is somewhat damped for AON2 strategies, because each individual 2-history is less likely to occur over the course of a game (in fact, some of the 2-histories will typically only occur after a rather particular sequence of errors).  #@NEW_LINE#@#  
To further corroborate our theoretical predictions, we show, in SI Appendix, that all-or-none strategies are also predominant when we simulate the dynamics among memory-1 strategies for the public goods game (see SI Appendix, Fig S4, using a strictly larger strategy set than in refs.  #@NEW_LINE#@#  13 and 34).  #@NEW_LINE#@#  Similarly, we show that behaviors reminiscent of all-or-none strategies evolve in the prisoners dilemma when players only remember how often (but not when) players cooperated during the previous n3 rounds (SI Appendix, Fig S3).  #@NEW_LINE#@#  Among these simplified memory-n strategies, the most abundant strategies tend to cooperate if both players were equally cooperative in the previous n rounds, and they defect otherwise.  #@NEW_LINE#@#  However, higher memory no longer leads to substantially higher cooperation rates (SI Appendix, Fig S3A).  #@NEW_LINE#@#  These results suggest memory is not only important to assess how cooperative other group members have been but is also an important mechanism to reach coordination among like-minded players.  #@NEW_LINE#@#  Such coordination attempts are most successful if players remember both the degree of cooperation and its timing.  #@NEW_LINE#@#  


Discussion  #@NEW_LINE#@#  
Previous research often used tournaments and evolutionary contests to distill properties that successful reciprocal strategies ought to have.  #@NEW_LINE#@#  Herein, we take the converse approach.  #@NEW_LINE#@#  We formulated three simple principles that we can expect well-performing strategies to obey.  #@NEW_LINE#@#  Based on these principles, we derived a successful class of cooperative strategies for general multiplayer dilemmas.  #@NEW_LINE#@#  Each of our principles seems to be psychologically intuitive.  #@NEW_LINE#@#  Our first principle of mutual cooperativeness is motivated by the observation that most subjects are most likely to cooperate in fully cooperative groups (3, 43).  #@NEW_LINE#@#  The principle of retaliation is based on findings that people are willing to fight back when being exploited, sometimes even if this comes at a cost to themselves (44, 45).  #@NEW_LINE#@#  Our last principle acknowledges that mutual cooperation can only be sustained in noisy environments if we are able to forgive others for their occasional failures to cooperate (46).  #@NEW_LINE#@#  The importance of these principles was noted before (9, 22, 23, 29, 47).  #@NEW_LINE#@#  However, the application of these principles has been usually limited to specific two-player games, assuming that players are subject to rather severe constraints on their cognitive capabilities.  #@NEW_LINE#@#  Here we show that the above principles can be used to construct strategies that can be applied in any multiplayer dilemma, and where subjects may remember an arbitrary number of past events.  #@NEW_LINE#@#  
Similar to the well-known WSLS rule in the prisoners dilemma, all-or-none strategies AONk follow a Pavlovian pattern.  #@NEW_LINE#@#  If players obtained different payoffs in the last round, AONk players will repeat a successful action for the next k rounds (if they received the higher payoff of a defector within the mixed group), or they will abandon their inferior action for the next k rounds (if they received the lower payoff of a cooperator).  #@NEW_LINE#@#  However, if all group members obtained the same payoff in each of the previous k rounds, AONk players cooperate.  #@NEW_LINE#@#  AONk strategies are self-synchronous: Independent of the previous history, all members of a group of all-or-none players will choose the same action in every round.  #@NEW_LINE#@#  Such self-synchronicity can greatly facilitate mutual coordination toward the cooperative equilibrium once the other players similarity is perceived (48).  #@NEW_LINE#@#  
Higher memory is not necessary if a strategy only needs to resist invasion by defectors.  #@NEW_LINE#@#  As an example, let us consider the generous ZD strategy (2426, 28, 42) that always reciprocates cooperation, but forgives the coplayers defection in the prisoners dilemma with probability 1/(k+1).  #@NEW_LINE#@#  A player with such a strategy retaliates against  for an expected number of k rounds, and hence the generous ZD strategy is stable against  if b/c(k+1)/k, just like the AONk strategy.  #@NEW_LINE#@#  However, the generous ZD strategy is susceptible to indirect invasions: Unlike AONk, it can be easily subverted by unconditional cooperators, who, in turn, promote the emergence of defectors (7, 39).  #@NEW_LINE#@#  In line with this observation, the most successful strategies in our simulations indeed made use of their full memory capabilities; players did not rely on cooperative memory-1 strategies when they had access to higher memory strategies.  #@NEW_LINE#@#  
Overall, our study suggests that memory-n strategies are particularly valuable when the benefit of cooperation is small or intermediate (for b/c2, already, the simple memory-1 strategy  allows for full cooperation).  #@NEW_LINE#@#  In such cases, we may well expect to observe selection for longer memory as suggested by previous simulations (8), provided that the expected gains are worth the higher cognitive costs (49).  #@NEW_LINE#@#  In principle, our results suggest that cooperation is feasible in any multiplayer dilemma, provided that the interaction is sufficiently relevant for subjects to memorize their coplayers past actions.  #@NEW_LINE#@#  

Materials_and_Methods  #@NEW_LINE#@#  
In the following paragraphs, we describe the setup of our evolutionary process.  #@NEW_LINE#@#  Our evolutionary simulations are based on a simple pairwise imitation process, based on the dynamics described in ref.  #@NEW_LINE#@#  17.  #@NEW_LINE#@#  We consider a population of size N. Initially, all members are unconditional defectors.  #@NEW_LINE#@#  In each elementary time step, one individual experiments with a new mutant strategy.  #@NEW_LINE#@#  This mutant strategy =(q) is generated by randomly drawing 22n cooperation probabilities q from the unit interval [0,1].  #@NEW_LINE#@#  If the mutant strategy yields a payoff of M(j), where j is the number of mutants in the population, and if residents get a payoff of R(j), then the fixation probability fM of the mutant strategy can be calculated explicitly (50),fM=(1+i=1N1j=1iexp{s[M(j)R(j)]})1.  #@NEW_LINE#@#  [3]  #@NEW_LINE#@#  
The parameter s0 is called the strength of selection.  #@NEW_LINE#@#  It measures how important relative payoff advantages are for the evolutionary success of a strategy.  #@NEW_LINE#@#  When s is small, s0, payoffs become irrelevant, and the strategys fixation probability approaches fM1/N.  #@NEW_LINE#@#  The larger the value of s, the more strongly the evolutionary process favors the fixation of strategies that yield high payoffs.  #@NEW_LINE#@#  Once the mutant strategy either reaches fixation or goes to extinction, another mutant strategy is introduced to the resident population.  #@NEW_LINE#@#  We iterated this elementary population updating process for 107 mutant strategies per simulation run.  #@NEW_LINE#@#  This process provides a reasonable approximation on the dynamics among memory-n strategists when mutations are relatively rare (51, 52).  #@NEW_LINE#@#  In SI Appendix, however, we present further simulations suggesting that our qualitative results are independent of the assumption of rare mutations, and of the considered selection strength (SI Appendix, Fig S6).  #@NEW_LINE#@#  

Acknowledgments  #@NEW_LINE#@#  
This work was supported by the European Research Council Start Grant 279307: Graph Games (to K.C.  #@NEW_LINE#@#  ), Austrian Science Fund (FWF) Grant P23499-N23 (to K.C.  #@NEW_LINE#@#  ), FWF Nationale Forschungsnetzwerke Grant S11407-N23 Rigorous Systems Engineering/Systematic Methods in Systems Engineering (to K.C.  #@NEW_LINE#@#  ), Office of Naval Research Grant N00014-16-1-2914 (to M.A.N.  #@NEW_LINE#@#  ), and the John Templeton Foundation (M.A.N.).  #@NEW_LINE#@#  The Program for Evolutionary Dynamics is supported, in part, by a gift from B. Wu and Eric Larson.  #@NEW_LINE#@#  C.H.  #@NEW_LINE#@#  acknowledges generous support from the ISTFELLOW program, and L.A.M.-V. gratefully acknowledges support from the European Research Consortium for Informatics and Mathematics Alain Bensoussan Fellowship Program.  #@NEW_LINE#@#  

Footnotes  #@NEW_LINE#@#  


