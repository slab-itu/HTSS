article id="http://dx.doi.org/10.1073/pnas.1616440113"  #@NEW_LINE#@#  
title  #@NEW_LINE#@#  
Evaluating the evaluation of cancer driver genes  #@NEW_LINE#@#  

Significance  #@NEW_LINE#@#  
Modern large-scale sequencing of human cancers seeks to comprehensively discover mutated genes that confer a selective advantage to cancer cells.  #@NEW_LINE#@#  Key to this effort has been development of computational algorithms to find genes that drive cancer based on their patterns of mutation in large patient cohorts.  #@NEW_LINE#@#  Because there is no generally accepted gold standard of driver genes, it has been difficult to quantitatively compare these methods.  #@NEW_LINE#@#  We present a machine-learningbased method for driver gene prediction and a protocol to evaluate and compare prediction methods.  #@NEW_LINE#@#  Our results suggest that most current methods do not adequately account for heterogeneity in the number of mutations expected by chance and consequently yield many false-positive calls, particularly in cancers with high mutation rate.  #@NEW_LINE#@#  

Abstract  #@NEW_LINE#@#  
Sequencing has identified millions of somatic mutations in human cancers, but distinguishing cancer driver genes remains a major challenge.  #@NEW_LINE#@#  Numerous methods have been developed to identify driver genes, but evaluation of the performance of these methods is hindered by the lack of a gold standard, that is, bona fide driver gene mutations.  #@NEW_LINE#@#  Here, we establish an evaluation framework that can be applied to driver gene prediction methods.  #@NEW_LINE#@#  We used this framework to compare the performance of eight such methods.  #@NEW_LINE#@#  One of these methods, described here, incorporated a machine-learningbased ratiometric approach.  #@NEW_LINE#@#  We show that the driver genes predicted by each of the eight methods vary widely.  #@NEW_LINE#@#  Moreover, the P values reported by several of the methods were inconsistent with the uniform values expected, thus calling into question the assumptions that were used to generate them.  #@NEW_LINE#@#  Finally, we evaluated the potential effects of unexplained variability in mutation rates on false-positive driver gene predictions.  #@NEW_LINE#@#  Our analysis points to the strengths and weaknesses of each of the currently available methods and offers guidance for improving them in the future.  #@NEW_LINE#@#  

Summary of evaluation dataset.  #@NEW_LINE#@#  The evaluation dataset consisted of mutations spanning 34 cancer types.  #@NEW_LINE#@#  All included mutations were small somatic variants.  #@NEW_LINE#@#  Cancer types are ordered from Left to Right by number of samples, ranging from 15 for soft-tissue sarcoma to 1,093 for BRAC, with an average of 232 samples per cancer type.  #@NEW_LINE#@#  These cancer types span a wide range of solid and several liquid cancers, including multiple tissues and cell types of origin, different background mutation rates, and different numbers of available samples.  #@NEW_LINE#@#  For each cancer type, total mutations and number of available samples are shown.  #@NEW_LINE#@#  
Results  #@NEW_LINE#@#  
Overlap_of_the_Driver_Genes_Predicted_by_Each_Method  #@NEW_LINE#@#  
Eight methods were evaluated: MutsigCV (12), ActiveDriver (13), MuSiC (5), OncodriveClust (8), OncodriveFM (7), OncodriveFML (14), Tumor Suppressor and Oncogenes (TUSON) (9), and 20/20+ (https://github.com/KarchinLab/2020plus).  #@NEW_LINE#@#  All data, on all cancers, was considered (pancancer) in these comparisons.  #@NEW_LINE#@#  First, we assessed overlap of the predicted driver genes with the CGC.  #@NEW_LINE#@#  We considered only those CGC genes typed as somatic, missense, frameshift, nonsense or splice site, excluding translocations, large amplifications/deletions, and other mutation consequence types not addressed in our study, yielding a total of 188 CGC genes.  #@NEW_LINE#@#  Although the driver genes predicted by all methods were enriched for CGC genes, the predicted drivers by any individual method did not contain a majority of CGC genes (Dataset S1 and Fig 1A).  #@NEW_LINE#@#  Three methods (20/20+, MutsigCV, and TUSON) had substantially higher fractions of predicted drivers in the CGC than the other methods.  #@NEW_LINE#@#  When we considered a subset of 99 CGC genes supported by functional studies (15), the results were very similar.  #@NEW_LINE#@#  The ranking of methods by fraction predicted was essentially the same as with the full CGC, with the three methods listed above having substantially higher fractions than the rest (Fig S2).  #@NEW_LINE#@#  
Genes predicted by more than one method may be more likely to be drivers (11).  #@NEW_LINE#@#  For each method, we calculated the fraction of predicted drivers that were unique or predicted by at least one, two, or three other methods (Fig S3 and Dataset S2).  #@NEW_LINE#@#  As shown in Fig S3, there was little consensus in prediction of driver genes among the methods.  #@NEW_LINE#@#  The majority (5980%) of genes identified by MuSiC, ActiveDriver, OncodriveClust, OncodriveFML, or OncodriveFM were not observed by any of the other seven methods.  #@NEW_LINE#@#  The fractions of genes identified by TUSON, 20/20+, and MutsigCV that were not identified as driver genes in at least one of the other seven methods was 14%, 19%, and 33%, respectively.  #@NEW_LINE#@#  Although it is likely that some of the uniquely predicted drivers are bona fide, we could not find convincing literature support for the top-ranked unique predictions of MuSiC, ActiveDriver, and the Oncodrive methods (Dataset S3).  #@NEW_LINE#@#  A consensus list of drivers predicted by TUSON, 20/20+, or MutsigCV appears in Table S1.  #@NEW_LINE#@#  

Observed_vs_Expected_P_Values  #@NEW_LINE#@#  
Given the lack of agreement among these various methods, we compared P values reported by each method to those expected theoretically.  #@NEW_LINE#@#  Such comparisons are often used in statistics and can indicate invalid assumptions or inappropriate heuristics.  #@NEW_LINE#@#  Theoretically, the P value distribution should be approximately uniform after likely driver genes are removed (16).  #@NEW_LINE#@#  Therefore, we removed all genes predicted to be drivers by at least three methods after BenjaminiHochberg multiple-testing correction (q  0.1) and any remaining genes in the CGC.  #@NEW_LINE#@#  We assumed that the number of bona fide driver genes not removed by this procedure would be small enough to have minimal impact on the P value distribution.  #@NEW_LINE#@#  To quantify the differences between the observed P values and those expected from a uniform distribution, we developed a measure named mean absolute log2 fold change (MLFC) (SI Materials and Methods).  #@NEW_LINE#@#  MLFC values near zero represent the smallest discrepancies and the closest agreement between observed and theoretical P values.  #@NEW_LINE#@#  
One method (20/20+) had an MLFC that was fivefold lower than the seven others (Fig 1B).  #@NEW_LINE#@#  We also compared observed and theoretical P values with quantilequantile plots, which provide a detailed view of P value behavior (Fig S4A).  #@NEW_LINE#@#  20/20+ P values had by far the best agreement with theoretical expectation across the entire range of supported values.  #@NEW_LINE#@#  In the critical range typically used to assess statistical significance (P  0.05), OncodriveClust, OncodriveFM, OncodriveFML, ActiveDriver, and MuSiC substantially underestimated P values, whereas MutsigCV substantially overestimated them (Fig S4B).  #@NEW_LINE#@#  For methods that combine multiple P values for each gene, failure to model correlation between P values may be responsible for this underestimation.  #@NEW_LINE#@#  The null P value distributions at the other end of the distribution (0.21.0) should also be uniform and in this case independent of the actual number of true driver genes.  #@NEW_LINE#@#  

Number_of_Predicted_Driver_Genes  #@NEW_LINE#@#  
The number of predicted driver genes (q  0.1) ranged from 158 (MutsigCV) to 2,600 (OncodriveFM) (Fig 1C).  #@NEW_LINE#@#  There were two obvious categories of methods with respect to predicted driver genes: MutSigCV, 20/20+, and TUSON predicted 158243 genes (Table S1), whereas the remaining had over 400 driver genes.  #@NEW_LINE#@#  

Driver_Gene_Prediction_Consistency  #@NEW_LINE#@#  
Statistical methods suffer from both systematic and random prediction errors.  #@NEW_LINE#@#  When no gold standard is available, it is difficult to estimate systematic error, but possible to estimate random error by measuring the variability of predictions.  #@NEW_LINE#@#  We tested the eight methods on 10 repetitions of a random two-way split of the all samples in our dataset, while maintaining the proportion of samples in each cancer type.  #@NEW_LINE#@#  An ideal method would produce the same list of driver genes, ranked by P value, for each half of the split.  #@NEW_LINE#@#  For a fair comparison, we considered that methods predicting many drivers would be less likely to have consistent rankings than those predicting only a few.  #@NEW_LINE#@#  Thus, we developed a measure named TopDrop consistency (TDC) (SI Materials and Methods) that examines the overlap between genes ranked at a defined depth (e.g., the top 100 genes) for each half of the random split.  #@NEW_LINE#@#  Examining TDC at a depth of 100 genes showed MuSiC, 20/20+, and TUSON to be the three with the highest consistency (Fig 1D).  #@NEW_LINE#@#  Most methods decreased in consistency when the gene depth was varied between 20 and 300, but the ordering of the TDC scores among the eight methods remained relatively stable (Fig S5).  #@NEW_LINE#@#  

Overall_Performance  #@NEW_LINE#@#  
In Table 1, we summarize the performance of each method according to the criteria described above on the pancancer mutation data.  #@NEW_LINE#@#  The overall protocol is shown as a flowchart in Fig S6.  #@NEW_LINE#@#  We assume that a preferable method would predict a higher fraction of driver genes that overlap with the CGC, that overlap with at least one other method, that have the least deviation from expected null P values, and that have the highest consistency.  #@NEW_LINE#@#  Each method is accordingly ranked by these four criteria and the average rank is shown.  #@NEW_LINE#@#  The top ranked methods are 20/20+, TUSON, OncodriveFML, and MutsigCV.  #@NEW_LINE#@#  

Evaluation_of_Specific_Cancer_Types  #@NEW_LINE#@#  
To evaluate whether methods performed differently on specific cancer types, rather than on the pancancer dataset, we repeated our evaluations using four specific cancer types.  #@NEW_LINE#@#  We considered two moderate mutation rate cancers (PDACs, with median of 0.7 mutations per MB, BRACs, with median of 1 mutation per MB), and two high-mutation-rate cancers (head and neck squamous carcinomas, with median of 3.2 mutations per MB, and LUADs, with median of 6.7 mutations per MB).  #@NEW_LINE#@#  These mutation rates were based on the same dataset used throughout this study and described above.  #@NEW_LINE#@#  As with the pancancer types, the 20/20+ method had the least discrepancy between observed and theoretical P values (Fig S7A).  #@NEW_LINE#@#  For the TDC evaluation, we used a rank depth of 10 genes rather than the 100 used for pancancer, as it is likely that this number is closer to the number of driver genes in a single cancer type.  #@NEW_LINE#@#  The most consistent methods were 20/20+ and MuSiC (Fig S7C), and the least consistent methods were ActiveDriver and OncodriveClust.  #@NEW_LINE#@#  Driver genes in HNSCC were the most consistently predicted overall.  #@NEW_LINE#@#  
The number of cancer-specific predicted driver genes varied widely (Fig S7B).  #@NEW_LINE#@#  PDAC had the fewest predicted drivers (q  0.1), ranging from 3 (TUSON) to 49 (OncodriveFM), whereas LUAD had the most, ranging from 9 (TUSON) to 922 (OncodriveFM).  #@NEW_LINE#@#  ActiveDriver, OncodriveFM, and OncodriveClust predicted hundreds of cancer type-specific drivers, whereas OncodriveFML, MuSiC, 20/20+, and MutsigCV tended to predict no more than 40 in any of the four cancer types.  #@NEW_LINE#@#  

Variability_in_Background_Mutation_Rate  #@NEW_LINE#@#  
Because only a small fraction of the total somatic mutations in any common solid tumor affects driver genes, the remaining mutations can be considered passengers.  #@NEW_LINE#@#  These reflect the mutation background, that is, all mutations that occurred during the divisions of the cells that eventually formed the tumor, from embryogenesis until the tumor was surgically removed (17).  #@NEW_LINE#@#  The total number of mutations (drivers plus passengers) is therefore only slightly larger than the number of passenger mutations, and, for simplicity, we refer to this number as the background mutation rate.  #@NEW_LINE#@#  The median background mutation rate for cancer types in our pancancer set varied over two orders of magnitude (Fig S8), with individual samples varying over an even larger range.  #@NEW_LINE#@#  Mutation rates vary among individual genes and are influenced by nucleotide context, environmental factors, gene expression, chromatin state, replication timing, DNA repair activity, strand, and perhaps by a variety of factors that have yet to be discovered (4, 18, 19).  #@NEW_LINE#@#  
We analyzed the possible impact of unexplained variability in background mutation rate on expected false-positive driver gene predictions.  #@NEW_LINE#@#  First, we applied a binomial model previously used for driver gene detection power analysis (12).  #@NEW_LINE#@#  The model assumes a gene-specific background mutation rate , which is set to a relatively high value, corresponding to genes in the 90th percentile of mutation rate.  #@NEW_LINE#@#  We used the binomial to set a critical value for driver gene prediction, that is, the number of mutations required for a gene to be considered significantly different from the background.  #@NEW_LINE#@#  Next, we modeled the situation where the genes actually had mutation rates that varied around , using a beta-binomial model.  #@NEW_LINE#@#  We estimated the false positives expected under the binomial, after a highly conservative multiple-testing correction (Bonferroni).  #@NEW_LINE#@#  The number of mutations required to meet or exceed the binomial critical value was compared with that of the beta-binomial, for different background mutation rates, for levels of variability [beta-binomial coefficients of variation (CVs)], and for sample size ranging up to 8,000 (Fig 2A).  #@NEW_LINE#@#  Levels of variability defined by CVs (CV = 0.05, 0.1, and 0.2) were chosen to approximate low, medium, and high unexplained variation around the mean.  #@NEW_LINE#@#  As the number of samples increased, so did the number of expected false positives.  #@NEW_LINE#@#  At the low end of background mutation rates (0.5 mutations per MB), the expected false positives remained low, even when 8,000 samples were evaluated, regardless of the level of variability.  #@NEW_LINE#@#  At an intermediate background mutation rate of 3.0 mutations per MB and with high unexplained variability, 1,000 false positives were expected from 8,000 samples.  #@NEW_LINE#@#  At a high background mutation rate (10.0 mutations per MB), both medium and high unexplained variability produced many thousand expected false positives.  #@NEW_LINE#@#  
We reasoned that unexplained variability might also have an impact on power calculations to estimate how many samples must be sequenced to find the majority of cancer driver genes.  #@NEW_LINE#@#  To this end, we repeated previous calculations performed with a binomial power model, in which the required sample size was estimated to be 6005,000 per cancer type (12).  #@NEW_LINE#@#  The original model was parameterized to detect intermediate frequency driver genes, having 220% mutation rates above background per sample, with background defined by genes in the 90th percentile of background mutation rates.  #@NEW_LINE#@#  First, we calculated the sample size required to detect 90% of these drivers, given exome-wide backgrounds of 0.110 mutations per MB, and a conservative estimate of 2% effect size (SI Materials and Methods, Unexplained Variability Affects Power and False Positives).  #@NEW_LINE#@#  Next, we calculated the sample size required if the gene mutation rate varied around the original estimate, using a beta-binomial model with different CVs (CV = 0.05, 0.1, 0.2).  #@NEW_LINE#@#  The binomial power model was in accord with previous estimates.  #@NEW_LINE#@#  However, when unexplained variability was taken into account, the number of required samples increased sharply, particularly for higher background mutation rates (Fig 2C, Left).  #@NEW_LINE#@#  

Variability_in_Ratiometric_Features  #@NEW_LINE#@#  
Ratiometric features are expected to have significantly less variability among cancer types than background mutation rates.  #@NEW_LINE#@#  Fig S8 shows the variability of the median ratio of nonsilent to silent mutations for cancer types in our pancancer set.  #@NEW_LINE#@#  The variability of this ratiometric feature among tumor types is miniscule compared with that of mutation rates in the same tumor types.  #@NEW_LINE#@#  However, ratiometric features might also be sensitive to unexplained variability in their background distributions.  #@NEW_LINE#@#  Therefore, we calculated the expected false positives and statistical power of a simple ratiometric feature, the fraction of mutations in a gene having a specific nonsilent mutation consequence type.  #@NEW_LINE#@#  A slightly modified version of the calculations used for background mutation rate was applied (SI Materials and Methods, Unexplained Variability Affects Power and False Positives).  #@NEW_LINE#@#  We observed improved false-positive control (Fig 2B), and reduction in the number of required samples (Fig 2C, Right), particularly for high-mutation-rate cancers.  #@NEW_LINE#@#  


SI_Materials_and_Methods  #@NEW_LINE#@#  
Evaluated_Driver_Gene_Prediction_Methods  #@NEW_LINE#@#  
In addition to 20/20+, we selected several methods that cover alternate methodological approaches: mutational clustering, mutation functional impact, and significantly mutated genes.  #@NEW_LINE#@#  All methods were run in-house, using the latest version of the software provided by the authors.  #@NEW_LINE#@#  Detailed output from each method is in Dataset S4.  #@NEW_LINE#@#  

20_20+__Random_Forest_Features  #@NEW_LINE#@#  
We designed a set of 24 features (Dataset S5).  #@NEW_LINE#@#  Many of the features are components of the 20/20 rule OG and TSG scores, and we included several ratiometric features not in the original 20/20 rule, for example, ratio of missense to silent mutations, as well as features that represented mutation functional impact and gene importance.  #@NEW_LINE#@#  Normalized missense entropy, a measure of positional clustering, was calculated as follows:Ek=ipilog2pilog2k,[S1]where k is the total number of missense mutations in a gene and pi = (count of missense mutations in the ith codon)/k.  #@NEW_LINE#@#  
We calculated inactivating single-nucleotide variant (SNV) fraction P value, normalized missense entropy P value, and missense VEST score P value (Dataset S5) with Monte Carlo simulations, to approximate their null probability distributions.  #@NEW_LINE#@#  Briefly, for each gene, SNVs were moved with uniform probability to any matching position in the gene sequence, holding the total number of SNVs fixed.  #@NEW_LINE#@#  A matching position was required to have the same base context (C*pG, CpG*, TpC*, G*pA, A, C, G, T) as the observed position.  #@NEW_LINE#@#  This method of generating a null distribution controls for the particular gene sequence, gene length, and mutation base context.  #@NEW_LINE#@#  The number of SNVs remains the same, but the mutation consequence of a SNV may change.  #@NEW_LINE#@#  For example, a SNV that generates a missense mutation may generate a nonsense mutation in its new position.  #@NEW_LINE#@#  
A complete list of Random Forest feature importance rankings (25), measured by decrease in Gini index, is shown in Fig S10.  #@NEW_LINE#@#  

20_20+__Class_Imbalance  #@NEW_LINE#@#  
With only 54 OGs and 71 TSGs labeled by the original 20/20 rule, the number of passenger genes far exceeds the number of labeled driver genes, creating a problematic class imbalance.  #@NEW_LINE#@#  We use a subsampling approach, in which passenger genes are sampled at a 1:1 ratio to OGs plus TSGs.  #@NEW_LINE#@#  To compensate for the remaining OG and TSG imbalance, the Random Forest is trained with class weights inversely proportional to the sampled frequency of the class.  #@NEW_LINE#@#  Predictions were made with a random forest of 200 trees.  #@NEW_LINE#@#  For the pancancer data, we used 10-fold gene hold-out cross-validation to avoid overfitting.  #@NEW_LINE#@#  The procedure of 10-fold cross-validation was repeated five times, and the resulting scores from each gene were averaged to limit minor fluctuations in scores due to randomization in the cross-validation folds.  #@NEW_LINE#@#  

20_20+__Statistical_Significance  #@NEW_LINE#@#  
The statistical significance of each gene score was computed with an extension of the Monte Carlo simulation algorithm described above.  #@NEW_LINE#@#  Because mutations that result in insertions and deletions will not change their mutation consequence type by being randomly moved to another nucleotide in the same gene, they were moved to a random position in a different gene.  #@NEW_LINE#@#  This gene was selected based on a multinomial model, with probability proportional to the CDS length of the originating gene.  #@NEW_LINE#@#  For each gene, the Monte Carlo simulation was repeated 10 times, and for each simulation all 24 features were computed.  #@NEW_LINE#@#  In this process, protein interaction network features (degree and betweenness) were, additionally, permuted as a pair.  #@NEW_LINE#@#  The features of gene length, replication timing, HiC value, and average Cancer Cell Line Encyclopedia (CCLE) gene expression were not altered.  #@NEW_LINE#@#  Next, each simulated gene was scored with the Random Forest previously trained on the real data.  #@NEW_LINE#@#  The resulting OG, TSG, and driver scores for all simulated genes were used as an empirical null distribution.  #@NEW_LINE#@#  To compute a P value for a gene score, we used the fraction of simulated genes with a score equal to or greater than the score.  #@NEW_LINE#@#  P values were adjusted by the BenjaminiHochberg method for multiple hypotheses.  #@NEW_LINE#@#  For comparison with other driver gene prediction methods, we considered a gene to be significant (q  0.1) if any of the OG, TSG, or driver scores were significant.  #@NEW_LINE#@#  

Unexplained_Variability_Affects_Power_and_False_Positives  #@NEW_LINE#@#  
To evaluate effects of unexplained variability in the mutation rate on false positives and statistical power, we established two statistical models.  #@NEW_LINE#@#  The first model assumes a correctly estimated background mutation rate  for a particular gene (binomial model) and the second model assumes that gene background mutation rate varies around  (beta-binomial model).  #@NEW_LINE#@#  We used a binomial model previously developed for driver gene power analysis (12).  #@NEW_LINE#@#  The gene-specific mutation rate factor Fg calculated by MutsigCV (12) was set to represent a gene at the 90th percentile, given an exome-wide background mutation rate of , so that =Fg (Fg = 3.9).  #@NEW_LINE#@#  Average gene length (L) was set to 1,500 bases and 3/4 mutations were assumed to be nonsilent.  #@NEW_LINE#@#  Effective gene length was adjusted as Leff=3/4L.  #@NEW_LINE#@#  Gene background mutation rate was calculated using the total number of potentially mutated bases that could yield a nonsilent mutation (Neff), which is the effective gene length multiplied by number of samples (S).  #@NEW_LINE#@#  A predicted driver was defined as a gene with significantly higher nonsilent mutation rate per base than that gene's background mutation rate, where nonsilent mutation rate per base is the following:es=1((1)Leffr)1/Leff,[S2]and r is the fraction of samples with nonsilent mutations in the gene above background.  #@NEW_LINE#@#  Exome-wide background mutation rates of ( = 0.5e-6, 3e-6, or 10e-6) were considered.  #@NEW_LINE#@#  
The beta-binomial was designed to model several levels of unexplained variability around .  #@NEW_LINE#@#  To parameterize the beta-binomial with low, medium, and high variability levels, we used different coefficients of variation (CVs) for the mutation rate (0.05, 0.1, 0.2).  #@NEW_LINE#@#  Beta-binomial  and  parameters were computed as follows:=((1)(CV)21),[S3]=(1)((1)(CV)21).  #@NEW_LINE#@#  [S4]To compute the number of false positives expected from a binomial model when unexplained variability is present, we examined the probability that the number of mutations in a gene from a beta-binomial model (Kbeta-binomial) would meet or exceed the critical value (for a genome-wide significant driver gene at  = 5e-6) by the binomial kbinomial:E[FP]=gP,Neff(Kbeta-binomialkbinomial),[S5]where g is the total number of human genes (assumed 18,500) and both models use the same mean mutation rate  and total number of potentially mutated bases Neff.  #@NEW_LINE#@#  
We also modeled the effect of various levels of unexplained variability in mutation rate on the power to detect driver genes.  #@NEW_LINE#@#  We reproduced the binomial model power analysis of ref.  #@NEW_LINE#@#  12 to estimate the number of samples required for 90% power to detect genes in the 90th percentile of gene-specific background rate, with 2% mutation rate above background (r = 0.02).  #@NEW_LINE#@#  Using Eqs.  #@NEW_LINE#@#  S3 and S4 to parameterize the beta-binomial model, we calculated the number of samples required for 90% power at a Bonferroni genome-wide significance level of 5e-6.  #@NEW_LINE#@#  Samples were iteratively added until there was greater than or equal to 90% probability that a driver gene with mutation rate es would be found significant.  #@NEW_LINE#@#  Using the jagged power curve for discrete data (28), we found the minimum number of samples required to achieve 90% power.  #@NEW_LINE#@#  
Next, we evaluated the effects of unexplained variability on a ratiometric feature.  #@NEW_LINE#@#  As a proof of principle, we defined a simple ratiometric feature as the fraction of mutations in a gene having a specific nonsilent mutation consequence type.  #@NEW_LINE#@#  As in the evaluation of mutation rate, we established two statistical models, assuming independence of mutation events.  #@NEW_LINE#@#  For the binomial model, the fraction is correctly estimated, and for the beta-binomial model, the fraction varies around that estimate.  #@NEW_LINE#@#  A predicted driver gene was defined as having a significantly increased fraction with respect to the gene's background.  #@NEW_LINE#@#  The fraction in a driver gene is then as follows:pes=p+(es)es,[S6]where p is the genes background fraction of the specific mutation consequence type, and  and es are calculated as in our above-described analysis of mutation rate.  #@NEW_LINE#@#  In Fig 2 B and C, p was set to 0.107, which is the fraction of inactivating mutations in our pancancer dataset.  #@NEW_LINE#@#  
As in the mutation rate analysis, we parameterized the beta-binomial with low, medium, and high variability levels, using different CVs for the mutation rate (0.05, 0.1, 0.2).  #@NEW_LINE#@#  beta-binomial  and  parameters were computed as in Eqs.  #@NEW_LINE#@#  S3 and S4, but with  replaced by p. Expected false positives were computed as in Eq.  #@NEW_LINE#@#  S5, but with  replaced by p and Neffthe total number of potentially nonsilent mutated basesreplaced by the total number of expected nonsilent or silent mutated bases:Meff=esNeff+(NNeff).  #@NEW_LINE#@#  [S7]To estimate the effect of unexplained variability in the ratiometric feature on power to detect driver genes, we applied the same protocol used to assess unexplained variability in mutation rate on power.  #@NEW_LINE#@#  We estimated the minimum number of samples required for the same power and effect size used in the mutation rate analysis.  #@NEW_LINE#@#  

Irreproducible_Discovery_Rate  #@NEW_LINE#@#  
We expect that the status of a gene (driver or passenger) is related to its reproducibility, so that the drivers should be reproducible and the passengers not.  #@NEW_LINE#@#  There is a powerful method called the irreproducible discovery rate (IDR) (29), which infers the reproducibility of signals.  #@NEW_LINE#@#  We considered using the IDR framework to assess the consistency of driver gene prediction methods.  #@NEW_LINE#@#  Results suggested that IDR was not well suited to the task of comparing driver gene prediction methods, for the following reasons.  #@NEW_LINE#@#  First, an initial assumption about the reproducible proportion of genes (1) is required, and the number of genes that passed the IDR threshold had strong dependence on this initial setting.  #@NEW_LINE#@#  We also found that, when applied to repeated random partitions of the same gene list, the number of genes that passed the IDR threshold was sometimes bimodal, clustering around one low and one high value.  #@NEW_LINE#@#  We suspect that, on our data, the underlying EM algorithm is sometimes trapped in a local optimum, rather than converging to a global optimum.  #@NEW_LINE#@#  


Discussion  #@NEW_LINE#@#  
A major goal of the huge public investment in large-scale cancer sequencing has been to find driver genes.  #@NEW_LINE#@#  Robust computational prediction of drivers from small numbers of somatic variants is critical to this mission, and it is essential that the best methods for this purpose be identified.  #@NEW_LINE#@#  Although many such methods have been proposed (SI Materials and Methods, Evaluated Driver Gene Prediction Methods), it has been difficult to evaluate them because there is no gold standard to use as a benchmark.  #@NEW_LINE#@#  Here, we developed an evaluation framework for driver gene prediction methods that does not require a gold standard.  #@NEW_LINE#@#  The framework includes a large set of small somatic mutations from a wide range of cancer types and five evaluation metrics.  #@NEW_LINE#@#  It can be used to systematically evaluate new prediction methods and compare them to existing methods.  #@NEW_LINE#@#  The results would be more informative to users of these methods than current ad hoc approaches.  #@NEW_LINE#@#  
To apply the framework to a new method, a ranked list of predicted driver genes can be generated from the pancancer mutation dataset (Dataset S4 and Figs.  #@NEW_LINE#@#  S1 and S6), including a P value and a BenjaminiHochberg corrected q value for each gene.  #@NEW_LINE#@#  The choice of a threshold q  0.1 to define driver genes worked well in our evaluations but can be adjusted if so desired.  #@NEW_LINE#@#  The same threshold should be used for fair comparison of different methods.  #@NEW_LINE#@#  If a driver prediction tool does not produce P values, a raw score threshold that represents the desired false-discovery rate could be selected.  #@NEW_LINE#@#  
By calculating the overlap fraction of predicted drivers with both the CGC and the eight methods evaluated here, it is possible to quickly determine whether a new method is on the right track.  #@NEW_LINE#@#  Two baselines of good performance are a methods ability to recapitulate many of the well-studied cancer genes in CGC and ability to identify a core set of genes that are predicted as drivers by several other methods.  #@NEW_LINE#@#  The methods with strongest support by these criteria were 20/20+, TUSON, and MutsigCV.  #@NEW_LINE#@#  Roughly 40% of predicted drivers by these methods were in CGC, contrasted with roughly 10% of predicted drivers by the remaining methods.  #@NEW_LINE#@#  They also had substantially more overlap with other methods and predicted the smallest fraction of unique genes, those having no overlap with other methods (Table 1 and Fig S3).  #@NEW_LINE#@#  Although detecting some unique genes is desirable for purposes of discovering novel drivers, if the fraction of unique predictions is much greater than one-half, a method may be prone to false positives.  #@NEW_LINE#@#  Comparing the gene P value distribution of a method of interest with theoretically expected P values and with the total number of predicted driver genes may help make sense of such a result.  #@NEW_LINE#@#  
The TDC metric (TDC 100 and TDC 10) evaluates the stability of the top k genes in a ranked list, when a method is applied repeatedly to matched random partitions of a dataset.  #@NEW_LINE#@#  Each method produces its own ranked list, and therefore a potentially different set of top k genes.  #@NEW_LINE#@#  For the pancancer dataset, we considered the top 100 genes predicted by each method, and for cancer-specific datasets, we considered the top 10 genes predicted by each method.  #@NEW_LINE#@#  For pancancer, the most consistent methods had a high average fraction of their top 100 genes consistently ranked between different partitions: MuSiC (87 of their top 100 genes), 20/20+ (75 of their top 100 genes), and TUSON (73 of their top 100 genes) (Fig 1D and Table 1).  #@NEW_LINE#@#  These three methods also consistently ranked an average of 8 or 9 of their top 10 genes in cancer-specific datasets of BRAC, LUAD, and HNSCC (except for TUSON on LUAD) (Fig S7).  #@NEW_LINE#@#  We suggest that the ability to reproduce approximately three-quarters of the same top-ranked genes is a reasonable baseline standard.  #@NEW_LINE#@#  
Most commonly used driver gene prediction methods produce a P value for each gene.  #@NEW_LINE#@#  These probabilistic scores have utility for end users, because they provide a means to separate driver and passenger genes by a threshold selected according to a users tolerance for false discoveries.  #@NEW_LINE#@#  If properly calibrated, P values can help eliminate arbitrary decisions about where to set a score threshold when one does not know in advance how exactly many driver genes are expected.  #@NEW_LINE#@#  However, poorly distributed P values can inflate false positives or reduce sensitivity, and they are an indication that a tool may be making inappropriate assumptions.  #@NEW_LINE#@#  Based on the assumption that the total number of cancer driver genes is small compared with the total number of human genes (6), it is reasonable to assume that P values assigned to all genes should be approximately uniform after a core set of well-established driver genes have been dropped.  #@NEW_LINE#@#  
The MLFC metric proposed here quantifies the deviation between these theoretically expected P values and the observed P values generated by a method.  #@NEW_LINE#@#  Lower values of MLFC are desired; 20/20+ had the lowest MLFC of methods evaluated, both for pancancer and for all four cancer types evaluated (Fig 1B, Table 1, and Fig S7).  #@NEW_LINE#@#  The highest MLFC values were for MuSiC, OncodriveClust, and ActiveDriver.  #@NEW_LINE#@#  More detailed P value behavior can be seen in quantilequantile plots that compare the observed P values with a theoretical uniform distribution (Fig S4 A and B).  #@NEW_LINE#@#  The plots show that MuSiC, ActiveDriver, OncodriveClust, OncodriveFM, and OncodriveFML P values are underestimated (lower than theoretically expected) in the critical range (P values from 0 to 0.05), whereas the P values of TUSON and MutsigCV are overestimated.  #@NEW_LINE#@#  The low end of the P value range is critical because it corresponds to the threshold used to call driver genes (q = 0.1 in this work).  #@NEW_LINE#@#  If P values are underestimated in this range, too many genes will be called as drivers.  #@NEW_LINE#@#  In fact, the methods that underestimate P values predict the largest number of drivers and have the highest fraction of uniquely predicted drivers (Fig 1C, Table 1, and Fig S3).  #@NEW_LINE#@#  
These results suggest that the true number of driver genes represented in the pancancer dataset is closer to the number predicted by 20/20+ (208) and TUSON (243), which have the lowest MLFC.  #@NEW_LINE#@#  If a new method is tested and reports a substantially larger number of drivers than these two methods, the MLFC and quantilequantile plots should be carefully checked for discrepancies with theoretically expected P values.  #@NEW_LINE#@#  Once a sufficient number of tumors have been sequenced, analysis of an individual tumor type can provide more relevant information about driver genes in that tumor type than can a pancancer analysis.  #@NEW_LINE#@#  For example, if a driver gene is only important for a particular tumor type or subtype, then the mutations observed in other tumor types contribute only noise.  #@NEW_LINE#@#  The reliability of the analytic method is particularly important when evaluating driver genes in this situation because the numbers of tumors and mutations will be relatively small.  #@NEW_LINE#@#  
The MFLC also has substantial implications for the accuracy of driver gene prediction methods.  #@NEW_LINE#@#  The relatively high MFLC of several methods brings into question the validity of the assumptions or analytic methods used in their construction.  #@NEW_LINE#@#  We believe that the most likely problem is with the assumptions rather than the analytic methods, which all appear to be well thought-out.  #@NEW_LINE#@#  In addition, the most likely problem with the assumptions is that there is unexplained variability in the background mutation rates.  #@NEW_LINE#@#  This variability may be tumor type specific or even patient or tumor specific.  #@NEW_LINE#@#  In an effort to understand the potential effects of such unexplained variability on cancer gene driver predictions, we modeled the situation encountered when various numbers of mutations were available for evaluation.  #@NEW_LINE#@#  The results were striking in that high levels of variability produced huge numbers of false positives when background mutations rates were high.  #@NEW_LINE#@#  Thus, cancers with high background mutation rates (such as those associated with environmental carcinogens) are the most problematic for driver prediction methods.  #@NEW_LINE#@#  This analysis also demonstrated how unexplained variability in gene mutation rates might confound power calculations.  #@NEW_LINE#@#  Estimates of near-saturation discovery of drivers using 5,000 samples in high-mutation-rate cancers, such as melanoma (12), may be overly optimistic, and such discovery may require more resources than currently projected.  #@NEW_LINE#@#  Identifying the optimum driver gene prediction methods will be an important part of this effort, and we hope that the evaluation protocol described here will help to test and improve those methods.  #@NEW_LINE#@#  

Materials_and_Methods  #@NEW_LINE#@#  
Data_Collection  #@NEW_LINE#@#  
The pancancer dataset consists of 729,205 small somatic variants encompassing 7,916 distinct samples from 34 specific cancer types by merging data in published whole-exome or whole-genome sequencing studies used by TUSON (elledgelab.med.harvard.edu/wp-content/uploads/2013/11/Mutation_Dataset.txt.zip) (9) and Mutsig (www.tumorportal.org/load/data/per_ttype_mafs/PanCan.maf) (12) and removing duplicate samples in both studies.  #@NEW_LINE#@#  Any studies that did not report silent mutations were removed.  #@NEW_LINE#@#  Data in refs.  #@NEW_LINE#@#  9 and 12 originated from The Cancer Genome Atlas, International Cancer Genome Consortium, the Catalogue of Somatic Mutations in Cancer database (20), and dbGAP (21).  #@NEW_LINE#@#  We did not see evidence of batch effects by data source in the number of variants per tumor type, single-nucleotide mutation spectra, or specific mutation consequence types.  #@NEW_LINE#@#  We further applied quality control to this data by filtering out hypermutated samples ( greater than 1,000 intragenic small somatic variants) (6), and regions prone to mutation calling artifacts [any sequencing read mappability warning cataloged in the University of California, Santa Cruz (UCSC), Genome Browser (22)].  #@NEW_LINE#@#  The cleaned pancancer dataset is at karchinlab.org/data/Protocol/pancan-mutation-set-from-Tokheim-2016.txt.gz.  #@NEW_LINE#@#  The CRAVAT webserver (version 3.0) (23) was used to automatically retrieve the mappability warning codes.  #@NEW_LINE#@#  Gene names were standardized to HUGO Gene Nomenclature Committee through converting previous symbols and synonyms to the accepted gene name (downloaded January 29, 2015: ftp://ftp.ebi.ac.uk/pub/databases/genenames/locus_groups/protein-coding_gene.txt.gz).  #@NEW_LINE#@#  Four cancer-specific mutation sets were extracted from the pancancer set: PDAC, BRAC, LUAD, and HNSCC.  #@NEW_LINE#@#  

Evaluation_Metrics  #@NEW_LINE#@#  
The MLFC is a metric of discrepancy between an observed P value distribution reported by a method and a theoretical uniform null distribution.  #@NEW_LINE#@#  We define P(i) = ith smallest P value, q(i)=i/n, and the MLFC=(1/n)i=1n|log2(P(i)/q(i))|, where P represents the observed P value, q is the corresponding expected P value from a uniform distribution, n is the total number of genes, and MLFC is the average difference of observed and theoretical P values.  #@NEW_LINE#@#  Values of MLFC near zero indicate smaller discrepancies, and therefore better statistical modeling of the passenger gene null distribution.  #@NEW_LINE#@#  To evaluate TUSON, which reports both an oncogene (OG) and tumor suppressor gene (TSG) P value, we calculated the average MLFC score between the two.  #@NEW_LINE#@#  
Consistency assesses stability in gene ranking.  #@NEW_LINE#@#  Each method was applied to 10 repeated random splits, consisting of two disjoint halves of the full data.  #@NEW_LINE#@#  For pancancer assessment, the proportion of samples from each cancer type was maintained in each half.  #@NEW_LINE#@#  Disjoint halves were scored separately by each method, and genes were ranked from low to high P values.  #@NEW_LINE#@#  For a fair comparison between methods, we considered a specific depth of top-ranked genes, rather than a fixed q value threshold.  #@NEW_LINE#@#  This is because consistency becomes harder to achieve as the number of top-ranked genes gets larger.  #@NEW_LINE#@#  For example, a method that predicts 100 significant genes at q  0.1 has an advantage in consistency over a method that predicts 1,000 significant genes at that threshold.  #@NEW_LINE#@#  We define TopDropconsistency=|Id|/d, where d is the designated depth of interest for the ranked gene list and Id is the TopDrop intersection, Id=A(1:d)B(1:2d), defined as the intersection between predictions from the two random halves A and B such that the top d genes in A do not fall past twice the designated depth (2d) in B.  #@NEW_LINE#@#  
We expect that all methods will lose statistical power and have greater random sampling error when they are predicting on a dataset that has been split in half.  #@NEW_LINE#@#  Therefore, we chose to allow genes to fall twice as far down the list in the B half of the split, to better distinguish random effects and methods with intrinsically low consistency.  #@NEW_LINE#@#  

20_20+__A_Method_for_Driver_Gene_Prediction  #@NEW_LINE#@#  
Our goal was to generalize the 20/20 rule (Fig S9) by replacing the decision tree and fixed thresholds with a more flexible learning framework.  #@NEW_LINE#@#  We selected a Random Forest (ensemble of decision trees) and used the set of OGs and TSGs identified by the original 20/20 rule as a training set.  #@NEW_LINE#@#  We designed a set of 24 predictive features described in Dataset S5 and Fig S10.  #@NEW_LINE#@#  20/20+ uses a three-class Random Forest (24, 25) machine-learning algorithm from the randomForest R package to predict whether a gene is an OG, TSG, or passenger gene.  #@NEW_LINE#@#  Each gene was scored as the fraction of trees that voted for OG, TSG, or passenger gene.  #@NEW_LINE#@#  A driver score for each was calculated as the sum of the OG and TSG scores.  #@NEW_LINE#@#  To assess statistical significance, we computed a P value for each score by using Monte Carlo simulations, and subsequently corrected for multiple hypothesis testing using the BenjaminiHochberg method.  #@NEW_LINE#@#  See SI Materials and Methods for details.  #@NEW_LINE#@#  
A paper that evaluates various cancer driver methods by independent criteria (26) was published during the review of our manuscript.  #@NEW_LINE#@#  


Acknowledgments  #@NEW_LINE#@#  
Thanks to Dr. Daniel Naiman for review of the statistical analysis.  #@NEW_LINE#@#  This research was funded by National Cancer Institute (NCI) Grant F31CA200266 (to C.J.T.  #@NEW_LINE#@#  ); NCI Grants 5U01CA180956-03 and 1U24CA204817-01 (to R.K.); and The Virginia and D. K. Ludwig Fund for Cancer Research, Lustgarten Foundation for Pancreatic Cancer Research, The Sol Goldman Center for Pancreatic Cancer Research, and NCI Grant P50-CA62924 (to B.V.).  #@NEW_LINE#@#  

Footnotes  #@NEW_LINE#@#  




