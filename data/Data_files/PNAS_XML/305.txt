article id="http://dx.doi.org/10.1073/pnas.1602413113"  #@NEW_LINE#@#  
title  #@NEW_LINE#@#  
Cluster failure: Why fMRI inferences for spatial extent have inflated false-positive rates  #@NEW_LINE#@#  

Significance  #@NEW_LINE#@#  
Functional MRI (fMRI) is 25 years old, yet surprisingly its most common statistical methods have not been validated using real data.  #@NEW_LINE#@#  Here, we used resting-state fMRI data from 499 healthy controls to conduct 3 million task group analyses.  #@NEW_LINE#@#  Using this null data with different experimental designs, we estimate the incidence of significant results.  #@NEW_LINE#@#  In theory, we should find 5% false positives (for a significance threshold of 5%), but instead we found that the most common software packages for fMRI analysis (SPM, FSL, AFNI) can result in false-positive rates of up to 70%.  #@NEW_LINE#@#  These results question the validity of a number of fMRI studies and may have a large impact on the interpretation of weakly significant neuroimaging results.  #@NEW_LINE#@#  

Abstract  #@NEW_LINE#@#  
The most widely used task functional magnetic resonance imaging (fMRI) analyses use parametric statistical methods that depend on a variety of assumptions.  #@NEW_LINE#@#  In this work, we use real resting-state data and a total of 3 million random task group analyses to compute empirical familywise error rates for the fMRI software packages SPM, FSL, and AFNI, as well as a nonparametric permutation method.  #@NEW_LINE#@#  For a nominal familywise error rate of 5%, the parametric statistical methods are shown to be conservative for voxelwise inference and invalid for clusterwise inference.  #@NEW_LINE#@#  Our results suggest that the principal cause of the invalid cluster inferences is spatial autocorrelation functions that do not follow the assumed Gaussian shape.  #@NEW_LINE#@#  By comparison, the nonparametric permutation test is found to produce nominal results for voxelwise as well as clusterwise inference.  #@NEW_LINE#@#  These findings speak to the need of validating the statistical methods being used in the field of neuroimaging.  #@NEW_LINE#@#  

Results  #@NEW_LINE#@#  
A total of 2,880,000 random group analyses were performed to compute the empirical false-positive rates of SPM, FSL, and AFNI; these comprise 1,000 one-sided random analyses repeated for 192 parameter combinations, three thresholding approaches, and five tools in the three software packages.  #@NEW_LINE#@#  The tested parameter combinations, given in Table 1, are common in the fMRI field according to a recent review (26).  #@NEW_LINE#@#  The following five analysis tools were tested: SPM OLS, FSL OLS, FSL FLAME1, AFNI OLS (3dttest++), and AFNI 3dMEMA.  #@NEW_LINE#@#  The ordinary least-squares (OLS) functions only use the parameter estimates of BOLD response magnitude from each subject in the group analysis, whereas FLAME1 in FSL and 3dMEMA in AFNI also consider the variance of the subject-specific parameter estimates.  #@NEW_LINE#@#  To compare the parametric statistical methods used by SPM, FSL, and AFNI to a nonparametric method, all analyses were also performed using a permutation test (22, 23, 27).  #@NEW_LINE#@#  All tools were used to generate inferences corrected for the FWE rate over the whole brain.  #@NEW_LINE#@#  
Resting-state fMRI data from 499 healthy controls, downloaded from the 1,000 Functional Connectomes Project (4), were used for all analyses.  #@NEW_LINE#@#  Resting-state data should not contain systematic changes in brain activity, but our previous work (14) showed that the assumed activity paradigm can have a large impact on the degree of false positives.  #@NEW_LINE#@#  Several different activity paradigms were therefore used, two block based (B1 and B2) and two event related (E1 and E2); see Table 1 for details.  #@NEW_LINE#@#  
Fig 1 presents the main findings of our study, summarized by a common analysis setting of a one-sample t test with 20 subjects and 6-mm smoothing [see SI Appendix, Figs.  #@NEW_LINE#@#  S1S6 (20 subjects) and SI Appendix, Figs.  #@NEW_LINE#@#  S7S12 (40 subjects) for the full results].  #@NEW_LINE#@#  In broad summary, parametric softwares FWE rates for clusterwise inference far exceed their nominal 5% level, whereas parametric voxelwise inferences are valid but conservative, often falling below 5%.  #@NEW_LINE#@#  Permutation false positives are controlled at a nominal 5% for the two-sample t test, and close to nominal for the one-sample t test.  #@NEW_LINE#@#  The impact of smoothing and cluster-defining threshold (CDT) was appreciable for the parametric methods, with CDT P = 0.001 (SPM default) having much better FWE control than CDT P = 0.01 [FSL default; AFNI does not have a default setting, but P = 0.005 is most prevalent (21)].  #@NEW_LINE#@#  Among the parametric software packages, FSLs FLAME1 clusterwise inference stood out as having much lower FWE, often being valid (under 5%), but this comes at the expense of highly conservative voxelwise inference.  #@NEW_LINE#@#  
We also examined an ad hoc but commonly used thresholding approach, where a CDT of P = 0.001 (uncorrected for multiple comparisons) is used together with an arbitrary cluster extent threshold of 10 8-mm3 voxels (26, 28).  #@NEW_LINE#@#  We conducted an additional 1,000 analyses repeated for four assumed activity paradigms and the five different analysis tools (Fig 2).  #@NEW_LINE#@#  Although no precise control of false positives is assured, we found this makeshift inference method had FWE ranging 6090% for all functions except FLAME1 in FSL.  #@NEW_LINE#@#  Put another way, this P = 0.001 + 10 voxels method has a FWE-corrected P value of 0.60.9.  #@NEW_LINE#@#  We now seek to understand the sources of these inaccuracies.  #@NEW_LINE#@#  
Comparison_of_Empirical_and_Theoretical_Test_Statistic_Distributions  #@NEW_LINE#@#  
As a first step to understand the inaccuracies in the parametric methods, the test statistic values (t or z scores, as generated by each package) were compared with their theoretical null distributions.  #@NEW_LINE#@#  SI Appendix, Fig S13, shows the histogram of all brain voxels for 1,000 group analyses.  #@NEW_LINE#@#  The empirical and theoretical nulls are well matched, except for FSL FLAME1, which has lower variance (^2=0.67) than the theoretical null (2=1).  #@NEW_LINE#@#  This is the proximal cause of the highly conservative results from FSL FLAME1.  #@NEW_LINE#@#  The mixed-effects variance is composed of intrasubject and intersubject variance (WTN2,BTW2, respectively), and although other software packages do not separately estimate each, FLAME1 estimates each and constrains BTW2 to be positive.  #@NEW_LINE#@#  In these null data, the true effect in each subject is zero, and thus the true BTW2=0.  #@NEW_LINE#@#  Thus, unless FLAME1's ^BWT2 is correctly estimated to be 0, it can only be positively biased, and in fact this point was raised by the original authors (29).  #@NEW_LINE#@#  
In an follow-up analysis on FSL FLAME1 (SI Appendix), we conducted two-sample t tests on task fMRI data, randomly splitting subjects into two groups.  #@NEW_LINE#@#  In this setting, the two-sample null hypothesis was still true, but BTW2 greater than 0.  #@NEW_LINE#@#  Here, we found cluster false-positive rates comparable to FSL OLS (44.8% for CDT P = 0.01 and 13.8% for CDT P = 0.001), supporting our conjecture of zero between-subject variance as the cause of FLAME1s conservativeness on completely null resting data.  #@NEW_LINE#@#  

Spatial_Autocorrelation_Function_of_the_Noise  #@NEW_LINE#@#  
SPM and FSL depend on Gaussian random-field theory (RFT) for FWE-corrected voxelwise and clusterwise inference.  #@NEW_LINE#@#  However, RFT clusterwise inference depends on two additional assumptions.  #@NEW_LINE#@#  The first assumption is that the spatial smoothness of the fMRI signal is constant over the brain, and the second assumption is that the spatial autocorrelation function has a specific shape (a squared exponential) (30).  #@NEW_LINE#@#  To investigate the second assumption, the spatial autocorrelation function was estimated and averaged using 1,000 group difference maps.  #@NEW_LINE#@#  For each group difference map and each distance (120 mm), the spatial autocorrelation was estimated and averaged along x, y, and z.  #@NEW_LINE#@#  The empirical spatial autocorrelation functions are given in SI Appendix, Fig S14.  #@NEW_LINE#@#  A reference squared exponential is also included for each software, based on an intrinsic smoothness of 9.5 mm (FWHM) for SPM, 9 mm for FSL, and 8 mm for AFNI (according to the mean smoothness of 1,000 group analyses, presented in SI Appendix, Fig S15).  #@NEW_LINE#@#  The empirical spatial autocorrelation functions are clearly far from a squared exponential, having heavier tails.  #@NEW_LINE#@#  This may explain why the parametric methods work rather well for a high CDT (resulting in small clusters, more reflective of local autocorrelation) and not as well for a low CDT (resulting in large clusters, reflecting distant autocorrelation).  #@NEW_LINE#@#  SI Appendix, Fig S16, shows how the cluster extent thresholds differ between the parametric and the nonparametric methods, for a CDT of P = 0.01.  #@NEW_LINE#@#  The nonparametric permutation test is valid for any spatial autocorrelation function and finds much more stringent cluster extent thresholds (three to six times higher compared with SPM, FSL, and AFNI).  #@NEW_LINE#@#  
To better understand the origin of the heavy tails, the spatial autocorrelation was estimated at different preprocessing stages (no preprocessing, after motion correction, after motion correction, and 6-mm smoothing) using the 198 subjects in the Beijing dataset.  #@NEW_LINE#@#  The resulting spatial autocorrelation functions are given in SI Appendix, Fig S17.  #@NEW_LINE#@#  It is clear that the long tails exist in the raw data and become even more pronounced after the spatial smoothing.  #@NEW_LINE#@#  These long-tail spatial correlations also exist for MR phantoms (31) and can therefore be seen as scanner artifacts.  #@NEW_LINE#@#  

Spatial_Distribution_of_False-Positive_Clusters  #@NEW_LINE#@#  
To investigate whether the false clusters appear randomly in the brain, all significant clusters (P less_than 0.05, FWE-corrected) were saved as binary maps and summed together (SI Appendix, Fig S18).  #@NEW_LINE#@#  These maps of voxelwise cluster frequency show the areas more and less likely to be marked as significant in a clusterwise analysis.  #@NEW_LINE#@#  Posterior cingulate was the most likely area to be covered by a cluster, whereas white matter was least likely.  #@NEW_LINE#@#  As this distribution could reflect variation in the local smoothness in the data, we used group residuals from 1,000 two-sample t tests to estimate voxelwise spatial smoothness (32) (SI Appendix, Fig S19).  #@NEW_LINE#@#  The local smoothness maps show evidence of a posterior cingulate hot spot and reduced intensity in white matter, just as in the false-positive cluster maps.  #@NEW_LINE#@#  Notably, having local smoothness varying systematically with tissue type has also been observed for VBM data (13).  #@NEW_LINE#@#  In short, this suggests that violation of the stationary smoothness assumption may also be contributing to the excess of false positives.  #@NEW_LINE#@#  
In a follow-up analysis using the nonstationary toolbox for SPM (fmri.wfubmc.edu/cms/software#NS), which provides parametric cluster inference allowing for spatially varying smoothness, we calculated FWE rates for stationary as well as nonstationary smoothness.  #@NEW_LINE#@#  Use of nonstationary cluster size inference did not produce nominal FWE: relative to the stationary cluster size test, it produced lower but still invalid FWE for a CDT of P = 0.01, and higher FWE for a CDT of P = 0.001 (SI Appendix, Table S2).  #@NEW_LINE#@#  This inconclusive performance can be attributed to additional assumptions and approximations introduced by the nonstationary cluster size test that can degrade its performance (33, 34).  #@NEW_LINE#@#  In short, we still cannot rule out heterogeneous smoothness as contributor to the standard cluster size methods invalid performance.  #@NEW_LINE#@#  

Impact_on_a_Non-Null__Task_Group_Analysis  #@NEW_LINE#@#  
All of the analyses to this point have been based on resting-state fMRI data, where the null hypothesis should be true.  #@NEW_LINE#@#  We now use task data to address the practical question of How will my FWE-corrected cluster P values change?  #@NEW_LINE#@#  if a user were to switch from a parametric to a nonparametric method.  #@NEW_LINE#@#  We use four task datasets [rhyme judgment, mixed gambles (35), livingnonliving decision with plain or mirror-reversed text, word and object processing (36)] downloaded from OpenfMRI (7).  #@NEW_LINE#@#  The datasets were analyzed using a parametric (the OLS option in FSLs FEAT) and a nonparametric method (the randomise function in FSL) using a smoothing of 5-mm FWHM (default option in FSL).  #@NEW_LINE#@#  The only difference between these two methods is that FSL FEAT-OLS relies on Gaussian RFT to calculate the corrected cluster P values, whereas randomise instead uses the data itself.  #@NEW_LINE#@#  The resulting cluster P values are given in SI Appendix, Table S3 (CDT of P = 0.01) and SI Appendix, Tables S4 and S5 (CDT of P = 0.001).  #@NEW_LINE#@#  SI Appendix, Fig S20, summarizes these results, plotting the ratio of FWE-corrected P values, nonparametric to parametric, against cluster size.  #@NEW_LINE#@#  All nonparametric P values were larger than parametric (ratio  greater than  1).  #@NEW_LINE#@#  Although this could be taken as evidence of a conservative nonparametric procedure, the extensive simulations showing valid nonparametric and invalid parametric cluster size inference instead suggest inflated (biased) significance in the parametric inferences.  #@NEW_LINE#@#  For CDT P = 0.01, there were 23 clusters (in 11 contrasts) with FWE parametric P values significant at P = 0.05 that were not significant by permutation.  #@NEW_LINE#@#  For CDT P = 0.001, there were 11 such clusters (in eight contrasts).  #@NEW_LINE#@#  If we assume that these mismatches represent false positives, then the empirical FWE for these 18 contrasts considered is 11/18 = 61% for CDT P = 0.01 and 8/18 = 44% for CDT P = 0.001.  #@NEW_LINE#@#  These findings indicate that the problems exist also for task-based fMRI data, and not only for resting-state data.  #@NEW_LINE#@#  

Permutation_Test_for_One-Sample_t_Test  #@NEW_LINE#@#  
Although permutation tests have FWE within the expected bounds for all two-sample test results, for one-sample tests they can exhibit conservative or invalid behavior.  #@NEW_LINE#@#  As shown in SI Appendix, Figs.  #@NEW_LINE#@#  S3, S4, S9, and S10, the FWE can be as low as 0.8% or as high as 40%.  #@NEW_LINE#@#  The one-sample permutation FWE varies between site (Beijing, Cambridge, Oulu), but within each site shows a consistent pattern between the two CDTs and even for voxelwise inference.  #@NEW_LINE#@#  The one-sample permutation test comprises a sign flipping procedure, justified by symmetrically distributed errors (22).  #@NEW_LINE#@#  Although the voxel-level test statistics appear symmetric and do follow the expected parametric t distribution (SI Appendix, Fig S13), the statistic values benefit from the central limit theorem and their symmetry does not imply symmetry of the data.  #@NEW_LINE#@#  We conducted tests of the symmetry assumption on the data for block design B1, a case suffering both spuriously low (Cambridge) and high (Beijing, Oulu) FWE (SI Appendix).  #@NEW_LINE#@#  We found very strong evidence of asymmetric errors, but with no consistent pattern of asymmetry; that is, some brain regions showed positive skew and others showed negative skew.  #@NEW_LINE#@#  


Discussion  #@NEW_LINE#@#  
Using mass empirical analyses with task-free fMRI data, we have found that the parametric statistical methods used for group fMRI analysis with the packages SPM, FSL, and AFNI can produce FWE-corrected cluster P values that are erroneous, being spuriously low and inflating statistical significance.  #@NEW_LINE#@#  This calls into question the validity of countless published fMRI studies based on parametric clusterwise inference.  #@NEW_LINE#@#  It is important to stress that we have focused on inferences corrected for multiple comparisons in each group analysis, yet some 40% of a sample of 241 recent fMRI papers did not report correcting for multiple comparisons (26), meaning that many group results in the fMRI literature suffer even worse false-positive rates than found here (37).  #@NEW_LINE#@#  According to the same overview (26), the most common cluster extent threshold used is 80 mm3 (10 voxels of size 2 × 2 × 2 mm), for which the FWE was estimated to be 6090% (Fig 2).  #@NEW_LINE#@#  
Compared with our previous work (14), the results presented here are more important for three reasons.  #@NEW_LINE#@#  First, the current study considers group analyses, whereas our previous study looked at single-subject analyses.  #@NEW_LINE#@#  Second, we here investigate the validity of the three most common fMRI software packages (26), whereas we only considered SPM in our previous study.  #@NEW_LINE#@#  Third, although we confirmed the expected finding of permutations validity for two-sample t tests, we found that some settings we considered gave invalid FWE control for one-sample permutation tests.  #@NEW_LINE#@#  We identified skewed data as a likely cause of this and identified a simple test for detecting skew in the data.  #@NEW_LINE#@#  Users should consider testing for skew before applying a one-sample t test, but it remains an important area for developing new methods for one-sample analyses (see, e.g., ref.  #@NEW_LINE#@#  38).  #@NEW_LINE#@#  
Why_Is_Clusterwise_Inference_More_Problematic_than_Voxelwise?  #@NEW_LINE#@#  
Our principal finding is that the parametric statistical methods work well, if conservatively, for voxelwise inference, but not for clusterwise inference.  #@NEW_LINE#@#  We note that other authors have found RFT clusterwise inference to be invalid in certain settings under stationarity (21, 30) and nonstationarity (13, 33).  #@NEW_LINE#@#  This present work, however, is the most comprehensive to explore the typical parameters used in task fMRI for a variety of software tools.  #@NEW_LINE#@#  Our results are also corroborated by similar experiments for structural brain analysis (VBM) (1113, 39, 40), showing that cluster-based P values are more sensitive to the statistical assumptions.  #@NEW_LINE#@#  For voxelwise inference, our results are consistent with a previous comparison between parametric and nonparametric methods for fMRI, showing that a nonparametric permutation test can result in more lenient statistical thresholds while offering precise control of false positives (13, 41).  #@NEW_LINE#@#  
Both SPM and FSL rely on RFT to correct for multiple comparisons.  #@NEW_LINE#@#  For voxelwise inference, RFT is based on the assumption that the activity map is sufficiently smooth, and that the spatial autocorrelation function (SACF) is twice-differentiable at the origin.  #@NEW_LINE#@#  For clusterwise inference, RFT additionally assumes a Gaussian shape of the SACF (i.e., a squared exponential covariance function), that the spatial smoothness is constant over the brain, and that the CDT is sufficiently high.  #@NEW_LINE#@#  The 3dClustSim function in AFNI also assumes a constant spatial smoothness and a Gaussian form of the SACF (because a Gaussian smoothing is applied to each generated noise volume).  #@NEW_LINE#@#  It makes no assumption on the CDT and should be accurate for any chosen value.  #@NEW_LINE#@#  As the FWE rates are far above the expected 5% for clusterwise inference, but not for voxelwise inference, one or more of the Gaussian SACF, the stationary SACF, or the sufficiently high CDT assumptions (for SPM and FSL) must be untenable.  #@NEW_LINE#@#  

Why_Does_AFNIs_Monte_Carlo_Approach__Unreliant_on_RFT__Not_Perform_Better?  #@NEW_LINE#@#  
As can be observed in SI Appendix, Figs.  #@NEW_LINE#@#  S2, S4, S8, and S10, AFNIs FWE rates are excessive even for a CDT of P = 0.001.  #@NEW_LINE#@#  There are two main factors that explain these results.  #@NEW_LINE#@#  
First, AFNI estimates the spatial group smoothness differently compared with SPM and FSL.  #@NEW_LINE#@#  AFNI averages smoothness estimates from the first-level analysis, whereas SPM and FSL estimate the group smoothness using the group residuals from the general linear model (32).  #@NEW_LINE#@#  The group smoothness used by 3dClustSim may for this reason be too low (compared with SPM and FSL; SI Appendix, Fig S15).  #@NEW_LINE#@#  
Second, a 15-year-old bug was found in 3dClustSim while testing the three software packages (the bug was fixed by the AFNI group as of May 2015, during preparation of this manuscript).  #@NEW_LINE#@#  The bug essentially reduced the size of the image searched for clusters, underestimating the severity of the multiplicity correction and overestimating significance (i.e., 3dClustSim FWE P values were too low).  #@NEW_LINE#@#  
Together, the lower group smoothness and the bug in 3dClustSim resulted in cluster extent thresholds that are much lower compared with SPM and FSL (SI Appendix, Fig S16), which resulted in particularly high FWE rates.  #@NEW_LINE#@#  We find this to be alarming, as 3dClustSim is one of the most popular choices for multiple-comparisons correction (26).  #@NEW_LINE#@#  
We note that FWE rates are lower with the bug-fixed 3dClustSim function.  #@NEW_LINE#@#  As an example, the updated function reduces the degree of false positives from 31.0% to 27.1% for a CDT of P = 0.01, and from 11.5% to 8.6% for a CDT of P = 0.001 (these results are for two-sample t tests using the Beijing data, analyzed with the E2 paradigm and 6-mm smoothing).  #@NEW_LINE#@#  

Suitability_of_Resting-State_fMRI_as_Null_Data_for_Task_fMRI  #@NEW_LINE#@#  
One possible criticism of our work is that resting-state fMRI data do not truly compromise null data, as they may be affected by consistent trends or transients, for example, at the start of the session.  #@NEW_LINE#@#  However, if this were the case, the excess false positives would appear only in certain paradigms and, in particular, least likely in the randomized event-related (E2) design.  #@NEW_LINE#@#  Rather, the inflated false positives were observed across all experiment types with parametric cluster size inference, limiting the role of any such systematic effects.  #@NEW_LINE#@#  Additionally, one could argue that the spatial structure of resting fMRI, the very covariance that gives rise to resting-state networks, is unrepresentative of task data and inflates the spatial autocorrelation functions and induces nonstationarity.  #@NEW_LINE#@#  We do not believe this is the case because it has been shown that resting-state networks can be estimated from the residuals of task data (42), suggesting that resting data and task noise share similar properties.  #@NEW_LINE#@#  We assessed this in our four task datasets, estimating the spatial autocorrelation of the group residuals (SI Appendix, Fig S21) and found the same type of heavy-tailed behavior as in the resting data.  #@NEW_LINE#@#  Furthermore, the same type of heavy-tail spatial autocorrelation has been observed for data collected with an MR phantom (31).  #@NEW_LINE#@#  Finally, another follow-up analysis on task data (see Comparison of Empirical and Theoretical Test Statistic Distributions and SI Appendix, Task-Based fMRI Data, Human Connectome Project, a two-sample t test on a random split of a homogeneous group of subjects) found inflated false-positive rates similar to the null data.  #@NEW_LINE#@#  Altogether, we find that these findings support the appropriateness of resting data as a suitable null for task fMRI.  #@NEW_LINE#@#  

The_Future_of_fMRI  #@NEW_LINE#@#  
Due to lamentable archiving and data-sharing practices, it is unlikely that problematic analyses can be redone.  #@NEW_LINE#@#  Considering that it is now possible to evaluate common statistical methods using real fMRI data, the fMRI community should, in our opinion, focus on validation of existing methods.  #@NEW_LINE#@#  The main drawback of a permutation test is the increase in computational complexity, as the group analysis needs to be repeated 1,00010,000 times.  #@NEW_LINE#@#  However, this increased processing time is not a problem in practice, as for typical sample sizes a desktop computer can run a permutation test for neuroimaging data in less than a minute (27, 43).  #@NEW_LINE#@#  Although we note that metaanalysis can play an important role in teasing apart false-positive findings from consistent results, that does not mitigate the need for accurate inferential tools that give valid results for each and every study.  #@NEW_LINE#@#  
Finally, we point out the key role that data sharing played in this work and its impact in the future.  #@NEW_LINE#@#  Although our massive empirical study depended on shared data, it is disappointing that almost none of the published studies have shared their data, neither the original data nor even the 3D statistical maps.  #@NEW_LINE#@#  As no analysis method is perfect, and new problems and limitations will be certainly found in the future, we commend all authors to at least share their statistical results [e.g., via NeuroVault.org (44)] and ideally the full data [e.g., via OpenfMRI.org (7)].  #@NEW_LINE#@#  Such shared data provide enormous opportunities for methodologists, but also the ability to revisit results when methods improve years later.  #@NEW_LINE#@#  


Materials_and_Methods  #@NEW_LINE#@#  
Only publicly shared anonymized fMRI data were used in this study.  #@NEW_LINE#@#  Data collection at the respective sites was subject to their local ethics review boards, who approved the experiments and the dissemination of the anonymized data.  #@NEW_LINE#@#  For the 1,000 Functional Connectomes Project, collection of the Cambridge data was approved by the Massachusetts General Hospital partners institutional review board (IRB); collection of the Beijing data was approved by the IRB of State Key Laboratory for Cognitive Neuroscience and Learning, Beijing Normal University; and collection of the Oulu data was approved by the ethics committee of the Northern Ostrobothnian Hospital District.  #@NEW_LINE#@#  Dissemination of the data was approved by the IRBs of New York University Langone Medical Center and New Jersey Medical School (4).  #@NEW_LINE#@#  The word and object processing experiment (36) was approved by the Berkshire National Health Service Research Ethics Committee.  #@NEW_LINE#@#  The mixed-gambles experiment (35), the rhyme judgment experiment, and the livingnonliving experiments were approved by the University of California, Los Angeles, IRB.  #@NEW_LINE#@#  All subjects gave informed written consent after the experimental procedures were explained.  #@NEW_LINE#@#  
The resting-state fMRI data from the 499 healthy controls were analyzed in SPM, FSL, and AFNI according to standard processing pipelines, and the analyses were repeated for four levels of smoothing (4-, 6-, 8-, and 10-mm FWHM) and four task paradigms (B1, B2, E1, and E2).  #@NEW_LINE#@#  Random group analyses were then performed using the parametric functions in the three softwares (SPM OLS, FLAME1, FSL OLS, 3dttest, 3dMEMA) as well as the nonparametric permutation test.  #@NEW_LINE#@#  The degree of false positives was finally estimated as the number of group analyses with any significant result, divided by the number of group analyses (1,000).  #@NEW_LINE#@#  All of the processing scripts are available at https://github.com/wanderine/ParametricMultisubjectfMRI.  #@NEW_LINE#@#  

Acknowledgments  #@NEW_LINE#@#  
We thank Robert Cox, Stephen Smith, Mark Woolrich, Karl Friston, and Guillaume Flandin, who gave us valuable feedback on this work.  #@NEW_LINE#@#  This study would not be possible without the recent data-sharing initiatives in the neuroimaging field.  #@NEW_LINE#@#  We therefore thank the Neuroimaging Informatics Tools and Resources Clearinghouse and all of the researchers who have contributed with resting-state data to the 1,000 Functional Connectomes Project.  #@NEW_LINE#@#  Data were also provided by the Human Connectome Project, WU-Minn Consortium (principal investigators: David Van Essen and Kamil Ugurbil; Grant 1U54MH091657) funded by the 16 NIH Institutes and Centers that support the NIH Blueprint for Neuroscience Research, and by the McDonnell Center for Systems Neuroscience at Washington University.  #@NEW_LINE#@#  We also thank Russ Poldrack and his colleagues for starting the OpenfMRI Project (supported by National Science Foundation Grant OCI-1131441) and all of the researchers who have shared their task-based data.  #@NEW_LINE#@#  The Nvidia Corporation, which donated the Tesla K40 graphics card used to run all the permutation tests, is also acknowledged.  #@NEW_LINE#@#  This research was supported by the Neuroeconomic Research Initiative at Linköping University, by Swedish Research Council Grant 2013-5229 (Statistical Analysis of fMRI Data), the Information Technology for European Advancement 3 Project BENEFIT (better effectiveness and efficiency by measuring and modelling of interventional therapy), and the Wellcome Trust.  #@NEW_LINE#@#  

Footnotes  #@NEW_LINE#@#  




